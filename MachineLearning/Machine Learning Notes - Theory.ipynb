{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.902028</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  1.000000  0.902028\n",
       "1  0.902028  1.000000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([path_1, path_2], axis=1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "- **Norm**: Answer the question how big is a vector; Norm of a vector: ${\\displaystyle \\left\\|{\\boldsymbol {x}}\\right\\|_{2}:={\\sqrt {x_{1}^{2}+\\cdots +x_{n}^{2}}}.}$ `numpy.linalg.norm(x)`\n",
    "- **Dot Product**: Algebraic definition: $x⋅y≡x′y:=∑_{i=1}^nx_i∗y_i$\n",
    "- **Dot Product**: Geometric definition: $x⋅y:=∥x∥∗∥y∥∗\\cos(θ)$ (where $θ$ is the angle between the two vectors)\n",
    "- NumPy: `np.dot(x,y)`\n",
    "- **unit vector**: $\\frac{x}{||x||}$\n",
    "- **loss function** is some way for us to value how far is our model from the data that we have. We first define an \"error\" or \"Loss\". For example in Linear Regression the \"error\" is the Euclidean distance between the predicted and the observed value:\n",
    "\n",
    "$$\n",
    "L(x,y;Θ)=∑_{n=1}^i|\\hat{y}−y|=∑_{n=1}^i|θ_1x+θ_2−y|\n",
    "$$\n",
    "\n",
    "- **Chain rule**\n",
    "\n",
    "$$\n",
    "\\frac{∂y}{∂x}=\\frac{∂y}{∂z}∗ \\frac{∂z}{∂x}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "## Linear Classifier\n",
    "\n",
    "Training data can be graphically depicted on a (hyper)plane. **Classifiers** are **mappings** that take **feature vectors as input** and produce **labels as output**. A common kind of classifier is the **linear classifier**, which linearly divides space(the (hyper)plane where training data lies) into two. Given a point $x$ in the space, the classifier $h$ outputs $h(x)=1$ or $h(x)=−1$, depending on where the point x exists in among the two linearly divided spaces.\n",
    "\n",
    "We saw in the lecture above that for a linear classifier $h, h(x;θ)=sign(θ⋅x)$, i.e. the sign of the dot product of $θ$ and $x$ (note that there are multiple parameter vectors that define the same classifier; note also that equidistant points on the same side of the classifier are classified with the same \"strength\"). For linearly separable data, a linear classifier can perfectly separate the data.\n",
    "\n",
    "#### Perceptron Algorithm Definition\n",
    "\n",
    "**Perceptron** $\\displaystyle \\left(\\big \\{ (x^{(i)}, y^{(i)}), i=1,...,n\\big \\} , T \\right):$:\n",
    "\n",
    "  initialize $θ=0$ (vector); $\\theta_0 =0$ (scalar)<br>\n",
    "    for $t=1,...,T$ do<br>    \n",
    "      for $i=1,...,n$ do<br>\n",
    "        if $y^{(i)}(θ⋅x^{(i)} + \\theta_0)≤0$ then<br>        \n",
    "        update $θ=θ+y^{(i)}x^{(i)}$<br>\n",
    "        update $θ_0=θ_0+y^{(i)}$\n",
    "\n",
    "When a mistake is spotted, the updated values of $θ$ and $θ_0$ provide always a better prediction. To see why, let's calculate the difference between the update value of $\\theta$ times the label and the updated value times the label, i.e. $y^{(i)}(θ⋅x^{(i)} + \\theta_0)≤0$.\n",
    "\n",
    "$$\n",
    "y^{(i)}((\\theta +y^{(i)} x^{(i)}) \\cdot x^{(i)} + \\theta _0 + y^{(i)}) - y^{(i)}(\\theta \\cdot x^{(i)} + \\theta _0) = \\\\ (y^{(i)})^2 \\| x^{(i)}\\| ^2 + (y^{(i)})^2 =\\\\ (y^{(i)})^2(\\| x^{(i)}\\| ^2 + 1)) > 0\n",
    "$$\n",
    "\n",
    "([Dot product of a vector with itself is equal to the square ot the norm](https://proofwiki.org/wiki/Dot_Product_of_Vector_with_Itself))\n",
    "\n",
    "___\n",
    "\n",
    "**Novikoff Theorem**: there exists $\\theta^*$  such that **a)** $\\frac{y^{(i)}(\\theta ^* x^{(i)})}{\\| \\theta ^*\\| } \\geq \\gamma$  for all  $i=1,⋯,n$ and some $\\gamma > 0$ **b)** All the examples are bounded  $\\| x^{(i)}\\|  \\leq R, i=1,\\cdots ,n$, then the number $k$ of updates made by the perceptron algorithm is bounded by $\\frac{R^2}{\\gamma ^2}$.\n",
    "\n",
    "**NOTE**:<br>\n",
    "- **For linearly separable dataset, the algorithm will converge!**\n",
    "- **if the dataset is not linearly separable, the algorithm never converges!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Support Vector Machines)\n",
    "\n",
    "*Objective function = loss (how examples fit) + regularization (preference for large margin boundaries)*\n",
    "\n",
    "The magnitude of $\\theta$, $||\\theta||$, describes the \"sensitivity\" of the classifier to changes in $x$: the smaller it is, the less sensitive the classifier is to small changes in $x$. The **decision boundary** is the set of points x which satisfy $θ⋅x+θ_0=0.$ The **Margin Boundary** is the set of points x which satisfy $\\theta x+\\theta_0=±1$.  So, the distance from the decision boundary to the margin boundary is $\\frac{1}{∣∣\\theta∣∣}$ (**maximizing the boundary then means minimizing the $∣∣\\theta∣∣$**). As we increase $∣∣θ∣∣$, $\\frac{1}{∣∣θ∣∣}$ decreases. The loss for the model is:\n",
    "$$\n",
    "J(\\theta , \\theta _0) = \\frac{1}{n} \\sum _{i=1}^{n} \\text {Loss}_ h (y^{(i)} (\\theta \\cdot x^{(i)} + \\theta _0 )) + \\frac{\\lambda }{2} \\mid \\mid \\theta \\mid \\mid ^2.\n",
    "$$\n",
    "The first part represent the **Hinge Loss**, defined as:\n",
    "$$\n",
    "\\max \\Big( 0, 1 - (y^{(i)} (\\theta \\cdot x^{(i)} + \\theta _0 )) \\Big)\n",
    "$$\n",
    "It spots the points not correctly classified or within the margin boundary. The second part represent the width of the margins; Through gradient descent. In other words, we will\n",
    "\n",
    "$loss(z) = 0$: if $z > 1$ if (the point is outside the boundary, on the right direction) and\n",
    "$loss(z) = 0$: if $1 - z$  if $z < 1$ if (either the point is well classified, but inside the boundary, or it is even misclassified).\n",
    "\n",
    "- Start  $θ$  at an arbitrary location: $θ←θstart$\n",
    "- Update  $θ$  repeatedly with  $θ←θ−η \\frac{∂J(θ,θ0)}{∂θ}$  until $θ$  does not change significantly\n",
    "\n",
    "The training objective for the Support Vector Machine (with margin loss) can be seen as optimizing a balance between the average hinge loss over the examples and a regularization term that tries to keep the parameters small (increase the margin). This balance is set by the regularization parameter $λ>0$ (*Note* - $\\theta$ is be column vector, and $\\hat{y}=θ^⊤x$)$\n",
    "\n",
    "**When the hinge loss is $\\geq 0$, the total loss is minimized by: $\\hat{\\theta } = \\frac{1}{\\lambda } y x$ <br>**\n",
    "**When the hinge loss is $\\leq 0$, the total loss is minimized by: $\\hat{\\theta } = ?$**\n",
    "___\n",
    "\n",
    "Passive Aggressive Algo: \n",
    "The new update, when $\\text {Loss}_ h(y \\theta ^{(k+1)}\\cdot x)>0$, should be $\\theta = \\displaystyle  \\theta ^{(k)} + \\frac{1}{\\lambda }yx$, where $\\eta = 1/\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a sequence of  $n$-dimensional data points, $x^{(1)},x^{(2)},...$, and a sequence of $m$-dimensional feature vectors,  $z^{(1)},z^{(2)},...$, extracted from the  $x$'s by a linear transformation,  $z^{(i)}=Ax^{(i)}$ . If $m$ is much smaller than $n$, you might expect that it would be easier to learn in the lower dimensional feature space than in the original data space.\n",
    "\n",
    "In general, **the accuracy in $z$-space (for the seen data) is always bounded by the accuracy in the $x$ space**, as we can always construct a classifier in $x$ space that corresponds to a classifier in $z$ space (but not vice versa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Linear Regression\n",
    "\n",
    "Linear regression tries to estimate a predictor $f$ which is a linear function of the feature vectors. i.e. $f(x)=∑_{i=1}^dθ_ix_i+θ_0$. In carrying out this estimation there can be two kind of mistakes:\n",
    "\n",
    "- Structural Mistakes (Non Linear relation $\\to$ $f(x)$)\n",
    "- Estimation mistake (too many parameters or too low data)\n",
    "\n",
    "In any case, the **objective** is to minimize the empirical risk; $R_n$ is defined as\n",
    "\n",
    "$$\n",
    "\\begin{equation} R_ n(\\theta ) = \\frac{1}{n} \\sum _{t=1}^{n} \\text {Loss}(y^{(t)} - \\theta \\cdot x^{(t)})\\,. \\end{equation}\n",
    "$$\n",
    "\n",
    "If we define the loss with the **mean square** criterion, the risk becomes:\n",
    "\n",
    "$$\n",
    "\\begin{equation} R_ n(\\theta ) = \\frac{1}{n} \\sum _{t=1}^{n} \\frac{(y^{(t)} - \\theta \\cdot x^{(t)})^2}{2}\\,. \\tag{1}\\end{equation}\n",
    "$$\n",
    "\n",
    "In order to minimize it that, we can use two different approaches (**Learning Algorithm**); 1 regards a closed-form solution, the other one is gradient-descend:\n",
    "\n",
    "**Gradient descend**\n",
    "\n",
    "In regular gradient descent, you run through your entire training set, average the computed gradient per sample, and update the parameters with this averaged gradient. This is guaranteed to monotonically improve the objective function, but it is slow (n calculations for 1 update). Often you instead perform stochastic gradient descent, or more specifically minibatch gradient descent, where you update after only averaging the gradient across $k \\dot n$ samples (a \"minibatch\").\n",
    "\n",
    "We learned in lectures that, in general, gradient descent works by moving the parameter in the opposite direction of the slope/gradient. This is accomplished in the update by subtracting the slope/gradient multiplied by the learning rate, $η$ from the current $θ$. The update is \n",
    "\n",
    "$$\n",
    "θ_{new}=θ_{old}−η∗∇θ\n",
    "$$\n",
    "\n",
    "in order to *nudge* the parameter down the error hill; $∇θ$ is the gradient, defined as  $∇θ=−(y_t−θ∗x_t)∗x_t$. So the update becomes:\n",
    "\n",
    "$$\n",
    "θ_{new}=θ_{old}+η(y_t−θ∗x_t)∗x_t\n",
    "$$\n",
    "\n",
    "\n",
    "To make the optimization more robust, we want to add a **regularization** term (**Ridge Regression**). \n",
    "\n",
    "$$\n",
    "J_{n, \\lambda } (\\theta , \\theta _0) = \\frac{1}{n} \\sum _{t=1}^{n} \\frac{(y^{(t)} - \\theta \\cdot x^{(t)}-\\theta _0)^2}{2} + \\frac{\\lambda }{2} \\left\\|  \\theta  \\right\\| ^2\n",
    "$$\n",
    "\n",
    "The new update becomes:\n",
    "\n",
    "$$\n",
    "xθ_{new}=θ_{old}-(\\lambda \\theta- η(y_t−θ∗x_t)∗x_t)\n",
    "$$\n",
    "\n",
    "In this way, **we are pushed to keep $\\theta$ small**; i.e. we will not see huge negative and positive coefficient (especially when we have *collinearity*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Classification\n",
    "\n",
    "[link on kernels](https://www.quora.com/What-are-kernels-in-machine-learning-and-SVM-and-why-do-we-need-them/answer/Lili-Jiang?srid=oOgT)\n",
    "\n",
    "We can use linear classifiers to make non-linear predictions. The easiest way to do this is to first map all the examples $\\in R^d$ to different feature vectors $ϕ(x)\\in R^p$ where typically $p$ is much larger than $d$. We would then simply use a linear classifier on the new (higher dimensional) feature vectors, pretending that they were the original input vectors. As a result, all the linear classifiers we have learned remain applicable, yet produce non-linear classifiers in the original coordinates.\n",
    "\n",
    "**The aim is to find some transformation of the original vector $x$ that maps it in a different dimension so that the data become separable** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can get more and more powerful classifiers by adding linearly independent features, $x^²$, $x^3$... This functions are linearly independent, so the original coordinates always provide something above and beyond what were in the previous ones. Note that when $x$ is already multidimensional, would result in dimensions exploding. Once we have the new feature vector we can make non-linear classification or regression in the original data making a linear classification or regression in the new feature space:\n",
    "\n",
    "- Classification: $h(x;θ,θ_0)=\\text{sign}(θ⋅ϕ(θ)+θ_0)$\n",
    "- Regression: $f(x;θ,θ_0)=θ⋅ϕ(θ)+θ_0$\n",
    "\n",
    "More feature we add (e.g. more polynomial grades we add), better we fit the data. The key question now is **when is time to stop adding features?** We can use the validation test to test which is the polynomial form that, trained on the training set, respond better in the validation set. At the extreme, you hold out each of the training example in turn in a procedure called **leave one out cross validation**. So you take a single training sample, you remove it from the training set, retrain the method, and then test how well you would predict that particular holdout example, and do that for each training example in turn. And then you average the results. While very powerful, this mapping could dimensionally explode quickly. Let's our original $x∈R^d$. Then a feature transformation: - quadratic (order 2 polynomial): would involve $d+≈d^2$ dimensions (the original dimensions plus all the cross products) - cubic (order 3 polynomial): would involve $d+≈d^2+≈d^3$ dimensions (the exact number of terms of a feature transformation of order $p$ of a vector of d dimensions is:\n",
    "$$\n",
    "\\sum_{i=1}^p {d+i-1 \\choose i}\n",
    "$$\n",
    "\n",
    "#### Kernels: Computational Efficiency\n",
    "\n",
    ">  **Kernel Definition**: the kernel is an inner product of an arbitrary function of its arguments. $K(x,x^′)=⟨ϕ(x),ϕ(x^′)⟩$; an **inner product** associates each pair of vectors in the space with a scalar  quantity known as the inner product of the vectors. \n",
    "\n",
    "The idea is that you can take inner products between high dimensional feature vectors and evaluate that inner product very cheaply. And then, we can turn our algorithms into operating only in terms of these inner products. We define the kernel function of two feature vectors (two different data pairs) applied to a a given $ϕ$ transformation as the dot product of the transformed feature vectors of the two data:\n",
    "\n",
    "$$\n",
    "k(x,x^′;ϕ)∈R^+=ϕ(x)⋅ϕ(x^′)\n",
    "$$\n",
    "\n",
    "We can hence think of the kernel function as a kind of similarity measure, how similar the $x$ example is to the $x^′$ one. Note also that being the dot product symmetric and positive, kernel functions are in turn symmetric and positive. For example let's take $x$ and $x^′$ to be two dimensional feature vectors and the feature transformation $ϕ(x)$ defined as \n",
    "\n",
    "$$\n",
    "ϕ(x)=[x_1,x_2,x_1^2,\\sqrt2x_1x_2,x_2^2]\\\\\n",
    "ϕ(x^′) = [x_1^\\prime,x_2^\\prime,{x_1^\\prime}^2, \\sqrt2x_1^\\prime x_2^\\prime,{x_2^\\prime}^2]\n",
    "$$\n",
    "\n",
    "This particular ϕ transformation allows to compute the kernel function very cheaply and having very few dimensions:\n",
    "\n",
    "$$\n",
    "k(x,x′;ϕ)=ϕ(x)⋅ϕ(x′)=\\\\= \\displaystyle {x_1}{x_1^\\prime } + {x_2}{x_2^\\prime } + {x_1}^2{x_1^\\prime }^2 + 2{x_1}{x_1^\\prime }{x_2}{x_2^\\prime } + {x_2}^2{x_2^\\prime }^2=\\\\= \\displaystyle \\left({x_1}{x_1^\\prime } + {x_2}{x_2^\\prime }\\right)+ \\left({x_1}{x_1^\\prime } + {x_2}{x_2^\\prime }\\right)^2=\\\\= \\displaystyle x \\cdot x^\\prime + (x \\cdot x^\\prime )^2\n",
    "$$\n",
    "\n",
    "Note that even if the transformed feature vectors have 5 dimensions, the kernel function return a scalar. In general, for this kind of feature transformation function $ϕ$, the kernel function evaluates as \n",
    "\n",
    "$$\n",
    "k(x,x′;ϕ)=ϕ(x)⋅ϕ(x^′)=(1+x⋅x^′)^p\n",
    "$$\n",
    "\n",
    "where $p$ is the order of the polynomial transformation $ϕ$. However, it is only for *some* $ϕ$ for which the evaluation of the kernel function becomes so nice! As soon we can prove that a particular kernel function can be expressed as the dot product of two particular feature transformations (for those interested the *Mercer’s theorem* stated in [these notes](https://courses.cs.washington.edu/courses/cse546/16au/slides/notes10_kernels.pdf)) the kernel function is *valid* and we don't actually need to construct the transformed feature vector (the output of $ϕ$). The task will be to turn a linear method that previously operated on $ϕ(x)$, like $\\text{sign}(θ⋅ϕ(x)+θ_0)$ to an inter-classifier that only depends on those inner products, that operates in terms of kernels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Kernel Perceptron Algorithm\n",
    "\n",
    "Let's show how we can use the kernel function in place of the feature vectors in the perceptron algorithm.\n",
    "\n",
    "Recall that the perceptron algorithm (**written in PRIMAL form**):\n",
    "\n",
    "```python\n",
    "θ = 0                \t\t# initialisation\n",
    "for t in 1:T:\n",
    "\tfor i in 1:n>\n",
    "\t\tif yⁱ θ⋅𝛷(xⁱ) ≦ 0   # checking if sign is the same\n",
    "      \tθ = θ + yⁱ𝛷(xⁱ)   \t # update θ if mistake\n",
    "```\n",
    "\n",
    "Which is the final value of the parameter $θ$ resulting from such updates ? We can write it as\n",
    "\n",
    "$$\n",
    "\\theta^∗=∑_{n=1}^{j}α^{(j)}y^{(j)}ϕ(x^{(j)})\n",
    "$$\n",
    "\n",
    "where $α$ is the vector of number of mistakes (and hence updates) underwent for each data pair (so $α^{(j)}$ is the (scalar) number of errors occurred with the $j$-th data pair and can also be interpreted as the relative importance of the $j$-th training example to the final predictor). When we want to make a prediction of a data pair $(x^{(i)},y^{(i)})$ using the resulting parameter value $θ^∗$ (that is the \"optimal\" parameter the perceptron algorithm can give us), we take an inner product with that:\n",
    "\n",
    "$$\n",
    "\\text{prediction}^{(i)}=θ^∗⋅ϕ(x(i))\n",
    "$$\n",
    "\n",
    "We can rewrite the above equation as :\n",
    "\n",
    "$$\n",
    "\\theta^* \\cdot \\phi(x^{(i)}) = [\\sum_{j=1}^n \\alpha^{(j)} y^{(j)} \\phi(x^{(j)})] \\cdot \\phi(x^{(i)})\\\\~~=  \\sum_{j=1}^n [\\alpha^{(j)} y^{(j)} \\phi(x^{(j)}) \\cdot \\phi(x^{(i)})]\\\\~~=\\sum_{j=1}^n \\alpha^{(j)} y^{(j)}k(x^{(j)},x^{(i)})\n",
    "$$\n",
    "\n",
    "But this means we can now express success or errors in terms of the $α$ vector and a valid **kernel function** (cheap to compute!). An error on the data pair $(x^{(i)},Y^{(i)})$ can then be expressed as $y^{(i)} * \\sum_{j=1}^n \\alpha^{(j)} y^{(j)}k(x^{(j)},x^{(i)})$. We can then base our perceptron algorithm on this check, where we start with initiating the error vector $α$ to zero, and we run through the data set checking for errors and, if found, updating the corresponding error term. In practice, our endogenous variable to minimize the errors is no longer directly $\\theta$, but became the $α$ vector, that as said implicitly gives the contribution of each data pair to the $θ$ parameter. The perceptron algorithm becomes hence the **kernel perceptron algorithm**:\n",
    "\n",
    "(**written in DUAL form**)\n",
    "\n",
    "**Kernel Perceptron** $\\displaystyle \\left(\\big \\{ (x^{(i)}, y^{(i)}), i=1,...,n, T \\big \\} \\right)$<br>\n",
    "  initialize $α_1,...,α_n$ to some values;<br>\n",
    "  for $t=1,...,T$<br>\n",
    "    \tfor $i=1,...,n$<br>\n",
    "      \tif (*Mistake Condition Expressed* in $α_j$)  \\# checking **if** prediction is right<br>\n",
    "        Update $α_j$ appropriately  **# update $α_{j}$ if mistake**\n",
    "\n",
    "Where the mistake condition expressed in $\\alpha_j$ is $y^{(i)}\\sum _{j=1}^{n} \\alpha _ j y^{(j)} K(x^{j},x^{i}) \\leq 0$ and the update condition is $\\alpha_j = \\alpha_j +1$. **In this case, in order to update, you only use the kernel function, and increment $\\alpha$ accordingly**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Composition Rules\n",
    "\n",
    "Now instead of directly constructing feature vectors by adding coordinates and then taking it in the product and seeing how it collapses into a kernel, we can construct kernels directly from simpler kernels by made of the following **kernel composition rules**:\n",
    "\n",
    "1. $K(x,x^\\prime) = 1$ is a valid kernel whose feature representation is $\\phi(x) = 1$;\n",
    "2. Given a function $f: \\mathbb{R}^d \\to \\mathbb{R}$ and a valid kernel function $K(x,x^\\prime)$ whose feature representation is $\\phi(x)$, then $\\tilde K(x,x^\\prime)=f(x)K(x,x^\\prime)f(x^\\prime)$ is also a valid kernel whose feature representation is $\\tilde \\phi(x) = f(x)\\phi(x)$\n",
    "3. Given $K_a(x,x^\\prime)$ and $K_b(x,x^\\prime)$ being two valid kernels whose feature representations are respectively $\\phi_a(x)$ and $\\phi_b(x)$, then $K(x,x^\\prime)=K_a(x,x^\\prime)+K_b(x,x^\\prime)$ is also a valid kernel whose feature representation is $\\phi(x) = \\array{\\phi_a(x)\\\\phi_b(x)}$\n",
    "4. Given $K_a(x,x^\\prime)$ and $K_b(x,x^\\prime)$ being two valid kernels whose feature representations are respectively $\\phi_a(x) \\in \\mathbb{R}^A$ and $\\phi_b(x) \\in \\mathbb{R}^B$, then $K(x,x^\\prime)=K_a(x,x^\\prime) * K_b(x,x^\\prime)$ is also a valid kernel whose feature representation is $\\phi(x) = \\array{\\phi_{a,1}(x)* \\phi_{b,1}(x)\\\\phi_{a,1}(x)* \\phi_{b,2}(x)\\ \\phi_{a,1}(x)* \\phi_{b,...}(x)\\ \\phi_{a,1}(x)* \\phi_{b,B}(x)\\ \\phi_{a,2}(x)* \\phi_{b,1}(x)\\ \\phi_{a,...}(x)* \\phi_{b,...}(x)\\ \\phi_{a,A}(x)* \\phi_{b,B}(x)\\}$ (see [this lecture notes](https://people.cs.umass.edu/~domke/courses/sml2011/07kernels.pdf) for a proof)\n",
    "\n",
    "Armed with these rules we can build up pretty complex kernels starting from simpler ones.\n",
    "\n",
    "For example let's start with the identity function as $\\phi$, i.e. $\\phi_a(x) = x$. Such feature function results in a kernel $K(x,x^\\prime;\\phi_a) = K_a(x,x^\\prime) = (x \\cdot x^\\prime)$ (this is known as the **linear kernel**). We can now add to it a squared term to form a new kernel, that by virtue of rules (3) and (4) above is still a valid kernel:\n",
    "\n",
    "$K(x,x^\\prime) = K_a(x,x^\\prime) + K_a(x,x^\\prime)* K_a(x,x^\\prime) = (x \\cdot x^\\prime) + (x \\cdot x^\\prime)^2$\n",
    "\n",
    "#### The Radial Basis Kernel\n",
    "\n",
    "We can use kernel functions, and have them in term of simply, cheap-to-evaluate functions, even when the underlying feature representation would have infinite dimensions and would be hence impossible to explicitly construct.\n",
    "\n",
    "One example is the so called **radial basis kernel**:\n",
    "$$\n",
    "K(x,x^\\prime) = e^{-\\frac{1}{2} ||x-x^\\prime||^2}\n",
    "$$\n",
    "\n",
    "It [can be proved](http://pages.cs.wisc.edu/~matthewb/pages/notes/pdf/svms/RBFKernel.pdf) that suck kernel is indeed a valid kernel and its corresponding feature representation $\\phi(x) \\in \\mathbb{R}^\\infty$, i.e. involves polynomial features up to an infinite order. The radial basis kernel look like a Gaussian (without the normalization term).\n",
    "\n",
    "The above picture shows the contour lines of the radial basis kernel when we keep fixed $x$ (in 2 dimensions) and we let $x^\\prime$ to move away from it: the value of the kernel then reduces in a shape that in 3-d would resemble the classical bell shape of the Gaussian curve. We could even parametrize the radial basis kernel replacing the fixed $1/2$ term with a parameter $\\gamma$ that would determine the width of the bell-shaped curve (the larger the value of $\\gamma$ the narrower will be the bell, i.e. small values of $\\gamma$ yield wide bells).\n",
    "\n",
    "Because the feature has infinite dimensions, the radial basis kernel has infinite expressive power and can correctly classify any training test.\n",
    "\n",
    "The linear decision boundary in the infinite dimensional space is given by the set ${x: \\sum_{j=1}n \\alpha^{(j)} y^{(j)} k(x^{(j)},x) = 0 }$ and corresponds to a (possibly) non-linear boundary in the original feature vector space.\n",
    "\n",
    "The more difficult task it is, the more iterations before this kernel perception (with the radial basis kernel) will find the separating solution, but it always will in a finite number of times. This is by contrast with the \"normal\" perceptron algorithm that when the set is not separable would continue to run at the infinite, changing its parameters unless it is stopped at a certain arbitrary point.\n",
    "\n",
    "#### Other non-linear classifiers\n",
    "\n",
    "We have seen as we can have nonlinear classifiers extending to higher dimensional space and eventually using kernel methods to collapse the calculations and **operate only *implicitly* in those high dimension spaces**. There are other ways to get nonlinear classifiers.\n",
    "\n",
    "**Decision trees** make classification operating sequentially on the various dimensions and making first a separation on the first dimension and then, in a subsequent step, on the second dimension and so on. And you can \"learn\" these trees incrementally. To make these decision trees more robust, **random forest classifiers**, adds two type of randomness: 1) in randomly choosing the dimension on which to operate the cut and 2) randomly selecting the single example on which operate from the data set (with replacement) and then just average the predictions obtained from these trees.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Recommender Systems\n",
    "\n",
    "#### Problem definition\n",
    "\n",
    "We keep as example across the lecture the recommendation of movies. We start with a $(n,m)$ matrix $Y$ of preferences for user $a = 1,...,n$ of movie $i = 1,...,m$. While there are many ways to store preferences, we will use a real number. The goal is to base the prediction on the prior choices of the users, considering that this $Y$ matrix could be very sparse (e.g. out of 18000 films, each individual ranked very few of them!), i.e. we want to fill these \"empty spaces\" of the matrix. Why not to use classification/regression based on feature vectors as learned in Lectures 1? For two reasons:\n",
    "\n",
    "1. Deciding which feature to use or extracting them from data could be hard/infeasible\n",
    "2. Often we have little data about a single users preferences, while to make a recommendation based on its own previous choices we would need lot of data.\n",
    "\n",
    "The \"trick\" is then to \"borrow\" preferences from the other users and trying to measure how much a single user is closer to the other ones in our dataset.\n",
    "\n",
    "#### K-Nearest Neighbor (KNN) Method\n",
    "\n",
    "The number $K$ here means, how big should be your advisory pool on how many neighbors you want to look at. And this can be one of the hyperparameters of the algorithm. We look at the $k$ closest users that did score the element I am interested to, look at their score for it, and average their score.\n",
    "\n",
    "$$\n",
    "\\hat Y_{a,i} = \\frac{\\sum_{b \\in KNN(a,i;K)} Y_{b,i}}{K}\n",
    "$$\n",
    "where $KNN(a,i;K)$ is the set of K users close to user a that have a score for item $i$. But how do I define this similarity? We can use any method to define similarity between vectors, like cosine similarity ($\\cos \\theta = \\frac{x_ a\\cdot x_ b}{\\left| x_ a \\right| \\left| x_ b \\right| }$) or Euclidean distance ($\\left| x_ a-x_ b \\right|$).\n",
    "\n",
    "We can make the algorithm a bit more sophisticated by weighting the neighbor scores to the level of similarity rather than just take their unweighted average:\n",
    "\n",
    "$$\n",
    "\\widehat{Y}_{ai} = \\displaystyle \\frac{\\displaystyle \\sum _{b \\in \\text {KNN}(a)} \\text {sim}(a,b) Y_{bi}}{\\displaystyle \\sum _{b \\in \\text {KNN}(a)} \\text {sim}(a,b)}.\n",
    "$$\n",
    "where $sim(a,b)$ is some similarity measure between users $a$ and $b$. There has been many improvements that has been added to this kind of algorithm, like adjusting for the different \"average\" score that each user gives to the items (i.e. they compare the deviations from user's averages rather than the raw score itself). Still they are very far from today's methods. The problem of KNN is that it doesn't enable us to detect the hidden structures that is there in the data, which is that users may be similar to some pool of other users in one dimension, but similar to some other set of users in a different dimension. on top, this method depends heavily on the *choice of the similarity measure*.\n",
    "\n",
    "#### Collaborative Filtering: the Naïve Approach\n",
    "\n",
    "Let's start with a naïve approach where we just try to apply the same method we used in regression to this problem, i.e. minimize a function $J$ made of a distance between the observed score in the matrix and the estimated one and a regularization term. For now, we treat each individual score **independently**, and this will be the reason for which (we will see) this method **will not work**.\n",
    "\n",
    "So, we have our (sparse) matrix $Y$ and we want to find a dense matrix $X$ that is able to replicate at best the observed points of $Y_{a,i}$ when these are available, and fill the missing ones when $Y_{a,i} = missing$. Let's first define as $D$ the set of points for which a score in $Y$ is given: $D = {(a,i) | Y_{a,i} \\neq \\text{missing}}$. The $J$ function then takes any possible $X$ matrix and minimize the distance between the points in the $D$ set less a regularization parameter (we keep the individual scores to zero unless we have strong belief to move them from such state):\n",
    "\n",
    "$$\n",
    "J(X;Y,\\lambda) = \\frac{\\sum_{(a,i) \\in D} (Y_{a,i} - X_{a,i})^2}{2} + \\frac{\\lambda}{2}\\sum_{(a,i)} X_{a,i}^2\n",
    "$$\n",
    "To find the optimal $X_{a,i}^* ~$ that minimize the FOC $(\\partial X_{a,i} / \\partial Y_{a,i}) = 0$ we have to distinguish if $(a,i)$ is in $D$ or not:\n",
    "\n",
    "- $(a,i) \\in D$: $X_{a,i}^* = \\frac{Y_(a,i)}{1+\\lambda}$\n",
    "- $(a,i) \\notin D$: $X_{a,i}^* = 0$\n",
    "\n",
    "Clearly this result doesn't make sense: for data we already know we obtain a bad estimation (as worst as we increase lambda) and for unknown scores we are left with zeros.\n",
    "\n",
    "#### Collaborative Filtering with Matrix Factorization\n",
    "\n",
    "What we need to do is to actually relate scores together instead of considering them independently. The idea is then to constrain the matrix $X$ to have a lower rank, as rank captures how much independence is present between the entries of the matrix.\n",
    "\n",
    "At one extreme, constraining the matrix to be rank 1, would means that we could factorize the matrix $X$ as just the matrix product of two single vectors, one defining a sort of general sentiment about the items for each user ($u$), and the other one ($v$) representing the average sentiment for a given item, i.e. $X=uv^T$.\n",
    "\n",
    "But representing users and items with just a single number takes us back to the KNN problem of not being able to distinguish the possible multiple groups hidden in each user or in each item. We could then decide to divide the users and/or the items in respectively $(n,2) U$ and $(2,m) V^T$ matrices and constrain our X matrix to be a product of these two matrices (hence with rank 2 in this case): $X=UV^T$\n",
    "\n",
    "The exact numbers $K$ of vectors to use in the user/items factorization matrices (i.e. the rank of X) is then a hyperparameter that can be selected using the validation set.\n",
    "\n",
    "#### Alternating Minimization\n",
    "\n",
    "Using rank 1, we can adapt the $J$ function to take the two vectors $u$ and $v$ instead of the whole $X$ matrix, and our objective becomes to found their elements that minimize such function:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{u},\\mathbf{v}; Y, \\lambda) = \\frac{\\sum_{a,i \\in D} (Y_{a,i} - u_a * v_i)^2}{2} + \\frac{\\lambda}{2}\\sum_a^n u_a^2 + \\frac{\\lambda}{2}\\sum_i^m v_i^2\n",
    "$$\n",
    "How do we minimize $J$? We can take an **iterative approach** where we start by randomly sampling values for one of the vector and minimize for the other vector (by setting the derivatives with respect on its elements equal to zero), then fix this second vector and going minimize for the first one, etc., until the value of the function $J$ doesn't move behind a certain threshold, in an alternating minimization exercise that will guarantee us to find a local minima (but not a global one!).\n",
    "\n",
    "Note also that when we minimize for the individual component of one of the two vectors, we obtain derivatives with respect to the individual vector elements that are independent, so the first order condition can be expressed each time in terms of a single variable.\n",
    "\n",
    "#### Numerical example\n",
    "\n",
    "Let's consider a value of $\\lambda$ equal to $1$ and the following score dataset:\n",
    "\n",
    "$Y = \\begin{bmatrix}5 & ? & 7 \\\\ 1 & 2 & ?\\end{bmatrix}$\n",
    "\n",
    "and let start out minimization algorithm with $v = [2,7,8]$\n",
    "\n",
    "L becomes:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{u}; \\mathbf{v}, Y, \\lambda) = \\frac{(5-2u_1)^2+(7_8u-1)^2+(1-2u_2)^2+(2-7u_2)^2}{2}+\\frac{u_1^2+u_2^2}{2}+\\frac{2^2+7^2+8^2}{2}\n",
    "$$\n",
    "From where, setting $\\partial L/\\partial u_1 = 0$ and $\\partial L/\\partial u_2 = 0$ we can retrieve the minimizing values of $(u_1,u_2)$ as 22/23 and 8/27. We can now compute $J(\\mathbf{v}; \\mathbf{u}, Y, \\lambda)$ with these values of $u$ to retrieve the minimizing values of $v$ and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Neural Networks\n",
    "\n",
    "Neural networks are, in a way, stacks of nonlinear \"classifier\" units built on top of each other. Each \"neuron\"/unit of a neural network takes as input a linear combination of the outputs of the layer behind it, performs some nonlinearity on this linear combination, and emits the result as an output. In a way, each layer forms a new feature mapping (of possibly different dimension) based on the previous layer A neural network unit computes a non-linear weighted combination of its input:\n",
    "\n",
    "$$\n",
    "\\displaystyle  f(z)\\quad \\text {where } z= w_0 + \\sum _{i=1}^ d x_ i w_ i \\\\\t f(z)\\quad \\text {where }  z = w_0+x⋅w,\n",
    "$$\n",
    "\n",
    "where $x=[x_1,…,x_d]$ and $w=[w_1,…,w_d]^T$ and where $w_i$ are numbers called **weights**, $z$ is a number and is the weighted sum of the inputs $x_i$, and $f$ is generally a non-linear function called the **activation function **.\n",
    "\n",
    "Recall the **hyperbolic tangent function** is defined as\n",
    "\n",
    "$$\n",
    "\\displaystyle \\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}=1-\\frac{2}{e^{2z}+1}.\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/QAAAM1CAYAAADekbpzAAAgAElEQVR4nOzde3xjdZ3/8XdhRhhkbAbwxiDNKMMC6jTjDXZXaSsgiKvNULwtYFtX8YY2dVddXH829Qbetqm3VVxtKqi76kxTFVRcaAa8gKhNhx1BRmkGBkFh4AysU7lIf398eiaXJm3SJj05yev5eOTRkzTn5NvpiPM+n8/3+22anZ2dFQAAAAAA8JWDvB4AAAAAAAAoH4EeAAAAAAAfItADAAAAAOBDBHoAAAAAAHyIQA8AAAAAgA8R6AEAAAAA8CECPQAAAAAAPkSgBwAAAADAhwj0AAAAAAD4EIEeAAAAAAAfItADAAAAAOBDBHoAAAAAAHyIQA8AAAAAgA+t8noAQDWkUtL27ZLjSMmkFAxKoZDU2WnHi3EcaXzcrpNKSYGAnd/eLrW1VX/88Jm9aen+3dLGGvnLsSclHRPyehQAAACosqbZ2dlZrwcBVEoyKQ0O2tdi2tulkZHiwX5wUIrFLNQXEgxKQ0NSOLz88cLH9qalrf3SrqQ0k/WXZVNY6hqSjizhzlExM460a/vc9TpLPy85LF0ZtfPXBKS+CYI9AABAHaPlHnXBcaTeXqmjQ5qclPr67OvsrD2mp606L1nY37zZKu/519iyRYpGpdZWaWwsc/7srDQxIXV3S+m0vS8eX/mfEzXihrg0sEHaNWGB++wBqb3PvrcjIV262b4uxd60nX9Z2B7DHaWdNxGTvhPJ3FyYcezcmSJ3pgAAAOB7VOjhe45jQT6VstAej1uLfCHhsLXSS/aeiQlrpZfsGsmkhfZCYT2RsOp99o2A6enSWvhRR26IS1f0SutbpUjSKuGuy3ukG0fteE1A+tfJ8iv12ddwfa6E/0y/Z13h8H7+iHRKT3ljAAAAgC9QoYevZYf5gQEL3cXCvGSt9Nnn9vfbcTS6cJiPx60qn1/VX6i1H3VoR8LC/MY26eJUbpiXcsP7jGNV83Llh/k1zYufM+MUr8TvSRV+HQAAAL5HoIevuSF7YMBC+WKCQWundyWTFtYHB6Xm5tzA70qnM8G/0PfQIGYc6fJeC9gXlthOf/N4eZ+xq8Adoo3ti5+3JlB8Qb67CPQAAAD1ikAP34rFLJC3tZUW5l35Ffze3sz1ClX3U6mFF8hDg3Dnp3fF5lfmXXvTCz9fzFIDvWQ3Gda3Lv4+AAAA1A0CPXwpnc5U1SuxOF1zs9RTZJpxsTDf0sJK9w1jb9pa4Y9oWXg++u+2L+9zlhPo1wTm5vTnteiXej4AAAB8h0APX4pGLWhHIuVXyfftm/9asTAvWWhvacl9rbl58fn6qCPuXPiOSPH37EnNr8iXuy/9rrwbAmuay9t2bk3AOggAAADQEFZ5PQCgXOm0NDpqoTqyQL4qJn9hO8n2pi8mELBzYjH77FDIbgAQ5huIu1DdQtX5Gwq0imwqo4VjOdX5bK1haWtEmtm39GsAAADAFwj08J3E3Hpk4XD5obpQmHevtZBAoLx5+qgjOxI2d35TZ/G589L81eklbwL9moBV9d1q/xEs9AAAAFCvaLmH77iBfqE2+WIKBfq2Mrui0WBumwvaC4VzN/Rn29RZ3h70lQr02eetaS5vDAAAAPAVKvTwnXDY5s0v1CZfTKF945dyHTSQY0IWzlsXCPTLbbeXlj9/vhDa7QEAAOoagR6+s5R5866pqfmvEeixoFN6Fp47P+NIO/L2m1/TvPANgHyVrM5nW+4NAQAAANQ0Wu7RMByn/AXxgEVNJea/tim88Hz7fJUO9O71qNADAADUNQI9Gkahdnvmz2PZdhQI9OVU56XKB/r7dy//GgAAAKh5BHo0DObPo+IKtdsf0eLt/Pm9aXts6lza+QAAAPANAj0axvbt818j0GNZirXbl4N2ewAAACwRgR4NgfnzqIpC7fbHl/mXqtKB3h1TuTcWAAAA4DsEejSEQu32ra0rPw7UmUKt8p5X6Ldb2z/7zwMAANQ9Aj0aQqJAIZXqPJZlT8rm0GdbShCv5Pz5HQkbE9V5AACAhkCgR0Ng/jwqrhKV9UpX5905/af0LP0aAAAA8A0CPepeOm2PfOElFDFjMamjw+bko8HtKbAoQ7mV9b0F/mIutTrvrrh/RMvSrwEAAABfWeX1AIBqq+T+84ODhHnMub8CYbzQNZZaoZ+aa7c/e2Bp5wMAAMB3qNCj7hUK9KElFDATCQvzra1SILD8caEOrfHwL8YPBu0r7fYAAAANg0AP3xketrb3jg47Xsz4+PzXljJ/Ph63r5FI+ecCJTtiCavT70pa+/7J3d7eVAAAAMCKouUevuE4FuKz95NPJqXZ2eIhO5Uq3CIfLDMzJZN2Y6ClReqhAAppLngXWG2xHPkr3EvzV84vxVVz1fmzo8sbDwAAAHyFCj18IxrNDfOuQlvSuWKxwq+X23I/OLjw9dCACs11LyeM70oWXuW+3EB/Q9yu097H3vMAAAANhkAP3xgdLfx6sfns6bSd09y8vM+NxaxC39m5tJXxUadaC/xlmFrg7lI+t6q+Ju8vaKHV84uZcaSt/bay/SuozgMAADQaAj18wXGKry5fLGT399vXSMQWsstWaKG8QpJJu05LS2YOPSDJ5qq39+W+dmORu075ropaVX1T5/w2+VKvMeNIwx329YI4c+cBAAAaEIEevlCsCt/dXXhOeyxmrfitrdaqn98qv1Cbvisel7ZssQp/IsHK9ijgFVFpfdbdol1JaWKReRk3xK06v6bZgnhHJPcae1KLX8MN83tS0vkjS9/qDgAAAL5GoIdvdHdnjltbpaGhwlXz4WGrqjc3Zyrx7e255w8PF56PL1knQH+/1NtrC+4lk0vb5g4NYE1AiiRzA/nWfumKXlt1PpvbHn9Fr4X5vmSmql7oGlcNzp9PP+PY6x/ckAnzbFMHAADQsJpmZ2dnvR4EUArHsWA+NWXV8p6e3Hb7dNoCfjJpgT+RmL+afU9PZi5+IGDt+O4Wdo5j58bjmf3mk0kq8yjRVVGrrM/sy7y2JiAdE5LuT2cC/sY26fx44QXsCl3jmFAm+LuL6K1vlc6NUZkHAABocAR6+IrjWPt8LCbt2zf/+83NFtqj0eJBPJGw709NFf5+W5tdg+3psCQ7ElY9d8P3fkc6LGCh/JQeadMiKyvOOLa43p6UdFdeG8kRQVuMb7FrAAAAoCEQ6OFbyWTuPvOhkFXbS62op1J2Dfd891za6wEAAAD4AYEeAAAAAAAfYlE8AAAAAAB8aJXXA8DKSZa6+ToA1Jj2dhYABAAAyEegbyC//OUvNTw87PUwAKAsn/70p70eAgAAQE1iDj0AAAAAAD7EHHoAAAAAAHyIQA8AAAAAgA8R6AEAAAAA8CECPQAAAAAAPkSgBwAAAADAhwj0AAAAAAD4EIEeAAAAAAAfItADAAAAAOBDBHoAAAAAAHyIQA8AAAAAgA8R6AEAAAAA8CECPQAAAAAAPkSgBwAAAADAhwj0AAAAAAD4EIEeAAAAAAAfItADAAAAAOBDBHoAAAAAAHyIQA8AAAAAgA8R6AEAAAAA8CECPQAAAAAAPkSgBwAAAADAhwj0AAAAAAD4EIEeAAAAAAAfItADAAAAAOBDBHoAAAAAAHyIQA8AAAAAgA8R6AEAAAAA8CECPQAAAAAAPkSgBwAAAADAhwj0AAAAAAD4EIEeAAAAAAAfItADAAAAAOBDBHoAAAAAAHyIQA8AAAAAgA8R6AEAAAAA8CECPXwnmZS2bJHWrZOamuyxbp3U2yul04XPSaft+4XOSaVWdvwAAAAAUAkEeviG41iQ7+iQHnhAGhqSJiaksTGprU2Kx6UNG+xrtkRC2rxZmp7OnDMxIfX12dfNm+efAwAAAAC1rml2dnbW60EAi0mnLcjPzlr4bm+f/55wWBoft+OxMXueTNp53d3zQ3s0Kg0P242CQMACfyBQ/Z8FAAAAACqBQI+a5ziZMJ9MFg/dbniXpGBQmpy0in1bm1Xps0UiFuazTUwUvlGA+VIpad++3Neam6VQyJvxAAAAAI2IQI+a51baUykL6gtpasocB4PWmp9/nuPY/Pl8BPr5HMe6HlIpeyST9nowWHy9gkDAgn1np91Q6excufECAAAAjYRAj5qWSNi8ebeFfjHZgV4q3GqfStm8+WzNzRZekQnxsVjlFgwMh+3R3V2Z6wEAAAAg0KPGBYP2cCvDCylUeZ+cLNwG3t4ubd9ux83Ndv1GbxdPp6XBQbt5kt9O39Zmf2bu78N95J+fTttNgHTa/kynpnLf09JiOwv09bFeAQAAALBcBHrUrHjcwl+p1fnsOfSShcdibeHu+yUL8ssNl6mU3SDo61vedbzgBvnsTobm5kxVvZQ/+2Icx7osEonMgoWS/XlHIgR7AAAAYDkI9KhZ4XCm2luKaNSCqauzc/5ieNUQi9nnOk7xjoBaNThoW/m5FfmWFgvaPT2VD9rptN00iMVyPy8WW95NAwAAAKBRsQ89alYwaOGyVPnzvau5wF06bavkb9gg9fdn5t/7ZR6+uw1gNGrhurlZGhmx1yOR6lTNg0H7vHRaGhiw1/btszUSenv982cHAAAA1Aoq9KgbgUDu3O9KVsvjcWl01I6z5/O3tWXm4kv+WCk/kcgN0H19FrRXuvU9nbZOAPfPLxSymwp+6nAAAAAAvESFHnUhnc4N89XYE3121h4DAzav/4EHLAj7ibsugePYn9HYmLW8ezGP3V3scGjInqdSVq2v1Mr6AAAAQL1b5fUAgErIXwW/0lXynh57+Jkb5iWptdUq9fkr1XshErHfV3t7ZirA2FjtdzoAAAAAXqNCj7pQ7UDvd/lhPpmsjTDvCoVsTK2t1j1ApR4AAABYHIEedYFAX1w8npka4Ib5WtwqLj/Uu7scAAAAACiMQA/fS6Wk3bszz6sxf96vUilbhX/37toO865AwKYCNDfbmLdsYfV7AAAAoBgCPXyP6nxhjpO7AF6th3mXu1ieZHPq3akCAAAAAHIR6OF7ywn0kcj88+tFNJppWU8k/BHmXaFQZvX7RMIeAAAAAHIR6OF7Sw30qZQ0PGxV4HqTTErj43Y8MODProVIRGprsxsR/f203gMAAAD5CPSoacnkwoE7lVr6/vOxmH0Nh5c+vlo1OGh/bi0tmQXx/Cgel2Zn7Wdxf18AAAAADIEeNSkel9atsz3JN2yw58Xel63UMO84VsHu7vZXK3opkslM10KxPze/CAatUi9lblIAAAAAMAR61JxUKrOYm6tYMM2fW11qOI9ErPLr5+p1MYOD9rWtzZ+t9vkiEeu8kOrz9wUAAAAsFYEeNafUqnI8blubuWFPKm2edSIhjY5aOAwGlzbGWpVKZRbCq5fwGwhkqvTj48ylBwAAAFwEetQcN5BmcwOdy3FsobS2tty51dn70Re7dm+vtdrnX7MexGL2Z9PSUh/VeZf7u3IcVrwHAAAAXAR61JzsReqam6WRkdzXHMfm1s/OWpW+p8eCvWRzrBdqz+/okFpb/T+3vBh3Zft6u1kRCNhNGMm6KwAAAAAQ6FGDenosdEvSli22OF46bdX10VFp82ZpetoWfnNb5hOJzDm9vTaP3G0/Hx21IL9li4XCet13PpHItKPX48r97s+UTNJ2DwAAAEgEetSgQMCC+MCANDFhQW7DBgvyfX1WjU+nc1e0d88ZGcls1bZ5sz16euy1ycn63vrMvVHR2lp/awNIuTcp6vWmDAAAAFAOAj1qVjRqwf2BByzYT05aZTYeL76afU+PnTM9bedMT2da80vd0s6vtm+3r/VYnXe5UysI9AAAAIC0yusBAIsJBMpf4C0YrM8q9ULcxQTr+cZFe7vduCi0cCIAAADQaKjQA3UgO+DWc6B3fza3GwEAAABoZAR6oA5kLxJXz50J2VMt0mnvxgEAAADUAgI9UAeyF8SrZ9lTLwj0AAAAaHQEeqCOFFssEAAAAED9IdADS5RKScPDua+NjlI5BgAAALAyWOUeKFFT0+LvicftkW92tvLjAQAAANDYCPRAiQYGvB4B9IMhfWjTA/rgjg95PRIAAADAcwR6oETRqNcjKK4h5s5vG5S2RvX/niM99OhaSe/xekQAAACAp5hDD9QBd6u6ut6f/ZwB7X/2OZKkT2x+r46+5UseDwgAAADwFoEeqAPZFfrsPenrzS/+bqt+fM8ZkqTjf/JW6Wff9HhEJdiTknZtl2ZW8Bcz46z8ZwIAAGDFEeiBOhAKZY5TKe/GUW3JpNR13ValHjrZXvj8P0qTV3o7qEJmHOmqQemiJunSzdJwu/SeddJlW5YWsm8ctevtSi7+3hvi0gc32Gdeulnay7YLAAAA9YpAD9SBQEBqabHjeg70qZT00GNr9ZmDt0nrT7QXY+dIt17n7cCyzTjScId0w4h0/oj0yQekwWlpTbO0I2HfKyfUXxWVLu+xr4uduyspXdGbec/etJ0HAACAukSgB+pEe7t9TZZQxPWrqSn7uqntaCmyTTpivfTYI1KsS9pdA3cy3DA/OytdnJJO6ZHWBKQjg9LGuV/QnpR0ZRkhe2K49PcWquDvGC/9fAAAAPgKgR6oE26gH6/T/JZKSem0dSOEw5KOPsFC/ZonSQ/dZ5X6P93u7SCvjEp7p6ULExbks2U/v7nEX9KeVG5F/oiW+dfNdkxo/mvMowcAAKhbBHqgToTDmeNEwrtxVEs8bl+bmzOr+utZL5IiW+34T9MW6h+6z5PxaVdSSg5LHRGryOe7P2sue6nz2vMr7m6Vv5hNYWvzBwAAQEMg0AN1IhCQ2trsuB4Dvdt5kH3jQpL0nNOtUi9Ju6ekoXOkxx5e0bFJskXr1jRLZxdop3dXnS9XuYFesjb/TZ3lfxYAAAB8h0AP1JFIxIL96Ki1p9eLRCLz80QiBd7wwi3SW+ZK+L+9XhrqWrGxSbKK+66kVecLmcq7w1Jq4M6/CVBKoJekrljWOW2lnQMAAADfIdADdSQctvXYJClaR4ubD8+tC9fZmdVun+/Ubqn7M3aculL63OtXZGySbPV6STq5p/D3bxzNfb4pv82ggELz5wu18hdyZFBa3zp3Xonn5JtxbArBjjps9wAAAKgTBHqgzrgV7Hqp0ieTmZX7C1bns73sndJrPmLHP/8v6StvqerYDtiRsABdKHC71ftsrSUE+qW022dzF8grtFBeKZ893CF9JyJNxBZ/PwAAADxBoAfqTCRiC8dJ9VGl7+21r21tmZX8F9T5b9Ir32fH114mfeM9VRvbAZvC0rlFgm9+hXtT58Ir1Rc7r9xA795cKDXQu4v6DXfYY08NbAMIAACABRHogToTCFiQd+fS+3lf+lgs02VQ1s2J110qnf42O77yU9LYhys+thwdkeKBO5m3j/wpRdry8y11/rzLXUl/ofOG26WLmuzhVuTXNFt7PwAAAGreKq8HAKDyIhHb5s1xrMI9OWkB309SKWlw0Mbd3V1idT5b7xekmQeln35d+s4HpTVrpbMW69mvsD2p3C3q1jSXNn8+v92+nPnzrrumFl8Q7+SeTODf2G7V/DUBC/r37y7v8wAAALDiCPRAnYrHpc2brcLd2yuNjXk9otK5NyIcR2ppWcbUgbdfYaH+19+TLu+X1jxJantjRce6oBviuc9LCfPS8ufPzzh2M+HsgYXfV2q3AAAAAGoSLfdAnQqFpKEhO04krH3dL3p7rUIv2diX1V3Qv006cS4QX/ZP0o3fWfb4SnbzeO7zUhbDk5Yf6N3zS72BAAAAAF8i0AN1LBKR+vrsuL/fqva1rrfXQrwkjYzYjYllOWiVhfrg8+z5Z14t7fjRMi9agr3ppbXbS8ufP39b0j5vKSvcAwAAwDcI9ECdi8Wk1rktyXt7azvUZ4+vu1vqqVRH+BPXWah/6nH2PNYl7fp5hS5exLzV7ZdYnV/K/Pmbx6nOAwAANAACPdAAksncUD88vPD7vZAf5it+4+GoFgv1zU+VHv6zhfo9Oyv8IVmW2jafv11cudV5dyG+Utv7AQAA4FsEeqABBAK5oT4SySw657V02hbvq2qYdz3juVJkq/SENZJztxQ7R9p7Z3U+666p3Oeltr8vN9BPxMpr7wcAAIBvEeiBBuGG+u5ue+6ugp9KLXxeNSUSmTG0tEgDAyswJeD4v5ci2+z47tss1O+vwp2N7PnzUumB/v6888ppt59xpB3jth0dAAAA6h6BHmgggYAFZnf1e7c6vtLV+nRa6uiQtmyxz21utrn+S96erlytZ0nv/G87vv2X1n4/+/gKfXiZylnYbiphob4jUr3xAAAAoGYQ6IEGFIlIk5NSW5s9j8elDRukwcHqBvt02m4ebNhg3QKSjSGdlsIr3SF+ymukN33ZjndeKw2ds8IDKNGaMvbs+8GgtKmz/EX0AAAA4EsEeqBBhUIWqgcGrELuOFYhX7fOQvf4+OLXKNX4uFXjN2zItNS3tkpjYzaGZe0zvxwdb5LO+7Qd/2pc+o83VO7aG9vKP2dPav6WdfmL6xVzVdTa/M9eqTYHAAAAeI1ADzS4aNQq5G6wlyx0h8OZcD86Wt5c+1TKVtLfssWuEQ5LExP2vZYW218+lfKgKl/I2e+WuuZC8E8ul+IXVea6+YvS5S92V8jW/vmvzZTQMrE3LU0MS+197D0PAADQQJpmZ2dnvR4EgNrgOBbm43Fpaqrwe0Kh4hX1dNoehXR3S+3tFdxbvtK+/s/SVf9ux6+6WHrtx5Z3vRlH+mBQmtlnz0/uli5YYMW/G+LSFb3ShWPSdyLS/bvt9Y3tUt/Ewp8z3CHNzkqRZHkt+sUMt2c6BTa2SX0ldgkAAABgRRHoARSUTtsq9Mlkbvt9c7O0b9/i57e0WPgPh+3hWVt9Of7zzdLEf9rxaz9mwX45diSky7Zknp8/Ip1S4I6GG+bd0L8nZaHavRlwbsyq7/l2Ja2qv3da+tdU5ebOE+gBAAB8gUAPoCSplIX87NZ7d2G7YNAeklXhs5/7zmdfK93wLTvu+Zx0xjuWd71dSenyntyKe2tYWh+S7kpJtyUt+OdX8PekpMvCmfM2ha2dfmO7XfP+tN0I2NgmXZioTGXeRaAHAADwBQI9AOT7xNnS1A/s+G1fk158wfKveUPcgvueVCakS9L6VukV0flz7vPP25XMVOwlW81+U7hwxX+5CPQAAAC+QKAHgHyPzEiXnCHd9lN7/u4x6fm1sILfCiHQAwAA+AKr3ANAvieskfq3Sc94rj0f6rK96gEAAIAaQqAHgEKe9BQL9Ue1SLOPS7Eu6fZfej0qAAAA4AACPQAU89TjLNQffoS035Fi50h33+b1qAAAAABJBHoAWFjweVJkq3TwKmnvnRbqnbu9HhUAAABAoAeARZ3YLkW22fGendZ+//CfvR0TAAAAGh6r3ANAqX76dekL59vxppdJ7/uRt+OppD0p2xZvV1K6Kpr7vbOj0sZ2aU2zdEzIm/EBAABgHgI9AJTjf/5DGnm7Hb/oXKnv296OZzmuikpXDS7t3LMHLOgDAADAMwR6ACjX9z4h/df77LjtjdKFX/F2PEu1KyntTUtHBss7zz1nY3t1xgUAAICSEOgBYCm+9QFp/KN2fFZEumDI2/EAAACg4bAoHgAsxWs+Ip35Tjv+YUz6zge9HQ8AAAAaDhV6AFiOL/VI143a8T9+UnrFv3g7HgAAADQMAj0ALFesS7ppblu7f/qS9NILvR0PAAAAGgKBHgAq4ZIzpP/9Hzu+6JvS377O2/EAAACg7jGHHgAqIbJNetaL7Phzr5dSV3o7HgAAANQ9Aj0AVMKatRbqjz7Bng91Sb+93tsxAQAAoK4R6AGgUo5YL/Vvk9atlx572EL97imvRwUAAIA6RaAHgEo6+kSpf6t06FrpoXul2DnSn273elQAAACoQwR6AKi0Z51slXrJwnysS3roPm/HBAAAgLpDoAeAanjO6VJkqx3vTlmof+wRb8cEAACAukKgB4BqeeE50ltG7PjW66z9HgAAAKgQAj0AVNOpPdIbhu148krp8//o7XgAAABQNwj0AFBtZ75LevVH7Phn35S+8lZvxwMAAIC6QKAHgJUQ/jfpH95rx9d+SfrGe7wdDwAAAHyPQA8AK+X1H5dOm6vOX/kpaezD3o4HAAAAvtY0Ozs76/UgAKChfOE86affsOMLYtJZfd6OBwAAAL5EoAcAL3z6VdKvv2fHF35Vauv1djwAAADwHVruAcALka3SiW12fNkbpV98x9vxAAAAwHcI9ADghYNXS5FtUnCzPR9+tXTz1d6OCQAAAL5CoAcArxx+hIX6px5nz2Nd0u9u8HZMAAAA8A0CPQB46clBa79/0lOkv/yfNHSOtGen16MCAACADxDoAcBrx26S+rdJqw+VnLutUr/3Tq9HBQAAgBpHoAeAWnD831uol6S7f2uhfv8+b8cEAACAmkagB4Ba0fpy6Z3/Zce33yTFzpHYWRQAAABFEOgBoJac8lrpTZfZ8c5rLdQDAAAABRDoAaDWdLxZOu/TdvzLhPTFbm/HAwAAgJpEoAeAWnT2u6VzBuz4+q9Jo+/0djwAAACoOQR6AKhVXVHp5f12fPXnpP9+v7fjAQAAQE0h0ANALTv/36X2f7Lj714iffdSb8cDAACAmtE0O8sSygBQ8z7zWunGb9lxz+elM97u7XgAAADgOQI9APjFJ14uTf3Qjt/2NenFF3g7HgAAAHiKlnsA8IvINun4v7Pj/3iD9Ktxb8cDAAAATxHoAcAvnrDGQv0znmvPY13Sbya8HRMAAAA8Q6AHAD9pfqoU2Sod1SI9/lcL9dO/8npUAAAA8ACBHgD85mkbLdQ/cZ305wek2DnSPbd5PSoAAACsMAI9APjRhudb+/1Bq6T77pCGuiTnHq9HBQAAgBVEoAcAvzqp3Sr1krTnf639/uH93o4JAAAAK4ZADwB+9vxXSW+/3I53/cza7wEAANAQCPQA4Hd/f77U+3k73vEj6TOv8XY8AAAAWBEEegCoB6e/XXrdpXZ84wGNFR8AACAASURBVLelL7/J2/EAAACg6gj0AFAvXvk+qfP9dpz8inRFv7fjWQHXXnutVq9erdWrV+vRRx/1ejgAAAArikAPAPXkNR+VXnaRHf8gJm0d8HY8VTY7O6vHHntMjz32mNdDAQAAWHGrvB4AAKDCuj8rzTwkXT8qbfuQdOiTpFf8s9ejqorW1lZ9//vflyStWsX/pQEAgMbSNDs7O+v1IAAAVTB0jvTLMTv+py9JL73Q2/EAAACgogj0AFDPPna6tPMaO77om9Lfvs7b8QAAAKBimEMPAPWsf5v0rBfZ8edeL6Wu8nY8AAAAqBgq9ABQ7+7fI11yhvSHW6XVh0oX/1j6mxd7PaqK2L9/v+666y5J0nHHHaempiaPRwQAALByqNADQL074hgpslVad7T06F+k2DnSHVNej6oifv7zn+v444/X8ccfz0r3AACg4RDoAaARrD9JimyTDj1cevBeKdYl3Tvt9agAAACwDLTcA0AjufnH0qUvs+PgZmu/P/xIb8e0DDMzM7r77rslSRs2bKDlHgAANBQCPQA0ml9slYbPteMTTpUu/h9p1WpvxwQAAICy0XIPAI3mRV3ShV+141uvszn1AAAA8B0CPQA0orZe6Q3Ddjz5fenz53k7HgAAAJRtldcDAAB45Mx3STMPSt/+f9LPviGtWSu98Ytej6os9957r37+859Lkv7hH/5BBx3EfWoAANA4CPQA0MjCH7BQ//1PStd8SVrzJOn1n/B6VCXbsWOHOjs7JUmPPPIIgR4AADQU/uUDAI3u9Z+QTnuLHX//k1LiI96OpwwHHXSQDjnkEB1yyCFeDwUAAGDFsco9AMB8/jxrvZdsfv2Z7/J2PAAAAFgQgR4AkPGpV9oieZKthN/W6+14AAAAUBQt9wCAjP5ttje9JF32RtuzHgAAADWJQA8AyDh4tYX64GZ7PnyudPOPvR0TAAAACqLlHgAw373T0iVnSH/8vXToWuniq6XjTvF6VPPs3r1b3/zmNyVJ733ve1nlHgAANBQCPQCgsDumLNQ/eK+07mjp4h9L60/yelQ5rrnmGp1++umSbNu61atXezwiAACAlUMpAwBQ2LGtUmSbtPpQ6YE/SLEu6f49Xo8qx9q1axUKhRQKhdTU1OT1cAAAAFYUFXoAwMJSV0mffIUdP+tFVqlf8yRvxwQAAAAq9ACARYTOli6yeer6/S+k2DmSuBcMAADgNSr0AEq2fbvkOFIqJc3OSk1NUjIphUJSIGDvCQbt0dbm7VhRBddeJn3lLXb8gi22Gj4AAAA8Q6AHUFQqJY2OSpOTFubL1doqbd4shcNSZ2flxwcPXPlp6Rv/Yscv6ZbeGvd2PAAAAA2MQA8gRzotxWLS+LgdF7JQ9T2Vkvbtm/96IGDBvq/PKvrwsa0D0rYP2fHLLpK6P+vZUH7zm9/o4x//uCTpq1/9qg4++GDPxgIAALDSCPQAJFl4HxyU4nEL345jr7e0WBBvb7cgHgwufi23LT+ZlBIJaWrKXnev294uDQzYV/jUFf3SD2J23Pl+6TUf9WQYbFsHAAAaGYEegHp7Lci73BAfiZQW4BeTTluwj8Wk3bszr7e3SyMjlfkMeODLb5KSX7Hj110qvfJ9Kz6EnTt36qMftZsJl19+ORV6AADQUAj0QAOLx6X+flvgbt8+C/LRqNTTU73PTCbtM7Zvl5qb7XOjUavYw4c+8xrpxm/bce/npdPf7u14AAAAGgiBHmhAjmNV+UTCnjc3W6iORFZuDImEfZ5bsQ+FpLExqvW+9PGzpB0/suO3XS69+HxvxwMAANAgCPRAg0mlrALvzmvv7MzMm19pjmM3EoaH7XkgYKGeufU+8/B+6ZIzpF0/s+fvHpee/ypvxwQAANAACPRAA0mlpI6OzIJ3Q0MrW5UvJpGwmwzu6vgjI9Vt+0cV7LtH+tgZ0p7/lQ5aJV18tXRSh9ejAgAAqGsEevheOp1p215oO7VsyaTU1FTeOX6XHeabm+3PoJa2j0unbSE+t3OAUO9D99xmlfr77pCeuE66+MfShudX9SNvuukmveMd75Ak/exnP9OqVauq+nkAAAC15CCvBwAsRTptc8DXrZM2bLAW7fZ2C+m9vcX3T49G7ZyOjtLPqQfpdG2HecnmzieTUmurPc+e4w+feNrxUmSbhfk/PyDFuqR7dlX1Ix988EHddNNNuummm8T9aQAA0GgI9PCdeFzavFmamLCW8elpW6V9ctLCoPv9VCpzjuPYa7FY7jnT01YJHhubf069cBxpy5baDvOuQCA31Pf31+fvpK5teL4U2SoddLB0324L9fv+WLWPe+Yzn6kPf/jD+vCHP8yWdQAAoOHQcg9fiURsAbWBAau253Mcq/Tu22fhcHLSnre3W5U6mcxdRT2VsrDrVuc7O+uvKrxlS+Znmpys3TCfLfv3GArZzRsvFu3DMvxqXPr3sB0f//c2p/4Jh3k7JgAAgDpDhR6+EY9bmB8ZKRzmJQt97rxrdwV1d8/zRCI3zLtt6Nmt9uPj1Ru/F2KxTJgfGfFHmJcylXrJbrr093s7HizB8zult33Njm/7qVXqAQAAUFEEevhCKmVzqvv6Fl8oLbuSOzpqNwG6u+eH2Xg8s9q7y231rgfptAV6yToP/LbAXChk0yMk+125AR8+8uILpJ7P2/HUD6XPvtbb8QAAANQZAj18oadHamnJBNSF5Ldmu5X6UoTD5Y+tVvX22ur/LS0WiP0oEsnsQtDb6+1YsERnvF167SV2fMO3pC+/2dvxAAAA1BECPWpePG5bmZUaSgtV3bNb7V2RSG5Fvq+v9OBf65LJTEU7GvX3/HP3955O1+jvZ8aRdoxLVw3aY8cKztu4cdQ+c0+Nrxz4qn+VOi+24+R/Sle8u2KXTiaTWrt2rdauXatHH320YtcFAADwAxbFQ80LhSykl7qtXDicOxe+2AJ6rlRq6XPLE4nMvumOY8E5GLQbBV7OV+/osEDf1lYfreo9PTZ9IhCwnQlq5gbFjoS0tV/a/4B0TEjam5bu3y0dGZTePGavlWpPysL5XSnp5QPSKQvMkZhxpOGOTJBfE5D+ddI+t5aNvlO6+nN2fM6A1LX8OzTXXHONTj/9dEnSI488otWrVy/7mgAAAH5BoEdNS6dtn/mhIauolyIYtFZz18SErXJfKY5j8/JjsfndANlCIRtzd3flPrsUqZRtwSdV/mf3ivv3QFr8Bs2KuSEuXdErnT0gdUQsVM840geD0sw+e/6haftaioENdkPA9bkF/tN8VdTCf7aTu6ULfDC34ovd0vVzi+Wd92np7OVV6//0pz/p+uuvlyRt2bJFBx1E4xkAAGgc/MsHNS0QsABX6oJujpMb5qXKBlo3LEejFtQnJ20/e/cxOZkJ8KmUjbujY+HgX2mxmP25tbbWR5iX7CaN++c6OurtWCRZZf6KXqlrSDo7mgntawKZqvyMI02UsOiDZJX27DB/RMvi7893f4ktLF5766j0grnFKr7+z9LEl5d1uac85Snq6upSV1cXYR4AADQc/vWDmhYIlDcHPL+93F1QrRLcbe7c4B6LzW+rD4VszvfYmNTcnBnTSoV6x7HA6zildzT4hfvzpNN2s8QzM450ea+0qdMq8wvZVeJ8h/z3bVzkTkyhz921vbTPqgWRbdKzT7Pj/7xQuuG/vR0PAACATxHoUVfyA30lK9Q9PRaUE4nF58eHw7lt4amUtGVL5cZSjLvnvDuGehIK2Yr9kser9k/ELNR3Fam+Zwfr/SXexSk30G9sl84fyXutgnevqq2pSYpslZ75Qnv+2ddJqR94OyYAAAAfItCjrlQr0KdS0vbtthJ+qYvdRSKZAOqOLTtwV4N7/c7OGlo4roLcqRfjK7iQfI4ZR5oYtvnqhRag25H3Cz6sxF9CfnV9sUAv2aJ5mzpLu34tOqzZQv3T/8aeD3dJv/1J2Zf5y1/+ojvvvFN33nmnWBIGAAA0GgI96objZFacd1Uq0LtBeXhYWreu9Jbv/Lb3agd69+evt+q8y/25HMejtvuphIX6Yq32U3m/4E0l/CL2pOyariNaSl+t/uysNpD1Hm6rsFRHPsPa79cdLT0yI8W6pDt2lHWJn/70pzr22GN17LHH6rHHHqvSQAEAAGoTgR51o5rz57Ov7Tilr7KeX80vdeu9pUilMtevl8Xw8oVCtjaBZ4H+xrgF7kLb0c04ti98tlICfbnt9tmOCWUW0Cv1JoC7Ov9wh/SedfYY7rDXbhzNvbmwEo45ySr1hx4uPfgnC/X3+mSBPwAAAI8R6FE3qjl/vlJ7ym+v4rplbsBtbrZV4euV+7vwJNDv2l48pOdX59e3lhaylxPopcxnLLbn/Q1xC+9X9Ep3TkqatZb9Y1ptDDfEpct7pA9ukLb2r2ywP+4UC/WS9MffWaj/v70lnXrKKado586d2rlzp1atWlXFQQIAANQe/vWDulHtBfHicWnfPgvMS90HvbW1cmPK51bnK3XzoVaFQnZjxJNA/6+TxUN6fnV+sRXwXUuZP1/IQudd3mPj29RpbfqFwv9V0cyCfxMxWw/gzWOL3yiolOe+TOr7tjT8ain9awv1F/9YOnj1gqc98YlP1EknnbQyYwQAAKgxVOhRF9Lppc+fd7eVW0goZJ8xMWFfSw3N+S321aycuwG3nqvzUmaxv927PfjwY0KZPeez7U3Pr7S3Vnn+vGtm38Ir3F8VtTDfNSRdmCge0M+OSn1Jac3cfot709aKv5KV+hedK134VTu+ZbuFegAAABRFoEddWM78+Xjc9pVfTCBgNwnKWT0+fxG8ai5W546r3gN9Ta4PkL+6/cndhYN/vuW22884dlOg2Hl709JVg1aZL6Vj4JhQ7kJ7M450eW95Y1qutl7pgrktAX/9PekL56/s5wMAAPgIgR41L5m01eUXWlBuqe32jiONjlYnaKfTudurtbRktl2rhmouuFeLaurnzW+3L6U6Ly0/0LvnFztvYi4YH99h4b4UHZFMlV6ymxWlnlspZ/VJ537Ijn/6dWnkbUXfev/99+vqq6/W1VdfzbZ1AACg4RDoUbMcR9q82drhIxE7Lhbi8ivhpbbEx+byzlLnxC8kf8u6eLzyn4EasDdtVXLXmubSVreXlj9//ra5Fvli57mB/zsR6dLNpQfz/PHndyCshC3/T3rFe+z4f74offN9Bd82OTmpM888U2eeeSbb1gEAgIZDoEfNikRyFz5znML7uLuL1WUrpS0+nbbKf19f5dvUE4nc6vzISI22imP5llplr8T8+ZvHF755cFfWwhIzjm27V4r8cax0hd71j5+QTnuLHX//E1Lio96MAwAAoEYR6FGzRkfnv1YoeMdi1s6ezSlhHa9weHkr1heTSkm9WdOOR0aq22oPj+VXr0utzuefV251fm/aHgudl79Y3hFLvHN1lxdbCsx54xelv3u9HX/7A9KPPpPz7dNOO02PP/64Hn/8ca1evfCK+AAAAPWGQA/faG2dP9c9GrXV7WMxqbs783r+nPp8PT1WoU8kylvkbjGOY2HevaFAmK+8Um7WrKi78rZXKKdCv5TzXG61faH5+l0xaf3cXontfdIpS/zLuNSt9CrlHd+QNv+DHX+tT7out9OgqalJTU1NHgwMAADAWwR61Cx3pfrmZgvr+SE9HpcGB61lPhzOrdSPjhbepzydtjn5iYRdr5J7tjuOXTuVsjFPTKxsmHe7Fxa7meF37u+1tdXbcRyQ345eatv8/Xn77pW73/uNo4uvpn9MSLo4JX1uVjo3Vvq186cRLLWyX0mRrdIJp9rxl3qlm7Z5Ox4AAIAaQKBHzYrHLbTt2yc1Ndmc9O3bLax3dFglvK8vs7BdIGBBvbU1E64HB+280VF7/4YN0gMPVDfMt7ba15WeM+8G+vz1BOqNuzBiTWzPN2/+fBn7JeZX6MsJ9LuSdiNhqRX3hcw4uYv1rWkufdX+alr1BAv1LXN/TrEu6X9/7O2YAAAAPLbK6wEAxQSDFrzjcQvq2avEd3dbBTw/NIdCFqbjcXu48+NbWux7Y2OV36IuO8x3d9sNhkq28ZfKvUFRqDOhnkzNdbhX8obMkpWy13w1XDVoi+hVoxV+Iq+S3xHx7ufMt/YoC/WXvEz60++l2Ln64xsv1zd/cbsk6V3vepcOOoj71AAAoHE0zbJxL7Bk2WF+aGj+VnXZ0mlp9+7MVIJKS6dtaz/HKXyzox44jrRunbTtJefoOa99qTaGXyqtP8nbQV2UNXd7Y5vUV8KchxlHes+63Nc+V+J/inclpeEO6fyRylfo96Ztezt39f31rdayX2t2T0mXnCE9dK8ePuwobf72fbpln/TII4+UtzDefkc6rEZuVgAAACwBpQxgidwwPz1tlf+Fwrxk3QIDA9UbTzBoc/el+p1Hn0xKGw6f1pZnjGnjz94pvffZUuSZ0pffJP3sG5Jzz8oP6oisLRZmSpzvkF8FL8fWfgva1Wi3vyycG+YjNfoXqaXVKvWrD9Eh++/T9097gtqee1z5C+P9YBm/B/iG4zjq7e1VPF7ito0rqL29XYlC+7ECAFAiAj2wBNlhPpksrY0/lar+vG93HOPj1f0cryQS0kuefL1+/OCrpcOPtBfvnZaSX5E+f570jqdLH3iB9M33SlM/lB57pPqDyg7We1KL79m+Ny1NDOfeCJDmb2NXyETMPuOCKgSTy3syK/a7Yb5WWu0LOeElFuolPfPQR5QMH6lVj+4v7xq3JO2BupVKpdTR0aGJiQmFKz3fqgJCoZC2bNmiwcFBr4cCAPApAj1QJnel/NlZOy5lLnc6bXO/qx3o3Tb7VCqzeFw9GR+Xvjb9Bu087VvSl+6TBn8uveaj0nNOs5UTJWn6V9L3Pyl94uVS72E23/q7l0q//0V1BtURsYXjXAtV32cc6ctbJM1aK/v6rKX6J4YX/pwb4lad7xoqf0X8xdwQt1XzJZs2UOth3hV6hXTRN+349zfaQnnl2kqQ8koqldL27duVrtJ/rNwwPz09rUQioYAXi5ssIhaLqbu7W9FoVL29vV4PBwDgQ8yhB8qQSlmYl2zRvVL/fRiLWXV5Jea2h0J282BgILMoYD2Ix22nAsk6I+bdHHn0Yek310o75x7pX8+/yNqjpGe/1B4nvVR62sbKDG5PShpuz7Tcd0SkswdyQ/HetIX5vdM2z/6YUGnnzTgW5G+I217y5Ww/V4ob4tIVc3+w1bj+Srj2Mukrb7HjF55zoHK/qPdvlnanpA9MSCfW4aITNchxHA0PDysWi8lxnAOvB4NB9fT0aKBC85LS6bQ2b94sx3E0OTmpUE2sollcT0+PRkdH1dfXp1jMh/8bBAB4hkAPlMgN81n/Bi3b5GT1V2ePRm27vkDAgm8NFqWWpKPDpjd0dtrNkUU5d2fC/W+ule4tUAV8+vEW7N2Q77bxL8XetHRVNFPpXhOw0H5k0L63K2lt9hcmcivsM461u+8YL37emmZrs99U4ZZhN8yvaZa6YtWZl79SrvyU9I332PGpPdJbRhY/57y5ro4T2y3Uo6rS6bS2bNmiVCql1tZWRaNRhcNhpVIpxWIxjY6OqqenRyMjJfzuFuA4jjo6OpRKpTQyMqKentr/e+04jtrb2zU1NeWbMQMAagOBHihBJcK8ZG361ZZOSxs22HG9VOmTyUxnxJJviuzZmVvBn3lw/nuOOyVTvX/2SzNt/OXYm7b58HtS0v1zNxHWBCyMt4aLt7IXOu+IoG1Nt9B5SzURs8p/oZsMPnLrrbdqaGhIkvTF05+ipsRH7BtnvlN6w2cWPvm8rN9v/5j0gtqbY10vskN2c3Oz0un0gRb4ZDKp4eFhJZNJOY6jiYkJtS+jlSkcDmt8fFydnZ2+WnAulUpp8+bNkuSLrgIAQG0g0AMlCIeXv9Bca+vK7RHf0yONjtZPld6tzre1VXAF/99ePxfuJ6Rbt8///upD58J9h30NPq9CH1wDLu+xToJSFr+7IW5bu1W6O6BCrrnmGp1++umS5rat+6/3Sj+ca1kO/5v06o8UPzk70D85KMWmqzjSxua2lEvKaStPJpPqcO/WzRkYGFB0iXciY7GY+vv71dzcrFQqpWC1Fy6psGg0qsHBQQWDQU1OTtbkvH8AQG0h0AMliMeXv8hcMGhBeyW4i/Xt2yf19dkcfr/KnjtftTUI/vJ/mdb8nddKd948/z2Bp+fOv3+yv4LCAW6YP7m7tNXy3xOYm9tfm60eN99884Hw961vfUsHH3yw9OV/kpJftTe87uPSK99b+OTz8jow3jJi7fqoqHQ6rQ1u25CUU4F3q+nZltpynj1vfmhoSJHF9hKtUcFgULt372Y+PQCgJAR6oE7FYlJ/vx2vxGJ81eA4Nn3AccqYO18Je+/InX9//13z33PMs3Pb89c8aYUGtwxumD97oLSAvjctDWyQLhyr2Qp9UZ95jXTjt+249wvS6W+b/578QE+Vviqyq/OSlP3Pjvb2dm3fnumQWU5l3b1WS0tL1VbOXwnxePzAivfLnX4AAKh/BHqgjrkr3geDNvfcb92bW7ZYiG9psVZ7z7pnd6dyK/iPzMx/z9+8JFPBP+HUlR/jYtwwf/5I6YvfufPs+yZsLr/ffPwsaceP7PjtV0h/f17u991Af5Sk++Zeo0pfcevWrTuwon1bW5uSWfNmssNrc3Oz4vH4kvaLz27dr4dF5UKhkKamptTe3q6JCRZsBAAUR6AH6lgqJc2tsaRwWBob83Y85XBX65ekkZGVm65Qkt9MZCr4u342//uHHp5bvX/Gc1d+jNncML+xvfRgfn9amkrYKvyf8+n/TTz8Z+mSM6RdP7fn//xd6XmvtOPdKdu2TpJOkHS7pEdElb7C8ufIF2ojT6fTSqfTCoVCS54zXi/VeVf2jY6xsbEl3eQAADQGAj1Q52IxC8d+mk+fPW++u9ue16w/P5Dbnv+HW+e/56hjc7fHW7d+5cbnhvmlOqJF+pCPA5Jzt4X6PTulg1dLF19t29TdkpQ+Mhc0T5D0sCQ3x1Olrxh3kTdXNarn2eHXz3Pn8wUCAe3bt0/BYFDT09xkAgAUdpDXAwBQXZFIpro9PFzj4Vi5Yb61tfbHqyeuk17UJfV+XvrkLdK//05602XS375OetJT7D333SFdF5f+4w3SRcdYZfjr/yxNXlm4fb9SvhNZXpiXpCNre/G/X/3qVzr11FN16qmn6rHHHpv/hsDTpcg26chjpb8+KsW6pPSv57/vKElPmDveNjj/+1iSZN62FNXYii2e9R+Jeqpkuzc+0um0r7bfAwCsLCr0QIPI3nqv5lrY52SH+bY2mz/vt3n/89x+U+78+78WCJ3Z7fkb/7Zyn31R0+LvWUypC+h5ZN62datXF37j7b+0Sv1+x9rqX/0R6Qvn2/dOkLRWNo+eKn1FZc+fl3IXxKuE7BX0/bbv/GKy96Wvt58NAFA5BHqgQTiOrXQ/NWXPe3os2NeK/Mp8MlkHYT7fXx/LDfe33zT/PU9cl7s93tEnrPw4feT3v/+9Rub+Ig8ODtq2dcXsvFa69Azp8celpzxT+tPt9rob6CVpSsylr5D87epaW1uVSqUq+hmRSETDw8OS6mMxvHzuFnaSND09vaTV/wEA9Y1ADzSYnh7J3UEqFLKF8rz8N6LjWJB3i091G+YLefBPufPv//j7+e956rNy59+7bfyN7t60dHlE2r9PaglJTyzwF+awgH0v220/lb71b7mvvTDrmCp9xSQSCW3ZsuXA8+7u7pz2+Eqo98CbveVfPa0PAAConFVeDwDAyorHLcAPDmZWwY9GbcG8lZZMWph3F6Xu7LTxNUSYlyyc/+3r7CHZgnpu9X7ntbbg3h9/b4+JL9t7nvnC3Ar+wQ36n/EnB6W3xqWtUemHFVzp8ShJd8mq9NsGCfTLkF+Nr3TYTqVSB8J8S0tL3YV5ydYEcAN9Mpkk0AMA5mFRPKABRaNWmW9utgp5JCJ1dFjAXgnptO0x39GRCfNDQ3UyZ345jj5BOv3tUt93pMvul6I/lV79YemkzLZfuv0m6Xsfly49U+o9zPZa/94nbI54ozksIF0Qkz42KR3bWrnrupsQ3Ju2xQyxJPmBvr29xC0TS5Q9p7zS164V2YsIjruLoAAAkIWWe6CBOY6F+7kpqJJsnn0kYtXySksmrd0/u+u2rc220qvC4tf15ZGZ3Pn3uwvMRX7SUzLV+2e/VHrKs1Z+nF76Ycwq9vv32fODZeH8KEn7i5yzX9JTC7zOXPqybN++fd5rPT09OXvCJxKJgvvMt7W1Lekz3b3nperPn3ccR8PDwwdW7Q8GgxoYGFi0KyCdTqu3t1cjIyNL7iBwt6+TpImJibq9eQEAWBoCPQAlkxbss/9NHgzayvjd3csL2+m0ra4fj1uLv6ulxYJ8He0ytbLuvyu3PX/vHfPfc/QJuSvoP3Hdyo+zyq677jp1dXVJkv7whz9o9aN/lr4Wka7P2q5vraRjJR1WxoWZS1+ycDi8rOrxwMCAotHyd1Joasrs4lDNoBuPx9Xf35+zWr9kQXtsbGzBzw2FQnIcJ+fGRrmyb1ws9c8KAFC/CPQADigU7CVrg29vt2AfCtnzQkU197xk0oK8+9XV3GznRqO1uW2er915c24F/y//N/89G/8ua/59x/zv+1DRbetuSVqwv2Mq8+anyir2CyyEn+NWSQ+JKv0iEonEvPb6dDp9YO63ZHPci1XQI5FIwcr9QrK3dJMqvx2eKx6Pq9fdfqOAQCCgiYmJnNZ4VzQa1eDg4LJvNrjXkdi+DgAwH4EewDzptFXPEwlpbs2pZWlutkp8JEJr/Yq5dftc9X5C+u3187//hMNyw33+avBe2+/Y/PVTe2yufBH33HOPrrnmGknS61//eh10UN7SMIXa8I+VteEv5iFZqJeo0pcpFoupv7//wPNKV5azg3ZLS8uyKuDFJJNJdXQsfuOrUKh3f/5K/NzZONEHrgAAIABJREFUP2swGNT0NDeXAAAZBHoAC0qlrNKeStljaqrw+5qbpblpnmppyVTzw2FCvOdmHszdHm/PzvnvOWJ97vZ4Rx678uPMd11curxfekNMekn30q/jbnH3q6y28FLb8KnSL0n2/vCSNDY2pnAF59dkV63b2toOzG2vJHdLvJaWFkWjUYVCIYVCISWTSaXTaSUSiQNTDQKBgHp6ehQIBJRMJpVMJitWTc+/scA/2wAA2Qj0AMqWTue20kvWSh8IeLunPUp0bzp3/r1z9/z3POO5udvjHXr4yo9Tkj7SLt2yXTqxXbpgaHmdBLckpS/2SPdltZ2sl7XiF2vDz67SXzAkncW2YaXInvctVX6P+OzrVyPQu1Xx7u5uxePFdzpwHEeJROJAyHccR1NTU2ptbVUymSx7KkEh+YF+cnKyYIs/AKAxEegBoNGlf51bwX/04fnvObEtU8H/mxev3NhuSUofyWp7PisidQ0s2Ia/KHfvercN/xBJz5BUbM1At0p/WEAanl7eZzeI7AXrpMpXlau9UFx7e7scx5m3NsBCHMdRR0eHHnjgAaVSqYqEeddKLQAIAPAf9qEHgEYXfJ70in+R3nuVNLJfuvjHUuf7peNOybznlu3S1gHpQy+R3hSQhrZIV3+2cPt+JZ3Ynttu/8OY1LfhwCr2jzzyiO69917de++9pV+zKyp9LCU9f25vxocl/U4W3AvcyziwL/1+R/pBrPyfocHkh+Clbku3kGrMmc8WjUbLbpePRCKanp4uuj1fpeSvtg8AaGyrvB4AAKCGNB0kPed0e0jS/+3Nrd7ffZs0s0/6ZcIeks0vz94eL/D0yo7pDTHpV4lMRX2/Y63z2+O6/pmv1+nnvUVS3ir3i3lyUHp3IrcN/yFJOzS/DX/t3OMhST8cll4eoUq/gPxAX4328N2VWK1zAeVUwB3HUW9vryYmJpRMJqveDp9KpSq6HgEAwN8I9ACA4g4/Ujr51faQpHt25W6P99B9Nic/+VV7SFbxz55/v/qQ5Y3hsIC12m8bzH39lqQ0scy50ye2S5ekrPLuXv8u2T702W3462UVfLdK38Ve4MXkV8/reb6322Y/PT29ImEeAIB8BHoAQOmettEep1lVXL+/MauCPyE9/lebk5/+tXTlp6zin129P+7kpX1uV9RWvb9vt815D0i6T3rRkdKvzpJ06Fqt+vnXl7a13GEBu/6pPdKXemx6gduGv04W7KnSlyx/gbp6DbnZc+YJ8wAArzCHHgCwdM86WXrVxTbvfmS/9N4fSK94j7Th+fb92cel//0f6VvvlwZOkd56lPSZ10jXfFG657byPuuCufnrD8va4Z8trX2y9LwjpOcd9pCavtRrC+jtLn0hsxxPDkofSEr9Y9JRLfbaA5J2SvqDmEtfoqm8vS2rHXSrOV+9mFQqpY6ODs3OziqVSlX9Z6zGOgQAgPpAhR4AUBmrniC1nmUPSXLuyd0e795p6aG90o3ftodk1f7sCv7ao4pf/wVhW23/lu3SHyUdJWmjrGp+u6RHZG3479+8vNXwXxCWTmrPtOH/VdaGf4jsRsJfRZW+CHfrNldra2vVP3OlF4lzw3xLS0vFtqZbTPYWgAAAZKNCDwCojsDTpL/7R+nN/ynFbpc+sVPq/qz0wi3SYc32nnt2Sdd8Sfrsa6W3Ptmq+P/9fqvqzz4+/5pulf6vsqq5ZK3wrZKOVmYhu7zV8MvmtuHHpu0mgmSdAX+d+34JVXrHcZRMJjU4OKiOjg5t3rxZTU1N8x6BQEBNTU3q6OhQb2+vBgcHy9ourZasxIJ4XorH49q8ebM6OztXLMwDALAQKvQAgJWx/iR7vOwie/7bn8xV8Cessi5Jv7vRHt+9RFp1SO7iehueJ7WEpLP6rEJ+n+QcLk09aKee+kyp6ShJd0hylLMavi4YsnPL5bbhXxeXLo9kVtqXpO9eOq9Kn06nNT4+rng8XnIo37fPrpk99zwajSoQCKi9vV3hcFjd3d3FTq8p9Rzo4/G4ent71d3drXg87vVwAACQJDXNzs7Oej0IAECDe/jPudvj3bFj/nsCT7Ngv/EU6b//TfrLQ7rGkU6/yr79yKek1W6FPrsN37WcNnzJbhBsjdrNBNc5A1JXVMlkUqOjoxobGzsQ0F1tbW0KBoMKBoMKhUIFq7rpdFrpdFqpVEqpVGretmytra3q6OhQX1+fgsHg0sa/AsLhsMbHxw88n5iYKGsLuFKFQqEDc/UHBgYUjVZ31wE3zA8NDSkSiVT1swppamo6cFytP1MAgD8R6AEAtWfvnbnb492/p+DbrrlHOv1aO84J9K67ZPPt3Vb5wwK2r/1LllHx3p2SPnm29MDdeuwJh2vLHSF9/9qfHPh2c3OzwuGwwuGw2tvbl9SWnU6nlUwmlUgkcgKyJPX09GhoaKgm2703bNiQs23dAw88UJVxtre3H5hX3tfXp1iseosU9vT0aHR0VCMjI+rpWcIuCsvkOI7WrVt34DmBHgCQjUAPAKh9d0xlVfCvkR6ekSQ9Pis93CTpudKaQ4uc+7AybfiuE9uX3oYvC1lb+16pc2d+otitUvRmq6JHIpGKhz7HcRSLxRSLxQ5U/5ubmzU4OKi+vr6KftZy5AfPlpaWeXvSV4obsiXrgMjfKq+Sn5NIJBSPxxUOh0s+z93SbmRkZNnTDpLJpDo6Og48r9ZNEgCAP7EoHgCg9h3bKr28Xzr5XOngQw68fFCTtOZoac3qBc49RLYa/gmSnjD3mrsa/uX91kpfhkQioQ0bNuhNX/uJguPScUcfpet/9D2lUqmqVHADgYCi0ajS6bQGBgbU3Nysffv26f+zd+/xcd31nf/f8iWJHcKMnUDS2EQjwCUXyIyStAkpRCPHTUIoSCItD7oQNNNu6G7pD0mlbNnuUo0ov963HgW2C2W3GhFYWhaiUVlSu9TRGAiJC8FHDkkgDugosUlo4viYpFLiS2b/+M7RXDSSZqSZOXN5PR8PPXQ0c2bOV7Li+H0+3+/nOzg4qM7OzqqF5nLVcv18LZYduGE+lUqVFeYlKR6Py7KsqgRvwjwAIBeBHgBQ/9wA/ulINoD7JV0psz984VT7YirQDX9oaEh9fX1yHEc+n0/Df7Zb793zjN5y06+U+Q2VLzfYu5V5y7LU2dmpZDJZ9euvpLBKXs1An/ve1djSLTfMl/t92Lat0dFRBYPBitx4yL1RUottAAEAjYVADwCoX8/Y0mei0ie6zdp1yVTZL5Wpup+9zGuXsk3SFTI3BKRsN/zcaxRwp1C7a7WDwaAsy/KkQZrf71c8HtfU1JR8Pp8cx1FfX5/nndcLZwpUc513Yciu5F707nT+eDxedph3/yzcZRKVkPtzbaZdAwAAlUGgBwDUnzlHunvEVOW/kQmq6yVdIlNlP888dPSE9Olvm4+Xy+kIU8Y0fDfMuxXogYEBWZblebf5cDgs27YXqrbRaFTRaNSz8bhd513V/PkEAgH5fL6Fr0vdInAl8Xh8YW1+NBpVW1ubOjo6FI1GFzUnLJRKpdTZ2SnLstTV1VWxGxq53xvN8AAAhWiKBwCoL98cN9vDPZNT8d2solPr9/1Y2pXJ+yeHpY1zq7zm08p2wpek9RulOz4r50096u7uXghVXnU6X47jOBocHFwIotXu+r6U3K3V3JkD1ZS7RV4ltpPLbT7X39+/sENBIpFYuI7f71dvb68CgYDC4bAcx5FlWUomkwu/Iz6fr6I3fPx+/0IzxJmZGc9vJAEA6ssGrwcAAIAkM939riFTKS80J+nw4oc3PSN1nGuO236oys07O3NK+nREz27cLs2aLfPqMcxLWgidkjQ+Pq5EIqFwOFx2I7e1KFw/X4tKcjgcXgjaqVRqTYHetm319fXJ5/MpmUzmjb+3t3dhGr7jOCsubUgmkxUL3ZZlLYT59vZ2wjwAYBECPQDAW3OOCfLfKH8N+PWvkn7cs8rrXta1+LGTc9K/OVJbmx5/9t909OgRxa+Wzvzy/6eddRjmcyUSCTmOo8nJSfX19dV0v/LCKe+1CvSutTbGi0QiSqfTSzbBy71hshSfz7dwM6VScm+UMN0eAFAMgR4A4K1nbOmGfvNRrsuqE3KSyaT6+vokZaaw/6faT2FfDTdQTk9Pq6+vTzMzMzXZ5qyWDfFcoVBI7e3tmp2dXZj6vpqmcYlEQvv379fExMSyr18u1Hd1da2qid5KcgN9LWdcAAAaB2voAQDI4TiOOjo65DjOQjf7RmJZlsLhsE6cOKHe3l5NTExU/ZrhcHihSl6L9fOueDyuoaEhSatfR+9uT1dq34FUKqVkMinHcRQIBNTb21u17vPu+vn29vZFN00AAJAI9AAA5HGnq0uqi272q5FIJBSNRhemgVe7upvbEK+np0fJZLKq13PZtq2Ojg5JpvP9zMxMTa5bC7mzRIaHhxWLxTweEQCgHrFtHQCgYT322GMaGBjQwMCAzpw5s/ILVuBWX0+cOKFYLNaQYV4ya8K7urp04sSJhQp2tRTOYKjl1PBAIKD+frNUw7bthptNsZzc5nv12IwRAFAfCPQAgIb15JNP6s4779Sdd96pl19+ec3vNzIyIkkKBoNr3gbNa24gtG27qtVdLwO9lB92V+pA3yjc5oaSWZ/fqDeWAADVR6AHADSsCy64QLfeeqtuvfXWvGnfq5FKpRaakHmxj3ul5VavR0dH1/Rek5OTGhkZKTqVPrdxW09PT02a8OUKh8Pq6jI7FrhbyzW63N8/ptoDAJbDGnoAAGQqy5OTk+rq6lq0r3qjyl1jPjY2tqqp2319fXlBfmJiIq8K39HRsdCwrZZb5eWyLEudnZ2SGn+9eW5Txv7+/qaZdQAAqA4q9ACAlmfb9sIU52Zar7zWKn0ikVhUlc8NmLZtL4T5YDDo2V7poVBIAwMDksz32chV+ng8Lsdx5PP5GvrGBACgNgj0AICW54ZWn8/XVIFeyq5ptyyr7K3Pis1UyA3tueHe62UKsVhM7e3tchynYYOwbdsLN14auSkjAKB2CPQAgJY3Pj4uqfYN3Wqht7dXPp9Pkta8nVx7e/vCDQ/HcRbCZ39/v2fVeZff71+4qTA6OtqQHe8HBwflOI66uroavikjAKA2CPQAgIZ18OBB3XTTTbrpppt0+vTpVb2H4zgL4a8ZA72U/b7KDfRuSG9vb9fu3btlWdZC07tYLCbHcRQMBj2vzrt6e3s1PDwsSYpGox6PpjzJZFKTk5Py+XxrvvECAGgdNMUDADSsffv2adeuXZKkkydPauPGjWW/RzKZVF9fnySpWf+XuJbvMRKJaHx8XJFIZOHGgLu2PhgMKpVK1byz/UrcBoeRSERjY2NeD2dFlmWpu7tb6XRaqVRKoVDI6yEBABrEBq8HAADAal1yySX68Ic/LElat251k87c6nwwGKzYuOpNbkBMpVJlTY9PJBIKh8NKJBILgd6t2NfrtPDcMQeDwbodp2RmiESjUTmOo7GxMcI8AKAsVOgBAC0tHA5r//79Tb9FmN/v14kTJ1a9fV2jcRxH4XBY09PTdf09h0Khuh9jNdm2TfM/AFgD1tADAFraiRMnJKnpQ4Vb+S23032j8vv9SqVS6unpUTQarcsmeZFIRLZta2JioiXDvGRuvIRCIUWjUU1OTjb0loMA4AUCPQCgpbkBwusu7dXm3rBolUAvmVCfTCY1NjZWl0ExEAjIsqymbcZYilAopEQioS996Uvq7e3Vli1b9OY3v7lhdyoAgFpjDT0AoKW1SsBtxUDvqtfqdywW83oIdSEUCum+++7T9ddfr/n5eT3wwAOanp7W/Py8LrroIt1yyy3q7e1VV1dX3TVgBACvEegBALU350j/GJf2xKW5E9nH20PS5tL/wX7f7Am950uPSJJmRn9LG165teyhDL9Jsv9N2nL0u1LqR9KFr88+eUG79KrmnooP1INQKKRvf/vbC6F+fn5ekvT000/rC1/4gr7whS/o1KlTuu666/Se97xHXV1dNBAEANEUDwDgpWds6Ssx6Zvjq3r5vqelXfea45PvkTZWciHZu4altw2WdYOhnsViMY2MjOiXfumX9LWvfc3r4QBFPfTQQ7rpppsWAn0x55xzjl588UVdeOGFuvHGG/Urv/Iruvnmm7V1a/k39ACg0RHoAQDeezQlfW5QemI6//GzJJ299Mt+Mif94xPmOPoGaV1bzpNzks6sYiyXdUm/lWi6yrwb6IFmNTw8zDIGAC2HKfcAAO9dFpb+xJK+kZDuGsxOwz8p6VWSLpS0fvHLLpb0m1et4npnJP1U0tHsQ6fO8WljZFR6a/8q3rBxXH/99ZqcnPR6GEBR3//+9/WOd7xDJ0+e1MmTJ4ue41boX/WqV+nGG2/U2972Nr397W/X+eefX+PRAoD3CPQAgPpxQ0S6ptesr787U00+KulpSZdIuqAC1zgu6UlJL2UfGnlIuuZj/11vf+t7K3CB+uR2DN+xY4cuuKASP0igsizL0jvf+c5FYf6ss85SOp3WqVOndO211+o973mPwuEwa+gBQAR6AEC92eyXbouZcH/XoPTgpKmoz0h6VtI2Seet4n1fyrzH8zmPXdal90y9qL9/6ICGHz6st//a2odfr9xt29xu90A9sSxLN9xwg+bm5nTmzBlt2rRJ8/PzuvDCCxe63IfDYbrcA0ABAj0AoD69KiD9btKsr/90RHp21oTxH8hU6i+WTm+U5jKFvFees8T7FJlerwvapdvj0jW9evG7Zg/wZt/zev/+/ZJEVRN1x7IsdXV16fnnzd02qvAAUDoCPQCgvl0SlN7336R/3C0dvl96+WVTqT8u7d8s7fqMOe3kX0obC9fZF5leX9i9PhQKKZVKaXZ2tvrfi0dyb1ZQoUc9sSxLkUhEfX19VOEBYBUI9ACA+vPIlPTwvebj8LeLn3OhTCf7YpaYXl+se304HNbIyIgsy5Jt200ZeFOplCTJ5/NR8URd8fv9TT87BgCqiUAPAPDeE9PZAP/wvdLJIkn9DW+Rnvy+NOeY7ewukq45Jd03YJ7esE4rTq8vJhwOLxynUilFIpEKfVP1ww30vb3FfwaAV5rxBhoA1BKBHgBQe8eezIT3fdIj90rPHV18zrbLpSt2SlfcaD7v/1vph9/KPCdpveRbL13v5oESptcvpaenR5OTk0omk00X6B3HWdimLvfmBQAAaHwEegBA9b34ggnubgX+yYcWn+O/yIT3y3eaAJ87NX7Okb6S2cbuPOVvX1fG9Pql9Pb2anJyUpOTk3Icp6nW8CaTyYVjKvQAADSXtnQ6nfZ6EACAJvTDb5nw/si90qP7Fz+/4exMBT7zEbhq6ff6dET65rg5vlQm1K9iev1SHMdRKBTS7OyshoeHFYvFynp9Pevs7JRlWerv71cikfB6OAAAoIII9ACAyjj6SM46+H3S/M8Wn/P6a7MV+CtulNraVn7fWUv6g05zfIGkDi1Mr//ZC9Kjmcv84r//Q7XdOrTi9PqlRCIRjY+Py+/36/jx46t6j3qTSqXU3d0tSZqammLKPQAATYZADwBYHefpTAV+n/n8jL34nIt25K+Df8X55V/nE91mL/r1knbIVOQz0+v3PS3tutccnzx5Uhs3blzlNyPZtq2Ojg5J0u7duzU4OLjq96oX3d3dSqVS6urqWmiMBwAAmgeBHkDJLEs6cUI6flyans4+7vdL7k5YXV3ejA01cPql/E709vcWn3Pe+dLlN2an0V+0Y23X/G5S2t1njs9WfsO7C9q179Lf0K7fHpa09kAv5VfpZ2ZmGnotfTKZVF+f+dlRnQcAoDkR6AEU5TjS/v3SxIQJ7+VsExwISMGg1N0t9fSYr9GgHj+Q38wu/XL+823r8tfBv+7ayl5/sKN45T/Tvf70Wa/Q88+bcv2WLVvWfDnbthUOhzU7O6uBgQHF4/E1v6cXHMdRZ2enbNumOg8AQBMj0APIk0pJo6NSTmPsooJBU5mXTPBfTigkRSJSf3/2NahTTx/OhvdH9knPH1t8TuCqnBB/o7ThrOqM5Ssx6e6R/MfK7F6/GrFYTCMj5rqNWtkeHBzU6OiofD6fUqmUQu4UGgAA0FQI9ADkONLkpBSLmen0J05knwsGpd5eE8oDgezU+mJs23ykUqain0rlv5ffb95reJiqfd14/tn8CvzThxef86pANrxfvtNsL1dtz9imEd6cY75eZff61QqFQpqenm7Iqfe5U+2brWM/AADIR6AHWtz4uAnyds6s5p4eE7x7e9deUU8msx+54X5w0AT7BspJzSH9ck4F/l4zpb7Qpldmm9hdsVPadnntx5m7TV1mev1qu9evhm3bCoVCOnHihEKhkA4ePFiza6+FZVnq7u6W4zgKBoOyylkrAwAAGg6BHmhRliVFo9LMTDZo9/ebcF+N6rnjSPG4lEhIs7PmsUBA2r3b3DhAFdnfy29md/qlxedc1mXC++U7pTe8pfZjzPVoynS2L2F6/VNPPaW9e/dKkt7//vdr3bp1FRtGbqU7EolobGysYu9dDbnr5n0+n2zbbqiZBQAAoHwEeqAFjY6a4O5kZjNXM8gXcoN9PJ69kdDbK42NUa2vmGfsbAX+4X1me7lCr3lT/nZyZ59b+3Eu5dMRM7W+hOn1+/bt065duyRVpst9oXg8rqGhIUn1Heodx1F3d7csy2LdPAAALYRAD7QQxzFT3cczM5nb203F3IueX7ZtGuW5DfVCIRPqySCrMHcifx380UcWn7N1W3YN/BU7pfNfU/txlsJdM1/i9Ppvfetbeve73y1JeuKJJ7Rhw4aKD8ndys493r17d11VvnOn2UuN28gPAACUj0APtAjHMdvI2bY57ukxYd7rXBKPS5kCqPx+aWqKUF+SR/dnQ/wPv7X4+bM2528nd0mw9mNsIrmhPhQKaWJiQoE66OyYTCYVjUblOA6VeQAAWhCBHg3LtrNrsXO3UFuOZWWneZf6mmbghnm3P9bu3aZSXy8sy8wSOHGCUL+kJx/KXwf/0guLz/n567MV+Mu7az/GJpdIJBSNRiVJfr9fY2Nj6vWoAYTjOBoZGVE8Hpcktbe3K5lMEuYBAGgxBHo0FNuWRkZMZblQJLL0dmiJhHldbid3yYTI4WFvppzXSmGYHxszP6t6Q6gv8NyRnHXw90rHnlx8zsWX5m8nd26L3KHyUCqVUm9vr05k7gyGw2GNjY3VtFqfSqUUjUZlZ/5CCwaDSqVSdbUMAAAA1AaBHg0jkTBd2dvbTQO3cNiEd8syAXV62pxXGFgjEbNmfHg4u5+6u1d6PG5eV68htxL6+syWcVL9f5+5oT4UkiYmWmi/+pNz+RX4J6YXn/PKV+dvJ/fq19Z+nJDjOOrt7dX09PTCuvVIJKLh4eGqBvtUKqWRkRGlUqmFx9hnHgCA1kagR0PIDeXF/u3qOCYAzs7mV3cjERNmU6n8aq/jmKDr/rvY7zfbtzVbgSsWMzMTpPoP867CUN8g23+vzmPfzlbgH5la/Pz6jdnwfvlO6bXX1H6Mde7xxx/XZz/7WUnSH//xH2v9+vU1u3YikVAsFtOsu/ZHJtj39/dXrCmd4zianJxUIpHIC/I9PT2KxWJMsQcAoMUR6FH33KZpKwXS3PAaDksDAya0F1svHgplK/quqanmmnqfSpmp9pLZlq7YMoV6lTv2gQHzO9AUfvKDbAX+kX3SvzmLz3ntL+Q0s7tRWle7gNqIqr1t3Uocx1E8Hlc8Hl+Yhi9JgUBA4XBYvb296urqKms6vG3b2r9/v5LJpJLu9JqMrq4uxWIxutgDAABJBHrUOTfYlRLqckOgZKrtwWC2Cr/Uea6Zmeaa3t3RYZYWuD+DRpt9kHuDpmFvtpz4af52cv/648XnXPi6TAU+M5X+la+q/Tgb2MGDB/V7v/d7kqS9e/dWZdu6UjiOo1QqpVgspunCu4UyTfRCoZBCoVDRcG9Z1sJ7FHttV1eXBgcHCfIAACAPgR51zQ3Yhc3siikW1CcmzLr5lc4LBrNN45pBLCaNjpqlBQcPNm5zOXcmRcNMvT9zKqcCf6/04+8uPufcLfnr4H/uDbUfJ6pjzpE2+2Xb9kJ1ff/+/at6K5/Pt1Dh7+3tpeEdAAAoikCPuuU2wSu1Opu7n7kk+Xwm0BaTO+U+GDTr7JulOm/bpjovLd1zoFFYltTZaY7rbau9BT/+Tn4zu5dPLz7HXQN/xU5px5trP0ZU32ei0i0DUvviu2epVGrJCnwgEJBt2woEAgsfbiUfAABgJQR61K1yqvOSCXujo9mvV1o37lbkV/PvZscxNwQKZ8eGw97vb+82EPT5zM+u0Qt77vdTN40Lf/p4tondw/uknz2z+Jz2UP46+I3n1H6cqJ09cemuIekL/O8UAADUljeLDYEVWJbpWL97d3mvybVSVX81QT6VMjcN3D5VXV3513er4b29pjpe6yKbbZvwK5kbHJ6H3wqIxcz35Djm517zTv0vPJe/Dv6pHy4+54JLsmvgr9gpbbm4xoOEZ/Z+0oT5S4JejwQAALQgKvSoS7ad3XKu1FDa1pb/daWb3LkzALq6zHHh2nzJTPuPxcyWa5I5Hh6u3BhKHWOzVOddbpU+HDZLMKrOXQP/8L3S4fsXP3/OeTkV+J3S9jfWYFAoZnp6Wh/72MckSRMTEzXdtk6PpqRPZBpyvOmXpY/+U+2uDQAAICr0qFOBwOLp7MspPNfnq2yYd5vMrbSOe3DQXLevL/u648drt+3a5KT5HIk0T5iXzM91fNz8OVtWFWY+zFr5zexOzi8+5w1vzQb4S2+o8ACwWs8++6y++tWvSpJefvnl2gX6WUv6i7dnvz7/NbW5LgAAQA4CPZpCsbXsleI42bX5k5PmvZcLlL29Zh2923RvdDQb9KvJsrL9BuqyedwahELZn2kiUYEbJM/O5lfhj/9k8Tnbr8gG+MtvlDadt8aLohq2b9+uD37wg5KkdevW1eaiz9hjy/N7AAAgAElEQVSmMv/SXPaxznfU5toAAAA5CPRoCuWuny/3vd1u+amUqb7PzCz/mnA4G+glE0Kr3W3ebQAYDDZPx/5ckYjZxWBychWB/sXn8yvwT35/8Tn+n8vfTu6C9oqMG9X1hje8QZ/61Kdqd8E5R9rdZz7nelUT/kcHAADqHoEeTaHaFfpcpXTdL5zuvtT2eZXkbnddye+9nrjfl22bjxVvWvzgm9kK/A++sfj5jefkVOB3SoHO0gZyxJKem5U2+aXtQfO5Vg5n/pB3dC1/HqpjzjGV+dnMHcTNktwifZHt6gAAAKqNQI+GZ1nZJnSSWT9fyTXW4bB5T/caAwMrv6Yw9Fd7PbvjZGcpFGvW1wxCoeyfQzJZZFnBke9LD09lq/DzP1v8Jq+/Lr+ZndoWn7OUA+PSlwel+Zy7M5v8UvegdOsqOh8eGJceSEjXRaRr+5c/95gtfbbP3EyQzGveN1b+NbE2n4lmw/wFkk7LBPrLuMECAAC8QaBHw3O3kHNVukLt95uAnkiYqnApgblwCUC1Q3bu9Wq9VV4thUJmJoJlyax7z91O7tnZxS/4uZ/ProG/Yqf0iq2ru/DnoyZ83zosXRuRzg9I98Ske0bM5+fs8gK2+1pJOpyStgWl7cv8weWGecmM5coe6comvXtTjz4Tlb6b+cvmAkkdkh7OPHcB0+0BAIA3CPRoeNWcbu/y+0tvNGfb+evng8Hqh2w30Le3N1d3+zynXtQdv3Cv3vGze/XOuXul3zm4+JzzLshfB3/h69d+XTfMf2AiP0BfG8mG8gcSpsq+o8RfvgPj+V/PL7MmY97JD/Oux1IEekn333+/3v/+90uSHn30UW3YUIX/rX0lJn0j06TiPJkwL2Wn27N+HgAAeIRAj4bnrh13lRPoYzHTbK3SW9zlcpvVVZO7Rr8Zm+EtOPh/9d6f/Jp0Wc5j69Zn18BfsVN63S9W9pqHkias37Z7cXg+v+CHPZ0sLdAfscwU+lzLVec3+aWt7Wbdfq6jRUJ+C5qbm9Pjjz8uSUqn05W/wDcS0t2ZGzebJe1wL5xzzuVN2rgCAADUPQI9Glqx/edLrYYnk9LIiLkBUKkgnEiY/dJdY2O1mQLv/hyaebq9WfMuPfjc1Xpwfqc+cGcmyG84q3rX/MqQmQ7fXWR6xuGCX75SA3bh67aV0FjvA0lpNCzNn1j+vBaU2+W+4nvQfzdpptpL0lmSLpXkXiI30DPlHgAAeIRAj7q2UjfztayfTyTMDYBKTNF396p3q/PBoHn/Wgfspp1uL0nnbtW33/e0funWCyVJH7iyytd7IGEq6QNTxZ8vnAZfarf7wkBfSlV/eygT6ruzj20lREr5+9BX1KyVDfPrZSrzufcLXsp83uxjyj0AAPDMOq8HABRyHCkaldrapI4Oqbt76W3fCiv0pQZo2zb7mZe6Lr5QImHG1d0tdXZKW7aYMO/zmaq8ZTV5tdwjJzddWLuL/eOImeq+VOAuXAdf6vr5wwVrRH6+xNftCOd3wy+c8o/KmbXM9nRzjgnxl8pMt8/1fOYz29UBAAAPUaFH3YnF8tedp1Lmo7BTvGXlN5+TSg/Rg4MmfK820EtSV85OVcGgGePsrJnGv3+/NDzc5Gvam5m7zv223Us/X1ihL6VB3RFrcQO8Um8ESFKwN3sjYbl194XmHenItFkWMOdIm/3StpC5YcGNgXxzjqnMz2X+nC7R4jAvSScznwn0AADAQwR61J3R0dLOi8cXP7ZUJT9XImGq8xMTq5+iHokUf9y98ZBImI9YzAR7NJhDmbUcS4X0Bwo6He7oKi0Yr2b9fN51csL/thKC5AMJKTWavfngBvgjVnY9/vaQ2dc+PFD6OOpIOp3WqVOnJElnnbXGfgpzjqnMu3vNd8hsUVeMO+We6fYAAMBDTLlHXSmcQi8VX+eeSpnmc8PD+ZXywv3fC1mWNDQk9fdXZ2/4cNiMzeczX8diZvlArdj2yuegRFf2LB3SC6fbX7vEHZ5Cq1k/n8sN/5t8y99AOGZLf9ppttzbFjRb7n0qLX3clgZS0l840kcPmhsRRyzpy4PScEfx7fHq3L333quzzz5bZ5999kKwX7XPRLNh/kItHeafzzmmQg8AADxEoEddCYezYVgyx6lUfiXdsqS+PjPNPRYzlXr3NePjS1fpk0mz5t1tWFctoVD+VP5EYm1T+0vh3vBo9kBv2zVq/HdrzDShK+ZQMn/a/CafmQpfitWuny+03I2AeUe6s1s6NmNC++2J4jMNtodMuN+RuSN2zDZN9xow1FfEZ6Kmq71kgvwly5z7Us4xgR4AAHiIQI+6406l9/tNQHfXxbud5Lu7pfb2/K3a3Nc4jnk+t1LvBvm+Pqmnp/gsgEorDPCjoyvPHqiE2dmVz2lktm3+jHNnZdTcdEHQv7K3tGnza10/L2Ur/Mu97msxE843b5GeK+EOz62x7PG8I322r7wxeeyqq67Svn37tG/fPm3YsMpVZHcNmv3mJek8man2y3G3rNvsM/0IAAAAPEKgR92JRMz6dp/PTItvazMfW7aYoNzfv7hqH4lIBw+aoGdZpvO8+7q+PimdlqamqluZz+X3Lw6dxdb8V0qrVOjdmzGeNhs8NJn/dcnV+TWun5ey1fPlAr27/v+YLf1N3+LrFip8r2N2Q1Xpt2zZop07d2rnzp1qa2sr/w2+kZD2ZBp3bJbZnm4lbqCnOg8AADxGUzzUpd5e82FZJqRalgmtodDSU65DIRP4bNt8pFLmNYHA2gKgbZvKt8+3tq3oCjvyV5L7c3Gc7PfdjNyfoWdbAhabbl9Kd3tp7evn3ffY5Fu+w/1zBdM0DqdWvta2oHQ05xf0Obu8LvqN6huJ7F7zZ8lsT7d+uRdkuIH+sib9Dw0AADQMAj3qWihkPsppYOcG+EqEWssy0/Xddfm7d5e+Hj4UMtvX5b5Xtfj9ZhmC45glBs0Y6C0r++fg2fdXbLp9qSqxfv7w/pWvuaMr/1qljPFowd2mcmcONKJZS7pryByvl6nMF4b5ZyWdLTMN33Um8yHR4R4AAHiOKffAMuLx/CZ7IyOlv7YwwAeDlRnTUtyQu3//8uc1Kne6fXu7hxX6xwt+uKVOt6/E+nn3PVa65geSZgu6K3tMd/uVKu2F45KkrY0TVF944QVNT09renpa6XS6tBfNWmZ7ujnHhPhLld1r3pE0I+l7mc9PF7x2LueYQA8AADxGhR5YRuGa9FLzgrS42361Q2hvb7b5nm17vM68CsYzO8V5Vp0/Ypn15blKDeWVWD//QKK0a27yS79aRsOGRbMOltmurw4dOHBAu3btkiSdPHlSGzduXP4Fc460u898lrIN8GYkHVe2+u5yMo+51fvcQM+UewAA4DEq9MAyCsNjqY3tHGfxmvlIiVuVr1Y4bKrXPl/tmv/VimVlZzxU++e4pMJGceWE8sLXrmb9/EOT0rX9lZ8Of6Dgl+W2KnZv9NqcYyrzz2RuzJwt6UlJD8tMr3fD/MZz8l93PPc9Mp8vaK/iQAEAAEpDoAeW4YbHUEiamSk9TBYG//7+2lSWBwelEydMpb5whkAjc3+e7e0eVugLt4Arp2lc4WvLXT9/KGlmB5Q6xb9UU/H89fbvG2uo6rwkvfWtb9VTTz2lp556auXq/F/1men2rpeU3VN+s096a780dHd2K7pNmcXzuYHePZ/p9gAAoA4Q6IFlBAKmEZ5lSdFoaSHZskygdgWD1d2yLpfbPNBtjtcMbDs73T4WW/7cqiqcbl9O8D2yxqZzDySkre3lNeEr5T2/kmkKt8ln1ttf59X0h9U766yzdNFFF+miiy5a/sTPRKVHi2zhd3WP9Ftj0mcd6T8kpGdmpROZhfM3ZDrgu9PuJen5zGem2wMAgDrAGnpgBYODpot8NCp1dJiv+/uLr1FPJKShoWzw7+kxjy211V6lBQJmbOPjZhy9vbW7drW4Id7nK2+3g4pby1T3wsZz5TSdO2ZLhyalW4dXf/3DKUlt0lHLTDs/kDDv626796vx5u5sf9eg2aLOdXWPdE2v+dhc8H3vzdyN23mH9LYhae+d5utnJeWeyh70AACgDhDogRJEImaqdyyW/Sjc3962s030gkFzjhcBNBYzgT6dNjMDPK1qr5Fl5VfnPb05URj8SjXvmLBcrJt8Ke6JmeDdXeJ+iYWOWNJod/HntndKr+lc3fs2im8kpD2j0iVBqSsiXd279HT5fZ/Orq+/ecCcd0lQemLaBPrNOecy5R4AANSBtnTJ+/wAkEz1PZUyYTOVM4M3FDIBPxz2cFu1jFgsu8XewYPej2e1urvNz7i9ffGOAzV3KCn9TV/261uHpVtLuFtyT0y6p2C/w4Gp0hrjHU6ZMF7qtUp1zDbvfU9Mem7W3HC4LmKu02CV+p/+9KeampqSJL373e/WunU5K8lmLTPNfrkQn+sjl0k/+YH0ltul//g589ieeHa/+gtkgr0kfYH/dQIAAO8R6IEm5DgmxM/Oms8HD3o9ovLl3pSYmvKwGV6uj/il+RPmeHtI+ugKP9h5R/rDDlNhf242+/htu1euuM87Jsyn09J/tpY/d7XmHSkelo5m1vhvD0l3TDRUY7x9+/aVt23dUr6RMOvsJekT35U6rjbHz9jSYGZvu/Uya+kvCUp/UqU/EwAAgDLQFA9oQn5/dus6yzLr/htJKpUN8wMDdRLmpfwq+RFr8f7yhUa7JaWlgZS0oyv7+D0jy0/Bd8P8sRnp9iruQbjJLw2mzA0HyXxPf9q5+uUBHti4caO2bNmiLVu2rO2N9mTWzl/7a9kwL5nK/mWZP7szOY8BAADUAQI90KTCYWk400dtdLRx9qa3LKkvM7Pd7UVQN7oHzV7wrr/pW7zHvGQCsfvcbXFT8X5fIhuc5x3prmjx4OxOsz82Y24ElLM93mps8kvX5nS3d8feIG644QY999xzeu6551Zfnb//77Lb2d0yUOQiBd3/aYgHAADqBFPugSbX2ytNTprjsTHT4K9eOY5ZN29Zpqu9ZRXfTcBzU3Gz/tydfr8jnF0Tv1C5T5swn7sV3DFb+nwku/f7Jr953faQCdLua7cFTWW+2mHe5Vbmc330YO2u77XhN0uPPyBd9Q7pw/+w+Pk5R7ojZwbAf51i2zoAAFAXCPRAk3McU62fziyTrtdQ71bmbduE+VSqzpv5zTvSdNIE8OfsbEjfFjQhvXtw6bXoRyyzD/xRyxzPnzCvOz9gtpHzYj/432nL/zo8YLaza3bfTUq7MzMS/uCfpStuLH7eX/VKD2bujMVnmHYPAADqAoEeaAGFoT4eN2vT64Vlmcq84zRImK9Xh5LSVGYtePeAuTlQqsJAv6PLTPlvdp/oNp3w3/TL0kf/aenzcpvm0eEeAADUCdbQAy3A7zchORg0Xw8Ommq4Uwe9z0ZHCfMVccw26/IPp8zHUuv7m8yPf/xjDQ8Pa3h4WGfOnFn5Bbmm95gwL5l955dzTebmyGVdy58HAABQQwR6oEW4ob4/09MtmZQ6O81jXnAcc1NhcNAcB4OE+TV5zl7cZO9QcvXvt6Mx1ojPzMzo4x//uD7+8Y/r5ZdfLu/FezOzGS59q9T59uXP3eyX3tovXcBUewAAUD8I9EALcbez273bfG3bpjoejZrjWhkdlTo6zE0FSerpIcxXRamhvFglv0ECvc/n0/XXX6/rr79ebW1tK7/A9WjKVOillavzrmt6WTsPAADqCmvogRbl7k+/f3/2sUjEbHVXjc7yjmO67cdi2ZsHPp+5wdBbxlJvLGHekf4wYBrsbW03jfVuLXHPvy8PSqnR7NfbgtJ/bvLp+rv7TEO81/6C9Ef/UvrrZi22rQMAAHWDCj3QokIhUxUfGzPBWjLhuqPDTIUfH6/MGvv9+6WhIfO+kUg2zPf3m2PCfIXk7ie/c6j0MD/vSAfGc97HZ7bMa2aPP2DCvFR83/nlEOYBAEAdoUIPQI5jOt8nEtLsbP5z4bD5CIXMOvflqveOYzrpW5a5WZBKZW8K+HzSiRMmyMdidbq/fDP4k5B0dNpU6G/bbYL+UuYd0zzvcE4jhQ9MlNcdvxF96tel+/9Oes2bpD895PVoAAAAVo1ADyBPImHWtk9OLn9eOGeJtW0vvwY/GDTT+3t7zTp+VJk7hX6TXwr2moC+oysb7ucd6dCkdE/MdMeXzDT72xPS9iavQM9a0h90muM7/qcU/k1vxwMAALAGBHoARTmOqbAnk6bi7u5h396+uIpfqL3dVPTDYRPiqcZ74JhtAvuhpFlXv5RtQal70FT0G9BDDz2kP/qjP5IkffGLX9T69euXf8FnomZP+Yt2SP/tsRqMEAAAoHoI9ABKZlkm6Lufc7kV+1CIKnzdOWKZbe3cbvab/KYSvz20/JT8BrBv3z7t2rVLknTy5Elt3Lhx6ZN/8gPpI5eZ48inpF/+YA1GCAAAUD0bvB4AgMbhbisXbowdzeByw3sTro2/+OKL9Zu/aabNr1u3Qp/XPZlO/ue/hjAPAACaAhV6AEDze8aWBjvM8Xv/Urr1w96OBwAAoALYtg4A0Pz2Zqrzr3yVdHOZW9UBAADUKQI9AKC5OU9np9vfPCCtZ7UZAABoDgR6AEBz2zsqpdPSpvOkW6jOAwCA5kGgBwA0rAMHDuiNb3yj3vjGN+r06dOLT5hz8qvz57yitgMEAACoIuYdAgAa1gsvvKCHH35YklS0x+ueUenkvLR+I9V5AADQdAj0AICGtWPHDv3lX/6lJGn9+vX5T556MVudv2VAOu+CGo8OAACguti2DgDQnL76Z9LffdQcf/JJaet2b8cDAABQYayhBwA0J7c6f9PvEOYBAEBTItADAJrPnlHJecocs+88AABoUgR6AEDz2Zupznf/e+mi13s7FgAAgCoh0AMAGta9996r9evXa/369Tp16lTmwc9I/zpjjqnOAwCAJkaXewBAw0qn03r55ZfzH3TXzv/S+6TXvLH2gwIAAKgRAj0AoGGFQiF97WtfkyRt2LBB+ua4dPRR8yT7zgMAgCbHtnUAgObxX66S7IPSL/6qNPB/vB4NAABAVbGGHgDQHB74exPmJarzAACgJRDoAQDNwV073/kr0hve4u1YAAAAaoA19ACAhjU3N6cnn3xSr/jhPm07fL95kOo8AABoEVToAQAN6/7779ell16qx+78oHngjbvMBwAAQAsg0AMAGtrNPyd1X5j5guo8AABoIXS5BwA0rBdffFHpP3ubNj2WMuvm//CbXg8JAACgZlhDDwBoWOfYB6THUuaLm6nOAwCA1sKUewBA49pzp/n82muka3/V27EAAADUGIEeANCYfnRA+s7d5pjqPAAAaEEEegBAY8pU53/mu0TJZ1+hl19+2eMBAQAA1BZN8QAAjeeJaek/hyRJdxyQ/uePpJMnT2rjxo0eDwwAAKB2qNADABpPpjo//8pt+sJPNmnTpk0eDwgAAKD2CPQAgMby1A+l/X8rSdrU91HNzc1pbm6O6jwAAGg5BHoAQGNxO9tv3S7d9DvejgUAAMBDBHoAQON4dlb65782x7fQ2R4AALQ2Aj0AoHHszVTnz7tAuvlD3o4FAADAYxu8HgAAACU58a/SnlFzfPOAtOEs2batL37xi5Kk3//939e6ddynBgAArYNt6wAAjeFL/0Wa/GPpnFdInzoqbXql9u3bp127dkli2zoAANB6qNADAOrf/M/yq/ObXilJOu+883TVVVdJktra2rwaHQAAgCeo0AMA6t/EH0lf/kNp3Qbpvx+VXvlqr0cEAADgORYbAgDq2+mT2er8LR8izAMAAGQQ6AEA9W3PqPTCMXPMVnUAAAALCPQAgPrmVud/+bel8y/xdiwAAAB1hEAPAKhfez8pHT9qjotU5x9++GHdfvvtuv3223XmzJkaDw4AAMBbNMUDANSv33299NMfSeHfkO74X4ueZts6AADQyti2DgBQn6Y+a8K8ZLaqK+Kiiy7Se9/7XknSunVMOgMAAK2FCj0AoD79/hulIw9Lv/TvpN/+gtejAQAAqDuUMwAA9edbd5kwLy1ZnQcAAGh1BHoAQP1xO9v/wruk1/2it2MBAACoUwR6AEB9OfB/pJkHzTH7zgMAACyJQA8AqC9udT50q3TpDcue+p3vfEfXXHONrrnmGp0+fboGgwMAAKgfdLkHANSP731Veuw+c1xCdf5nP/uZHnzQVPPp8QoAAFoNgR4AUD/c6vwVO6U33bTi6a973ev0iU98QpK0fv36ao4MAACg7rBtHQCgPjz0delPMyH+w5PSVe/0djwAAAB1jjX0AID6sDdTnf/56wnzAAAAJSDQAwC894NvSge/Zo7Zdx4AAKAkBHoAgPfc6nzHVdJ17/Z2LAAAAA2CQA8A8NaPvyP9y1fMcZnV+VQqpXPPPVfnnnuuTp06VYXBAQAA1C+63AMAvOV2tt92ufTW95f10jNnzmhubq4KgwIAAKh/BHoAgHeefEi67wvmuIR95wtdeeWVuvvuuyWxbR0AAGg9bFsHAPDOZ/+9lPpf0qtfK+3+kdejAQAAaCisoQcAeOPpwybMS6uqzgMAALQ6Aj0AwBvu2vktF0s3f8jbsQAAADQg1tADAGrv2JPS1/+7OV5Ddf7FF1/UT3/6U0nSJZdcora2tkqMDgAAoCFQoQcA1J677/wrtpa9VV2u++67T4FAQIFAQKdPn67Q4AAAABoDgR4AUFs/eyY73f6WAWnj2d6OBwAAoEEx5R4AUFt7R6Uzp6WzN6+pOi9J1113nR599FFJ0oYN/C8NAAC0Fv71AwConRefz1bnbx6QNvvW9HbnnnuuLr300goMDAAAoPEw5R4AUDt7RqUXX5DWrWOrOgAAgDUi0AMAauPMqfzqvO9Cb8cDAADQ4JhyDwCojT2j0vPPmuMKVeePHTum73znO5Kkm2++mW3rAABASyHQA4CXjtnSQ5PStqC0I+z1aKrLrc7v+o/SBe0VeUvLsvS2t71NknTy5Elt3LixIu8LAADQCAj0AOCVBxLS56PZr6+LSO8b82481fRPn5KeO2KOK7h2vq2tjao8AABoWW3pdDrt9SAAoCV9xC/Nn8h/7KMHpe0hb8ZTTR/eIT39uNQVlT7wt16PBgAAoCnQFA8AvFIY5iVp3qn9OKpt6n+aMC+ted95AAAAZBHo0XJsW3rXu6T166Wrr5Ysy+sRoWXt6Mr/emt7c66j35tZO3/9r0vtQW/HAgAA0ESYco+Wc9VV0vR09mu/Xzp2zLvxoIXNO9KXB6VDSRPkb40133T7+z4v/fXt5njkAen113o7HgAAgCZCoEfLWb9+8WP79knhJiyMAp772C9IP/6udE2fNHR3xd/+iSee0Fe+8hVJ0sDAgNatY+IZAABoHQR6tJytW6UTBUuXjx0zlXoAFfQvX5ZGf80c/9eUdFnX8uevwr59+7Rr1y5JbFsHAABaD6UMtJzdu/O//qu/IswDVeHuOx98W1XCvCSde+65uvzyy3X55ZezfR0AAGg5VOjRkmzbrKNvb5dCTbZkGagLB/+v9JfvMMe/v0e68mZvxwMAANCENng9AMALgYD5AFAle+40ny/vJswDAABUCVPuAQCV9f1/lr7/dXN8C/vOAwAAVAuBHgBQWXsz1fkdb5au7vF2LAAAAE2MQA8AqJwffkv63lfN8c3Vr87/4Ac/0B133KE77rhDZ86cqfr1AAAA6glN8QAAlXPnu6UD/0cKdEr///eqfjm2rQMAAK2MpngAgMqY+a4J81JNqvOS9OpXv1q33XabJGndOiadAQCA1kKFHgBQGf/j/dK37pK2XSb9+SNejwYAAKDpUc4AAKzdke+bMC/VrDoPAADQ6gj0AIC1c/edf1WHdONveTsWAACAFkGgBwCszU8fl6Y+a47Zdx4AAKBmCPQAgLVxq/P+n5Nu/lBNL/3ggw/qLW95i97ylrfo9OnTNb02AACA1+hyDwBeOWJJn4+az5v80m27pesiXo+qPM8dkf7pk+b4lgGpra2ml3ccR/fdd58kiR6vAACg1RDoAcArd0Wko9PmeN6RvjIkBXtNuG8UezPV+XO31Lw6L0kdHR362Mc+Jolt6wAAQOth2zoA8MrvFKlmD0xJO8K1H8tqPP+s9DvbpNMnpdti0ruGvR4RAABAS6GcgZY0Pi69613SnXdKjuP1aNCyNvkWP7Y9VPtxrNbeO02YP2uTJ9V5AACAVkegR8sZGpJ+4zekyUlzfNttXo8ILWsglR/q3zfWONPtX3pB2jNqjm8eMFPuAQAAUFNMuUfLWb9+8WMPPiiFGqgwiiZzOGUq840S5iVp8o+lL/0X0wTvU0dNh3sAAADUFBV6QJK/gXIUmtCOcGOF+ZdP51fnPQzz+/btU1tbm9ra2nTq1CnPxgEAAOAFAj1azjvfmf91V5cUCHgzFqAh7blT+tm/muNbWDsPAADgFabcoyWNjpo19D09Un8/FXqgLB9ql449Id34H6Tf+B9ejwYAAKBlEegBAKX7+l9LiQ+a4794RLr4Mm/HAwAA0MKYcg8AKN3ezNr5GyKEeQAAAI8R6AEApUn9rfTUY+aYfecBAAA8R6AHAJTGrc6/+T1SoNPbsQAAAIBADwAowbf/t/TEIXNMdR4AAKAuEOgBACtz952/ulfa8WZvxwIAAABJBHoAwEq+c7f0o38xx+w7DwAAUDcI9ACA5bnV+StvkS7v9nYsAAAAWECgBwAszbpH+sE3zDHVeQAAgLpCoAcALM2tzl8WloJv83YsAAAAyEOgBwAU9/C90kP/ZI6pzgMAANSdDV4PAABa1rwjTY1Kh1PS+QHptt3SJr/Xo8py951//XXSNX3ejgUAAACLEOgBwCt3RaRDk+b4sKQjlvTRg54OacFj35Ye/AdzTHUeAACgLjHlHgC84oZ51xHLVOvrgVudbw9Jb/51b8cCAACAogj0aEm2Le3fbz4DdaUeptzb35Me+JI5viynsfYAACAASURBVJnqPIB8juNofHxcNv8TBQDPEejRcsbHpauvlnbulF73Oml01OsRoWXdOpz/9bX90vaQN2PJ5Xa2v/hSqSvq7VgA1J1YLKZIJKLOzk6vhwIALa8tnU6nvR4EUEtbt0onTuQ/9qMfSYGAN+NBizuUNFPttwak6yJej0Y6+oj0n64wx9G/lnb9R2/HA6DuhMNh7d+/X5LEPyMBwFs0xUNLcZzFYV4yU+8J9PDElb3mo1641fkLAoR5AACAOseUe7QUv18KBvMfa2+XwmFvxgPUlX/9sXTv35hjOtsDAADUPQI9Ws7f/q3U1WWOg0Hp7ru9HQ9QN9zqvO9C6ZYBb8cCAACAFTHlHi0nFJLuvdfrUQB15vhPpL13muNbBqQ27vcCAADUO/7FBgDIVuc3+6Sbqc4DAAA0AgI9ALS6F56T9mYC/S0D0tmbvR0PAAAASkKgB4BWt3dUOvWStPFsqvMAAAANhDX0ANDKXprLTre/eUB6xVbPhpJIJDQ7OyvHceT3+9Xf369AGftJxmIx+f1+DQ4OVnGUWKv9+/crlUot/DmHQiH19PTUfByO42h0dFSO46inp0dhtjtBhm1L09OSZZmPUMhsbdvVtfIWt44jTU6a9yj3tU1v3pEO75eOWOb4/ID0ph7zudYOp6RDk9Imv9Q9YD4DDaotnU6nvR4EAMAj//An0t//gTn+1FFpy8U1H0IymdTQ0JBs2170XDwe18DAyrMGksmk+vr61N/fr0QiUY1hYo1SqZSGhoZkWdai50KhkMbGxhQKhcp+X8dxFt43HA5r9+7dK77Gsix1d3fLcZyFxyYmJtTb21v29VtROBzW/v37JUnN9M9I25ZGRqTl/goZHJSGh802uIVGRqR43IT6cl/b9FKj0tdiJsgX6h6Ublv5v9uiDiWlqVHzvrcOS1eW8N/wPTHpnpHs19tD0sAUoR4Niyn3ANCq0i/nVOc/5EmYHxwcVF9fX9Ew7z4fi8WWfQ/HcRSNRuXz+RSPx6sxTKxRIpFQd3e3jh8/romJCaXTaaXT6YXwXSxgl6qzs1OJREKWZSkejyuZTK74mr6+vkXXGhoaKvvaaB7JpNTZKU1MSAMD0sGDUjptPo4fl/r7zXnxuNTdvTi0R6NSLGYq8TMz2dem0+Y929uzr205n49KXx6UdnRJIzPSp9LSXxw3X0vSVNycU67DKelv+sznI5Z0VwnvcTiVH+Yl89oHuBGMxkWgB4BWtWdUOvFTc+zBvvOxWEyjo6MrnjcyMrJs1T0cDstxHCUSCflbsvRV31KplKLRqILBoCzLyquCRyKRhWPHccpeLpFMJhfdDFrppoBlWUVvINm2veSNJTS3RELq6zOh27JM8M6dLOL3m3PclSGWZc53RaPm+bExc2Mgd2q9ZUmjo9LsbPbrlppE9PmoCcvvG5M+kMxOr9/kl3bkLHN5IGHCdjkKQ3ix6n+hpa5xaOUbgUC9ItADQKtyq/M7PyC9+rU1vXQqldLIyMjKJ2ZEo9FFod6tzE9PT6u/v5/p0nUod/ZEKpVadMOl8OvJycmy3j+VWvyP85XWwgcCAfl8vqLPEehbTyJhAnlPj5RKLb/OPfd+UyplXut+DAxIOfenJJkqfne3OTdXkV/b5nQoaUL3tf3SdZHFz28t+GFPlxmqDxX8feFW/JdTeE3X/Inyrg3UEZriAUAr+uf/IT2bKRl5UJ3Prcy6YTwcDsvv9y9USpPJpJLJpGYzpa1oNKrx8fG8irzjOAoGg55MtbdtW5OTk6uaJu4Fv9+vnp6eshoNrlUsFpNt25qYmCg6e6JYdd227ZLH6K7jdrW3t6/4Wr/fr3g8rmh0FVN80VQsy4T5YNCE8pUm+BTeKxoZMaHd5zPT7QslEsXX07fERKJ5x0yB3+STfnWJv5+fK7iBdnRxf40luY31cu0oobHldRFTpT8wnv/4sZnSrw3UGQI9ALQid9/5t75f2nZ5TS8dj8c1Ozu7ULUtbIQWCAQUCAQUDocVj8dlWZYSiYRSqdTCh2upym8tdHZ2NkyYd8ViMR0/frwm17JtW6Ojo+rq6lpy9kSxCnupP1PHcRY12Cu1U717Q4lQ39qiURPGk8nVhWz3ftRSje6WqsSvovdj45mKm8D9vrGlm82VO8V+pdeWEugl6faEuZlwOOeG4PZW+ENBs2LKPQC0mv1j0k9+aI492HfenTpfLMwXEwqFFoJ9Op3W8ePH5ff7PQ3zUmN2967lmN1mhpHCecg5igX6Ujvdr2a6fa5IJKKurvwpumxd1zoSCVOhHxxc+3ZyS7V+KPbr1NW1eGp+U5oaNdX5YlPtpewWdrmWmg5fzFoCvSS9r5UaGaDZUaEHgFbjVueve7fUcVXNL2/btgYGBla9RVl3d7fS6XTJNwSqxbbtoluw1bNaTrefnJyUz+dbMtA7jqPx8fxpr+XsR7/WQC+ZXRTcaftLratHcxoaMtX5cvowFvvPvadn6er+4KCp4rsbL0Qi5V2vYT2QMIE9vMwN42Lr5YNl9EEpvBlQyvr5XOcHzNp+d+p9OTcDgDpDoAeAVnL/F6XZaXPsQXVeKn1KdbHXdXd3a2ZmxvMwL5m12FR0i0smk3IcR/3uXl9FFNu5oJzGhqtZP7/c9cr9fXIcR5OTk0qlUrJtW+l0Wm1tbQoEAgqFQjXvV4DSuWvbBwbKm2pfrGfiSn8FxOPmo6W4HeOXqs5LZl/6XJt8pYfq1a6fLxTszQb6cmYHAHWGKfcA0ErczvZXv1P6+eu9HUsZ3DBvWVZdhHksz62eLxfQC6vzPp+v5EC/lvXzhdxp96W+3nEcDQ0NqaOjQ5FIRBMTE/L5fAqHw2pvb9fBgwc1ODiojo6Ohd9Z1Bd3cke5U9+LrYmv53t6+/fv19vf/nZt3rxZr371q/W7v/u7tbnw4f3S1val16Ufs00oz3Vl79Jr7Re9/xqn27tyr8caejQwKvQA0Cq+OyE9fsAce1SdXw3bttXX16eZmRlNTU0R5huAW6FeKqAXW67Q29tbcj+ESky3L1TK71XujSVJGh4eXugVUDi+WCymVCqlzs5OxWIxDQ8Pr2l8qJxAQOrvL785XeG9GZ+vfhvcHThwIO+/ifn5ee3evVszMzOamJio7sV3dJmAvpSpIlMWlqvmF6pUoHdfs8lHoEdDI9ADQKvYc6f5/KabpCt2ejuWElmWVTdr5lG6SCSybDO8YtsMLnd+IS8CfWGYP3jw4JKvCYfDSqVSikQiGh8fVywWk8/n02CNF1A7jqPR0dGiP6+1mJ6eXjju7u6u6HsHAoFV99goVbEt5kpRsMqjrqvzn/zkJ4s+nkwmtWfPHt1yyy3Vu/gHVthP/qGC/eO3tpcXyNe6fn7hfTL/XRDm0eAI9ADQCqb/UXo0848XD/adXw3CfPOanMz/B317e3tZgbwS6+dz36uU10cikbzKfCm/j+52i7OzsxoaGlIgECirT8BauTMFqn2NSjt+/LiSyRVCYY012nT7++67b8nnvv/971c30C/niGWm3OcqpzpfqfXzUvZ9aIiHBscaegBoBW51/tIbpNCt3o6lBIlEQp2dnUvuVY/GZVmW7ILuYuWE3Equn3ffZ6XXp1KphZsQ5VbacwP10NDQKka5eqFQqCG799fypkepGi3Qt7e3L/ncJZdcUsORFHigyHZx13ow3V6SHsu813LLA4AGQKAHgGb3yJR0aI85boDqfDweVzQaVTAYlGVZhPkmU6y7vVfT7Utp3iflh/Jy1voXvrdt20W//2oJBAJyHEfpdLqiH24jQUkVf+90Ol3W70OtFP7a1fP6eUl673vfW/Txiy++WH19fTUeTY7C6fbbgmYLuVJVMtA/vp/182gKBHoAaHZudf51vyj9wru8HcsKIpGIhoaG1NXVpVQqVVZwQmMoNt2+nJs21Qj0y73etu28Kf7lTu33+/0KBoMLX4+Oji5zNupVI62fl6Q77rhDH/nIR/Iee+1rX6vPfe5z2rhxozeDWut0e6ly6+fnHTMeptujCRDoAaCZHb5fejCzFrXOq/NuA7H+/n7CfJOybXtN0+2lyq+f7+rqWvZ3rXAt92puHuS+f7ElB6hvjTbd3vXnf/7nmp2d1d///d/r61//un70ox/pxhtv9G5AxabblxOoK7l+fjrz3zXT7dEECPQA0Mz2Zqrzl1wpXf/vvB3LEhzHUV9fn8bHxzUwMFDTKcmorWKNzrxaP59MJuU4zorXr0RztsIxVqORHKqnUQO9ZNbLv/vd79auXbu8HoqZ4p5rub3qi6nkdHv3vYIEejQ+Aj0ANKvZg9L9f2eO63TfeXcrsGQyqbGxsaLbmdWroaEhtbW1NdRHNBr19Ge21unylZxu7wb1lQJ94YyAtW6PJ2nRTQnUt0ZbP1+X3CnuucoN45UM9IcmpSt7pE3MBEPjI9ADQLNy187/3M9L4d/wdixF5O7rPTY2tupGWPF43JOA1Eg3H1xez37I3b9cUl5ztVIU+3NebcCenJxUMBhcdrp+tabGE+gbSyXWz4+MSC39x14Y5qXyw/jR/L8/Vr1+/oGEucHAdHs0CfahB4Bm9JNHpW9kwlsdVufdMD8zM6OJiYlVb1OVSCQ0NDRU8r7glTQ8PNxwU6crUV1ei8KAXO6fWbGAvZr184lEQo7jaPfu3WVfrxJmZ2er8r6ovGIrLsr9zyiZlGIxKZ1u4cp+sUBfTnd7aXFDvW2r/GEeyvyhMt0eTYJADwDNyK3On3+J9Mu/7e1YCjiOo87OTh0/fnzNe8y7VXIv9q3O3coMq1Nu48PCgF1uhd81Pj4un8+34u+N4zjLPl+qwt9xmuI1jkqsn3cnxnjw11T9KGxmJ629w/zmVUyXP2ab6fbX9jPdHk2DKfcA0GyemZH2fdoc11lne7cy7+7HvdYwPz09Xfa2Z2htlmUplUqVtJ98pabGs2NDfRkdlfr6pO7u4hX4XIXT7aXyquyOI01OSu3tLVydr5atq9jd4p7Mjdhyt8sD6hgVegBoNm51/pWvlm75kLdjyVG4Zn4tVXV3qr1EpbyVnDhxYs3vwe9Na+vszF/LnkpJBw8WD9u2vXjdezBY3vUGB83nlv91K6ebfTGF0+2l1U3ZPzRp1t6z/zyaCBV6AGgmzlPS3lFzfMuAtK5+7tuGw2FZliW/36+RkRG1tbWps7NzYcu6Uqc3x2KxhW7tXV1dq26mh9oLlpuGcqRSqTVXzFOplFKplPr7+1e9dz0aVyxWvDHdUlX6Yn0vy5lsYVnS+LjU1SW1/F9TxarpxUL6Uu4pckekWNf75XxlyEz9v7XV766g2RDoAaCZ7LnTdF7a9Erp5vqpzkcikYUO5+l0Wu3t7erv79fx48eVTCYViUS0ZcuWJcO9bdsaHR1VR0eHRkZGJEk+n8/zru0oT2FTvnICuvvnnqtwS7nlOI6jaDQqn8/XkDsUYO2W6mFZrDrvOCaM+3z5j5c6ScRxpGjUvJ6/pmQq9Fvb8x87WuJ//8ds6cD44sfnyuhxcThlmuGFB6jOo+kQ6AGgWfzb8fzq/Dmv8HY8GYlEQuPj5h9jw8PDsm1bqVRKiURCtm1reHh44dzccN/W1qaOjo6Fz4ODg3nNxOLxOFXWBjM4OChfTkKanJwsaWZGPB5XKpXSwMDAokZ4yZUWQWf09fUt9G5gTXtrKvar1t5evMldNGrOTySk/v7s45ZV/H0KrzM0ZM6NxyX+msroHsz/emq0tNd9ts98ft9Y/uPFQn4xRyzpb/rMDYW3U51H8yHQA0Cz2HundHJe2nBW3VTnLctamB4/NjamWCy2KEzFYrEltw9bqhv47t27mWrfgAKBwKLquPv7sZRkMqmhoSEFg0HFYjHF4/G8mwJDQ0PL3hRwK/OpVErDw8Oe7IjAvvP1obASHwya6faF93eGhszj/f2mM30sll+pX26Ch22bZnuJhDQ2xlT7PN2D0racZTeHU2ZP+OV8PmoCeXjANLIL5zR6nXeKT8XPdcSSRrslpaUPJOlsj+aUBgA0vpfm0uk7tqTT/07p9P/+iNejWRAMBtOS0mNjYyue29/fn5a04kcp74X6NjY2lvdnGg6H0wcPHlx03uDgYFpS2ufz5T0/MTGR9vl8C68PhULpqampRa9PJBLpQCCQlpQeHh4ue5xTU1OLfv9WY3h4uCLvUy+6uroa8vs4eDCd9vnSaSmdDofT6ePH85+fmUmne3vN8/39+c9NTWVfK6XThX8NHT+eTsdi6bTfb87jr6klzB1Pp/84mE5/UNmPr8XM47mePJhO/0nIPP+5gj+Mz/Wv/Pq54+n0lwfN87/nM+8HNKm2dDqdrtG9AwBAtXz1z6S/+6g5/uST0tbt3o5HZqp9NBrVwMBAyWuWI5HIwvT8Ql1dXYrH42xR1yQsy9Lg4GDeOni/369QKCTHcRaq2l1dXUomk4tmdhR7fSAQUCAQyHt9e3u7EonEovX7pUilUuru7s57bDX/bIrFYnk9AILBYENX7cPh8MLPvdH+GWlZpuo+O2u+DoVMhd5xsg3zhoeLd6W3LFNxz7QDkd9vXp/72q4uU8Hnr6kVTMXNx3Oz2ce2h0wF/YiV3bc+PCD9P/buP7jt/L7v/Iuxa8cmM4DWbbiNvSVFdpM6aQkqPdcONynJpOLuxO2QUJNpphcuweaaSm26guaou2Y8LcFO46YnTkXupUfVbU7QcjM5exIR7MXNLpiUX6VZrp1zTl/wkjqxDQnKblIh8VpfNVC2sZ3w/vjoC3wB4scXJED8ej5mOAJJfIEPAZDC6/v+fN6fHyjz/8d+Qvq5aPHx7tp47/EfXjDHU5lHFyPQA0DHO5D+0ftNh/uZfywtvNjqAUkqrHuud82yZVlaW1uT4zj5gDc1NXWkQIb2l8lklEgkZNt20RKL4eFhzc3N1Zwif9zjq3EcR6dOnSr6WiMC/ezsrO+1/+2okwO9K5EwTfK851Xm5sxHrTXvpce6wT4SYb183fYTJoCXdqx/ekr6cKT21nSVjh+bMx/1bm0HdCACPQB0ulfWpc3HzYb+9Relwb/Y2vEAXSQYDOqhp7X57u5u3SeXSgP98vKyYh28MXk3BHoA6BY0xQOATvfK407B03+fMA80WCNmhpROr2e2CQCgUQj0ANDJfvnfSn9w11x+rj062wPdpHTK/lHWvnuXAgQCAQI9AKBhCPQA0Mncfee/e176wF9u7ViALlQa6CttpVhNyu2iVub2OtEwC8UBoG0Q6AGgU/3KDel3P28ut8m+80C3CQaDWlhYyH++vb1d1/Glze+i0WhDxtVK0WhUk5OTWl5ebvVQAKDn0RQPADrVx75TytyWPvyD0gufavVogK6VyWQ0Pj6eb45XT2M8bwO5Tu9uDwBoP1ToAaATfeaTJsxLVOeBJhseHi7qSr+4uCjHcWoel0gk8mE+EAgoHo83bYwAgN5EoAeATuR2tv/OvyV923e3dixAD4hGo/mp95lMRtPT01VDvWVZWlxclGTCvGVZCgaDJzJWAEDvINADQKf59W3pi6+by1TngRMTj8fz68Zt29bp06e1vr5e1CjPDfJu4A+FQrIsS+Pj460aNgCgi7GGHgA6zU98r/RfdqW/fFb68WSrRwP0nEwmo1gspkQikV9XXyoUCikajSoSiZzw6AAAvYRADwCdZP9V6V89Zy4v/d/Smb/Z2vEAPc62bTmOo0wmk9/ObXx8nOn1AIAT8c5WDwAAUAd37fy3fQ9hHmgDTKVHL3EbPdq2LcnMVnGXnExOTsqyrFYOD+hJBHoA6BSfvyWlftFcfo618wCAkxWJRCouM2FWCtAaNMUDgE7hVudHPiT9tR9o7VgAAD3Htm3t7u5qd3dXs7OzRd+bmppq0aiA3kaFHgA6wZc+K31uy1ymOg8AaIHh4eF8rwjLsrS9vZ3/HoEeaA0q9ADQCV59XJ1/6q9Iz/xwa8cCAOh53vXygUCAfhJAixDoAaDd3UtJez9rLrPvPACgDdy6dSt/meo80DoEegBod251/smnpen/qbVjAQD0vNJu9gR6oHUI9ADQzv7rb0u3rpvLVOcBAG2AQA+0DwI9ALQzt7P9+56SZn6stWMBAECsnwfaCYEeANrVl+9Jv7RhLlOdBwC0CdbPA+2DQA8A7cqtzn/Tn5Oeu9jasQAAIKbbA+2GQA8A7ehhttAM77kXpHf8mdaOBwAAEeiBdkOgB4B29Mq69Kd/Kn3jN0nPUp0HADRfPB5XOBzWmTNn1NfXp1OnTikcDheFeNbPA+2FQA8A7eaPHhZX59/zTa0dDwCgqyUSCZ06dUqLi4u6ffu2Jicntbu7q+XlZT148EDT09O6dOmSJNbPA+3mna0eAACgxKvr0h//kZlmT3UeANAkjuMUVeAXFha0tramYDAoyQT2aDSqWCymlZUVZTKZouMJ9EDr9R0cHBy0ehAAgMe+9sfSj32LlPuK9NH/Wfq7q60eEQCgCzmOo+npadm2LcmE+Xg8XvH6U1NTRdV5Sbp9+zZT7oEWI9ADQDv5hf9N+tn/1Vx+8XfM/vMAAN8WFxcPVZK70dbWVr6SXq/SMD87O6tEIlH1GMuyND09nf88EAjIcZwj3T+AxmHKPQC0E3erurP/iDAPAHWyLKtqlbmbxONxRaPRIx0bjUbzYT4QCPh6zEqn1zPdHmgPNMUDgHbx6ovSg98zl9l3HgDqNjw8rEAg0OphnIgbN24c6bh4PF50bDQa9VXpZ7s6oD0R6AGgXbjV+akfkZ58urVjAYAONDw8rFgsVvH7y8vLOjg4aNnH3bt3tbu7q93dXV29elXLy8uanJzU0NBQ3T+rbdtHWlpQ+vhEIhFfxxHogfbEGnoAaAf/6RPST/8Dc/kn96Wn/kprxwMAHWxubk7b29tlv7e7u9uWYdRxHFmWpUQiIcuydO/evZrHXLx4UWtra77vIx6Pa3FxMf+5n7XzLm9TPNbPA+2DCj0AtAO3Ov/M/0iYB4BjisfjFave4XC4LcNoMBjU3Nyc4vG4MpmMdnd3tbCwUPWYSictKildK1/PiQ32nwfaE4EeAFrtP78k/e5/MZdZOw8AxxYMBis2enMcp6hK3a6mpqYUj8d19+5dXbxY/v+GTCbju8LuOM6hbef8BnOm2wPti0APAK326ovm37/2t6WRD7V2LADQJaamprS8vFz2e4lEoq6p6q00PDystbU13b17V5OTk4e+7zfQu13tXYFAwPce8gR6oH0R6AGglT77Kenur5vLz1KdB4BGisViZUOwJF26dOlQyG1nw8PDsizr0EmK7e1tX0sIShvo+Q3zUnGgr+dEAIDmI9ADQCu98rg6f+aj0l/6ntaOBQC6UDwer7iV3eLiYluup68mFovp+vXr+c8dx/FVpS8N9I1cP59IJHzPFADQWAR6AGiV//c/SF94zVymOg8ATTE8PFxxPb1t27p06dIJj+j4IpFIUag/6p70fviZbh+JRAj0QIsQ6AGgVdzq/Hd8n/RXzrZ2LADg4TiO1tfXj7TPeTuam5ur2FguHo93ZBiNRCL56feWZdV8rkqD+PDwsK/7qdUZ37ZtPXz4kHX1QIsQ6AGgFf6/pPSbv2wu09keQJuJRCKKRqOKRqOtHkrDxGIxhUKhst9bXFzsyJMX3h4BtU5KTE1NFS098PPz2rZ9qPpfun7evd+5uTlfYwbQWAR6AGgFtzr/rc9I3/m3WjsWACjhritPpVItHknjuFvZlVtP7ziOwuFwC0Z1fG63/vX19ZrXjUQi+cu1Ar1t25qenq55m/F4XLOzswoGgzWvC6DxCPQAcNJ+61ck+9PmMtV5AG2sE6vW1YyPjysWi5X9nm3bFb/XzsbHx7WwsKBMJlOza38sFtPQ0JAk0x2/0vObSCQ0PT2toaEhXb16teLtxeNx3bt3r6tmcgCdhkAPACfNrc6f/qvSh3+wtWMBgB4TjUY1Oztb9nsrKyuHmsB1AvdEhFutryQYDCqRSCgQCORnJXh/XjfIh8NhTU5OyrIsRaPRoqUK7pp6y7J06dIlLSwssH4eaKG+g4ODg1YPAgB6RvrXpH/2YXP5wkvSd8+3djwAUMbU1FR+q7JufKvoOI7Gx8d17969Q98LBoO6e/dux00htyxLwWDQ1x7xjuMoGo2W7Y4/OTmpWCxWFNIrXX9hYaHiDgIATgaBHgBO0v/xw9JrPyN94Dukf/UbrR4NAJTV7YFeMgG40hrxubk5bW1tnfCITp7jOLJtW47jKBgManh4uGr3+0wmk/8YHx/3dfIAQHMR6AHgpPzOvvTjj6ct/sgnpO/9+60dDwBU0AuBXjJT1VdWVsp+7+rVq6wNB9D2WEMPACfl1cdr5wdHCfMA0AaqbWV36dKlmk3mAKDVCPQAcBLuf0GyftpcfpbO9gDQLtwmceUsLi7mt/ADgHZEoAeAk+B2tn/i/dKz/7i1YwFOiGVZWlxc1PT0tM6cOaNwOFy2CVe96t1K7caNG/kxJBKJY98/usvw8HDFxm62bevSpUsnPCLgsBs3pMVFaXpaOn3a/Lu4KNXalMFxpPV1c/0zZ8zH9LT5WlvuSmmtS58ISz95Rlqfll5elN5swEyZt+r4Yd92pJ+/ZMbwiXBj7r+JCPQA0Gxv/Y6082/MZarz6AGO42h6elrT09Pa3d3V0NCQAoGAEomEIpGIpqenj1T1tG1bp0+fzn/4CfbRaFSRSESWZcm27UPbdAGSaYK3sLBQ9nvxeJxO7miZRMIE+EhE2t2VDg6k2Vnp7l0pHjfhfHraBPdSlmWOjUbNcZOT0tCQ9OCB+drp01KFFhIn701bWj4t/VxUeuuu9P6Q+fczcROsd6tvyVjRZ+LS5VPmtj8R9nfM+rS5vzdtaT8h/buwCfltikAPAM3mVucH3ic990JrxwI0mRvmb9++ra2tLWUyGcXjcVmWpcnJSUmmcu/um12PcDicD/Hu7VaTyWS0vr5+6Ou19upGb/YYhgAAIABJREFUb1pbW6u6nr7emSHAcTiOqcCHwyaE7+6airplSWtr5vLVq+a6lnU41LthPxQy4d89LpGQbFty/wTHYoXLLfOmbUL0Nwakf3Jb+nFbmo+bf10/f8mE63q8lTEVfjeM7ydqV+rdIF96O6n2nd1FoAeAZvpvvy+98jhQPHdReue7WzseoMmmp6d19+5dWZalubm5ou9597VeX1+vq+GYbduHAlWtLbMqBTC3ezvgFQwGK54kchxH4bDP6h7QAIuLJpRfvWrCuOfPZ140aqr1kgnp7kvUts3xk5PmWO9OhI5jpt17Q3yZ854n562MCfNPDElRS/qA5+/6e4LS05OFz3++zuUvny3z+/zeYO3xlPPF9p3ZRaAHgGZ65UXpT78uvbtfepbqPLpbLBaTbduKxWK+9qeuZ+p7ubXvU+Xe4XqMj4+XbXZGkzNUMj4+rqtu2bOEbdtsY4cTsbhoKunXr5vQXk0kUrhsWea4cFgKBMzlcrddei61pX8SX16UdCD9aMIE+GreytS3nr00hL8/VPs+vrXC/ytfad8ZOu9s9QAAoGu9/d+kVz3V+feW76KMzhGPxxvS1O2kVAsnjZbJZLSysqLJycmKoae0Il9PsC4N/0NDQwoGq78xCwaDsixLU1NTevjwoe/7Qm+LRqOyLEvb29uHvre+vq65ubmaJ5OAo0okTGV+YaE4rFdS+mdwcdEE9OvXD3/Pvf1SQ0NHG+uxfSZuQvf3L0vvGy5/nS+WzKiqZy176bFP+/i9HZuTfvj64xMNnYFADwDN8uqL0n/PSd/wDqrzXSIej3fUdG3LsjQ7O3si4cNdE19tbfxxHrvSY/3+TOPj44rH40XTpYda9u4VnSIej2t4eLjsiaBwOKy7d+/WPKEE1MtdNz80ZEL9UW8jECh/MqDSOdSS1VEn5xdXpPcEpOkK0xCOM8293Hr7StX3Uh+JmJkAlmctgp+TAS3ClHsAaIavf7V47XxgsLXjQUNEIpGKTbPaTSAQ0OzsrK+p78flOI62t7c1NDRUMWgnEolDFXm/Yys3Nb+ekxRzc3OadReaymxTBlQTDAYrbnHIeno0y9qaCd3HbVJXKaAHg6by7zU52aKmeG6Dug9HKk+DL9eIzm+w/kKZkwH1hPKPxszJhg5AoAeAZnj1RekPv2wuU53vGpFIRLZt6+DgoO0/HMdRIpE4kSqiG9arrS8uDUeBQOBQ07xKjhvoJfPcuY56ksOyLN26dUuWZdHxvAdMTU1peXm57Pcsy2K3BDSUu1/80JC/qfaucr1Fq/1pjcelrS1pedn8a1nlp+bXy7LqXIv/mcdTED5S5Yf9bMkSt7HZ8tcr50slM8L8rJ/3ek/QTL93HadC/6Zdu7v+MRDoAaAZ3Or83/iH0p9lei+6mxvWKwV0x3EO9R7wG+al8uvn662ye08A1BPoLctSOBxWX1+fpqenNTU1penpaZ0+fVp9fX0Kh8Nl11qjO8Risapb2dWzUwNQTSJhAnE9YV6qP9C734/FGjPV3ralU6fMFnmnT5vt9HzZ3zad7T9Q4e/xZ+KH18uP+Rzw287h5nlHCeTesVUaZ61xrE9LP3lGWj5d/7Z7PhHoAaDRkj8lfeVNc5l959EDbNtWKBSqGLLLTV2uJ9Afdf28l3emgp9A706rnp6eViKR0MLCgra2tvTgwQM9ePBAu7u7unjxonZ3dzU3N6czZ85Qte9SiUSi7G4JkllPz64JaAT3z0e9gT6VKv58crL89Zplbq5QmXccn2v/3bXx1arzpeH3PYHq1y93+15+1897uSH+iaH6qvuun4sWj2W3ObN6aIoHAI3mVucn/57057+ttWMBTkCtqf3rJZscDw0Nneh0e69AIFAz0DuOo+npadm2rUAgoEQiceg+p6amNDU1pVgspqmpKdm2rTNnzmh3d/dE+haUanSzRm8zuEbf9uRJJ45jGh4ePtRY0ZXJZHTp0iVdv369BSNDN4lGTTiuZ/KR4xyu0J/0Bgz37hV/7utP+9NT0sXdylXztx1TwffyW52Xjr9+vtRRqvPS4a3umtRYj0APAI20+++l7JfMZarz6BHVAmwmkzk0Lfk40+2lowV6t4rqJ2xPTU0p9bjsVS7Me7lb442Pj+vevXuanp4+8VB/5syZpk79bvQuCePj47p9+3ZDb7PZ5ubmtLCwUHbbyng8rtnZ2bpe10CpYFCq989GmT+PJx7oFxYk99fi+vU6foZq4bZcM7xKnfDLOe76eZe77v2oQXw6Wtg6b2xW+v7mdB9kyj0ANJJbnZ/4u9Jf6Ixu6EAzlZtuX615XqlGrJ+XlA+8tUJXLBbLh/mFhQVfYTYYDOa363McR5cuXap7fMdx9+7dE72/4+q08brW1tYqrqdnLT1aoR0CfTwu3b0rHRzUv1ygIqt4VlfVtfalGrV+XirczlGPH5uTrjwwHz/anPXzEhV6AGicX31ZevM3zGWq84AkHapoVltrX04j1s9LhRMD1Y53HKdoeUA9FddIJKJoNKqHDx/KsizF4/GizvrNZNu24kfdtLqCeDyue4/n0lbq9H5UJ/W4NFowGFQ8HteZM2eKvh4Kheo6SQU0SulqmFbtqtrQnUDfyhwO5PVMt2/U+nnJVPrfEzj6lHvpaDMD6kSgB4BGefVxEPjQOWn0w60dC9AGyk23ryfMNXL9/Pb2ds318/F4vKjBWb1TqMfHx/MnIG7cuHFiwXV4eDg/Q6BRLMvKB/pG33YnGx8fL5p67/ZYOIntIQGvdlg/3xTlOsH7bYYnNW79vFvp//BC/ceeMKbcA0AjfPbnpDufM5fZdx6QVH66fT2BvJHr523brhnQvVXuSlOrq/GOjb3qu5NlWUWzThKJxJGWgADH1Q7T7ZuitMJez3R7qXHr5911/E1qZNdIBHoAaAS3Oj/+/dIHO6uDM9As5da/17sHfOnxRwlP7omFWtPtU579n45ScS09ptwJDXSuTCZT1On+6tWrDW8YCPjVtYH+ON3tG7l+3j2xEGr/ZpdMuQeA47r9C9Jv/6q5THW+q9m2re3t7bKV43YzPDysqakpLSy0brrg9nbxG7N6w0+j1s+7wbpahb50acBRutSXHkOjtO7hOE7RnvMLCwusm0dLlVs/3/ErP467/r00zNd7vNf+tulMfwJr4I+LQA8Ax+V2tv+O75XGnm3tWNBU0Wi04XtyN1M8HlcoFGrJvujlwmw9gfy4x7scx9H29rZmZ2erVt1LT9I0Yk20t+KPznbp0qX8azIUCmltba3FI2qORCKhlZUVZTIZXb16tWMbGB5FJBLRjRs3dPv27Zb8zaxHI9bPO46UydS/VV48LqVS5vjhYbNtXcNWnZQL9PVU2I97vGs/Yar99cwOcO//i7fM/vNPDEtPT57IlH2m3APAcfzGL5kPiep8D2j3N3mljjpFvRHKrR+v5/E77vEuP9X5Svd3XFTou8Pa2lq+v0I3N8FzlxTYtt2S7RdbxbIsnT59Ot8bwdsYs12VW81Tb6CPRKSSDRuqsm3p9GlpcVG6fdt8xGLmNhq2yUZphf2Jofoq5Mc93vWZxz+Q3+n2bzvSJ8LS+rSU2pLeuiv9x5j5/Oeb/3tEhR4AjsOtzj89If3V2daOBU23trbWtZW5RisXZusJ5Mc93rW+vq5AIFCz0kgDO5STSCSKgq1lWV3bBK9068NAINCikTSX2y8jkUgokUh05O/+cdfPZzLS9rY06/Nti21L09PS0JAJ8u6f4uFh6d49E/LHx+uv9h/ydsnJlPfV+bt23OMls23e/rbpbu/nZMDbjgnub92VfnSrUNX/uahkrUu7a+bEwnTzluhQoQeAo/rtXzXr5yX2nQfakGVZsm2btc44Etu2tbi4mP/8+vXrHTdLpx6lP1s3nbyMxWLq6+tTX1+fTp06pampKa2trSkQCGhysj0a2WYy0vq6tLJiLldz3PXzboXfz86cjmMCeyBgTiR4Xybec1tt2QP0/Uf4ff3s4xNbfrfK+3TMzAz40UTxFP33ep6Qz944fFwDUaEHgKNyq/PD3yl95O+0dixAm2l0FfMoQWplZUWSWhroLcuiE3oHchxHi4uLRU3wun09+dzcnHZ3d/NbPHbTTITh4eF8cB8fHy/6iMViLe+NsrYmeVc4rK2ZSni5p8C2Dwf+ev48Oo45aTA0ZKbd+xmbbUu7u4dPGngnUjWlV+xRArnXe+ucbv+2I+2u+1/7/kXLVOGnLh6+/lueJ6lcs74GItADwFHc+Zz0az9nLlOdBw45bhjw7vUt1b8e3bIsWZal5eXlrlzvjOZaXFwsaoJXOh29W01NTXXlCahIJNK2J2RsuzjMSyZ0x+NmjXqpchMn6vlzu7Zmbv/q1drXdRwza2By8vCUfsuSHj4sfN6Ql83TU6apnOt36/i7/1am+Fip/iD96ZgJ9d9f5oEv5z8+vt5Hy1x/3zNl4f2h+sZRJ6bcA8BRuPvOv//bpe9p3bZgQLuampo6tAbXbyiPx+Nl17X6bVblVlcDgQDT7VG3WCyWb6YYCAQ6YptKdK5K54rKhXTHMWvfy33dD9s21fnZWX/V+Xjc3Ha565aO28/0/ZpKu8p/5Z7/Y8s1n/vdOnYaedM21faxWX/VefcEQrm19p+JS297znb4nb5/RAR6AKjXG78h/erL5jLVeaCi0jCd8LHIMpPJ6NKlSxoaGtJsSccmP8dLZouxTCbTtd3I0TzxeDy/VMMN87yG0EzlznMGAuUr3ouLJmBvbZkp8y4/Kwa8je38TjixbTOW0kDvOJJ3ElUo1ICGeJL0gfHiavZbmfJb0ZX6TNxUxMdmTQO6eo9/25H+XVh6T0Ca9/nguLMHyoX1z5bcRr3b39WJQA8A9XKr8988In3vP2jtWIA2Fo1GNeR517m+vl61Su84jsLhsBzHUTweVzweL6ryr6ys1KzSLy4uKh6P6+rVq20xdbgdxgB/bNsu6mi/trbW1U3w0B5K/0QEAiZwl1bo43HTeG5hwVTDvVPvy62r93LD/MGBuQ2/56jc9fOlSk8INHQi1A+UrCn4+UuHu9d7vWmb67hhvN7j3S71f/RAumj53+ZubE76J7fLr533Tv0fmz1at/06EOgBoB7ZL0m7/95cZt95oKpgMCjLshQKmYqL4zianp7Wdpk5o5Zl6cyZM7JtW9evX9fU1FT+eDfUZzIZTU9Pl52O7+4lHY/Htby8zFR71MV7MkmSLl682LZrrtFdIhET4iVT5bbt4unrjmPW2C8umqnybpiem5MuXixcLxw+HL4zGXPcmTOmMl/apb6WYLD81H9voA8EGjTd3vX0lPTD1wufv2mbwF1uPby1br6ng0IYH5srf3y5Sv1+Qvpnpx9vOZcwMwTqUe76pdX5Jk+3l2iKBwD1cTvbn/oW6bmL1a8LQMPDw7IsS7FYTOvr63IcJ99B222cl8lklMlkFAgEdP369aIgNT4+Ltu2FYlEdOvWLdm2rdOnT2t8fDw/Fdq2bTmOo6GhIW1tbWnuCO8uh4eHW97pGq0TDofzJ4omJye7asu2amzb1sPHnc1CoRDLC1pgeNgE7UjEBPLTp4ur9m4Lh4sXDzfEW1szAT0aNceeOWM+DwbNiQA34C8smOs24um1bSnlWZo+N9eY2y3ykYgJ9i9HTLX7TVv6yTMmQLsV9DdtU11/f8hU5r3h+iMRUxXfjJh1+G6of9+w6Zz/tlM4/ulJ6W+v1R/mK/mMJ9A/MdT06fYSgR4A/PvKm1Lyp8xlqvOAb8FgUGtra/lmY7Zty7ZtHRwcSJKGhobyFdFygcI9KeCui7csS47j5I+fnZ3V3NzckYK89z4arV32t0Z10Wg03/huaGjId6+GduLOMJicnFSsXGv0Eu7yAm/Dv2AwqGg0quXl5WYOFWW4lflEwnx4JyFdvGgCe6U/UZGICdXxuAn/jmOm1g8NmSAfiTQ2cJeeVGjaRJb3DZuq+1sZU0l/05a+kpFk/u7r6UkTlitVwJ+ekv754zX07ockvf3A/PvhBXNso4K8ZMbpbeR3AmFeItADgH9udb7/CarzwBEEg8FjTWMeHh5WNBptynT60rXSR+lsXroUoJv28e5W8Xhc6+vmb3sgEOjYRoruia6Fhdq7rsTj8Xzjydu3b+f3Yl9ZWVEsFtPBwYGvkwJovLm5o01fDwZN6G/2SqPSLvtDQw3arq6a9w1L08f4wZ6e8te1vhE+UzLd/jjjrgOBHgD8+MMvFwL9cy9If+YbWzseAA3ViOZ1pYGehnjtrbQJXjwe79gmeG5n/lqzVNyfeXJysmgmwtTUVP423GBfSzwe1w1vq/MWmZ2dpWfGCUkkirfIK/cycb/fgefFjudtR9r3nO2o1AzvrUzDm+QR6AHAj1fWpT/5mvSu91KdB7pQMBhUKBRS6vHi0FSqjv2LHyPQdw63QaPbBG95eflYSzZaKRaLKZPJaHZ2tubsgmg0qoODA8VL2pSX7h5hWVbN128sFtO9e3XsE94klmUR6E+In73nh4cLSwB6Sml1vtxSgM2I9Nkb0k8dNPSuCfQAUMt/zxW2qnvuBem9vXbaGegNkUgkX7F1HEeO49Q1/dq7Jd/k5GRXTLnv1j4A3jA/OzvbsVPMbdvOLxmodUIiHo/r1q1bun79+qHXdWnfAD+v3bW1tarbUJ6UTp1V0WkymeL97hcWDlfhEwnp4cMG7UnfaXY9zQXeEzi8ft6t4I/NNvyuCfQAUMur69Lbfyj1fYP0LNV5oFtFIhHFYrF81+9EIuF7zb/jOEVV/U6vGK6trSkajXZs0K1mcXExH0RDodChanWncBxHi4uLchxHgUDAV6CvdD1voB8aGvIV6I/biBKdpbRXZLmnPh4329j13I6Pb9q1m+GlEibUN6FRHvvQA0A1f/L14rXzwSdbOx4ATeN2+Xa5lU8/vNucTU5OdnzQGR8f9zXtutPE4/F8gA8EAorH4x3ZBM9dMuCemJibm6v6cziOo1u3bpW9Xjwez5/Ekjr/ZBSao3QyRumfONs2DfOi0R5dP+9VOt3+bUf6xRWzxV4T9qUn0ANANa+uS//tD8xlqvNA14vFYgqFQpLMdGY/+5F7pz0HAoGe2cO809i2rcXFxfzniUSiI6drZzKZojAv1Z5uHwwGdfXq1bJhvXSGwnF2okD38k7aePwnMs9xpHDYdL3vyfNB7yk5g/FEyQyXT8dMM7wfaM7/DQR6AKjGrc5/33npz3X+elgAtVmWlQ/1ly5dqlqpt207vx47EAjIsqyODIndzg3BrqtXr3bk7INEIqEzZ84UhXk/0+0lU3kvfW1mMhnd8iyM9tNYD70pEjHT6SWzTt6VyUjT09KDB2Zafk++fD4wbqrvrq94GqRuRiRrXfrbV5u2fR6BHgAq2fk30ltvmMt0tgd6RjAYlGVZmp01zYui0aimp6d148YN3bp1S7du3dL29rYWFxd15swZOY6jUChEmG9TjuMoHA7nm+AtLCx03LTyTCajcDhc9HO4jrO8o3Q2CdV5VDI8LK2tmVCfyUhnzpggf/q0CfOW1aPN8FzzcemJIXP55UVpfVq6fEraT0g/fL2pe9LTFA8AKnnlRfPvX49I3/KXWjsWACcqGAwqkUjIsizF43FZlnUo7AQCAc3Ozmpubo4g1MYuXbpU1ASvk5ZEZDIZ3bhxo2pzwuMEeu90+6GhoY7v/YDmikSkqSnT/M62TchfWOjBJnjlfGBc+ucZ0+3+rYyp0k9flD4cafi+86UI9ABQjvXT0v0vmMtU54GeNTU1VTQ127IsSaZpHFOT29/a2lpRE7xEItH2z5vjONre3lYikTi0nVwpv9Pty0kkEkXN8DgpBT+Gh6Uu3PyicZpYia+EQA8A5bjV+e/6IWmol+eQAfDqxHXXvcqyLF26dCn/eSKR8LUd20nKZDK6d++eLMtSJpORbdt17e1+nBB+3GZ4X/7yl2Xbtr7+9a8feQzH9Y53vENnz55t2f0D7YBADwClXvsZ6Y19c5nqPAB0HNu2FQ6H85+Pj4/n+x+0Yiyl697Lfe0ojhroM5mMtre385/Pzs4eOtlhWZZWVlZ0/fr1sidCnnnmGX3hC1840v030szMjF599dVWDwNoGQI9AJR69XF1/n+Yk/7iR1o7FgBAXRzH0eLiYlFgrrfy3QmGhoaO3ITRT3Xe7R1RaYnCD/7gD+onfuInjnT/jfR7v/d7rR4C0FIEegDw+rWfl9K/Zi6z7zwAdJzFxcWuC+/lNKoZXrl1+I7j6MaNG1W3sfsX/+Jf6J/+03+qP/mTPznyOBrhve99b0vvH2g1Aj0AeLnV+dBz0rezVhYAOonjODUbyXWL46yfv3fvXtXbcXcCqLW937vf/e4jjwFAYxDoAcBlf1r6rV8xl6nOA0DHCQaDevDgQU9U6I863b5UaQXetm2trKxodna2J5pAlutv0As/N7oHgR4AXG5n+2+fMhV6AEDHCQaDBLIaZmdn803xvIHetm0tLi5qaGjo0Dr7TmdZlvr6+oq+lkgkdOPGjaKvraysqK+vr+wJk8nJyaaOETiKvoODg4NWDwIAWu43f1n6+N8wly9tmYZ4AAB0oUwmo/HxcT18+FDj4+OKxWKyLEvxeDwf5hs1A6BdlIb5oyA2oR1RoQcAqVCd/4sfIcwDALra8PCwbNvOB/m5uTmFQiFdvHhR0Wi0YiO8Tra8vFzxe+Pj4woGg8pkMspkMic4KuD4qNADwBdek1a+21z+sZ+VvuuHWjseAAAAwIdvaPUAAKDl3Or80DhhHgAAAB2DQA+gt939demznzKXn6OzPQAAADoHgR5Ab3P3nf+WvyT99aPv6QsAAACcNAI9gN715m9K//klc5nqPAAAADoMgR5A73Kr839uWPq+860dCwAAAFAnAj2A3vT7aek/fcJcfpbqPAAAADoPgR5Ab3I72weflJ57obVjAQAAAI6AQA+g9zz43cJ0+2cvSn38KQQAAEDn4V0sgN7jVuf7g1TnAQAA0LEI9AB6S+4t6ZV1c/nZi9K73tva8QAAAABHRKAH0FteeVH6+h9Lf+Ybqc4DAACgoxHoAfSOP34kvfq4Ov/cRan/idaOBwAAADgGAj2A3vHKi9IfPTSXn6U6DwAAgM5GoAfQG/70T4qr86e+pbXjAQAAAI6JQA+gN7z6ovQway5TnQcAAEAXINAD6A1uZ/vv+wfSN4+0diwAAABAAxDoAXS/X9qQvnzPXKY6DwAAgC5BoAfQ/dzq/PcsSO//9taOBQAAAGgQAj2A7nbruvRff9tcZt95AAAAdBECPYDu5lbnP/J3pOHvbO1YAAAAgAYi0APoXns/K/1OylymOg8AAIAuQ6AH0L3cfef/6qz09ERrxwIAAAA0GIEeQHf6f7akL33WXKY6DwAAgC5EoAfQndzq/Niz0rd/b2vHAgAAADQBgR5A90n9ovT5W+Yy+84DAACgSxHoAXQft7P9Byel8e9v7VgAAACAJiHQA+gu/2VX2n/VXKY6DwAAgC5GoAfQXdzq/OiHpQ+da+1YAAAAgCYi0APoHl98Xfr1bXOZzvYAAADocgR6AN3Drc7/hZA08XdbOxYAAACgyQj0ALpD5rb0mU+ay1TnAQAA0AMI9AC6g7vv/J//Nmny77V2LAAAAMAJINAD6Hy/+3npV26Yy1TnAQAA0CMI9AA6n1ud/7ND0t/4h60dCwAAAHBCCPQAOtsf3JV++d+ay+w7DwAAgB5CoAfQ2dzO9oFB6bmLrR0LAAAAcIII9AA6l/NfC4H+2Rekb3hHa8cDAAAAnCACPYDO5Yb59waozgMAAKDnEOgBdKZHD4qr8+/ub+14AAAAgBP2zlYPAEBns23JcaS+vuKvHxxIw8PmoyleWZe+9t+ld76b6jwAAAB6EoEegG+2LaVSUiJhLmcy/o6bmpJCIenMGWl2VgoGjzmQr75d2KruuRekgfcd8wYBAACAztN3cHBw0OpBAGhfmYy0vm5CvN8AX8v4uBSNHiPc/4eflD754+by//6m9MT7GzMwAAAAoIMQ6AGUZVnSyop0+7b08GHh64GAqbiPj5t/g0FzudJtOI6p5luWdOtW8ffHx83H8nIdU/MPDqQf+xbJuS89+4+l51880s8HAAAAdDoCPYAiti1dumQCuGtoSJqbkyKRyuHdr0Si8OE9URCJSFev+qjYv7ImbV4yl//1l6TB0eMNCAAAAOhQBHoAkkwlfWVFun69ELQnJ03QjkSac39ra+bDvb+hIXMy4WK1HnfR09IfZKTv/fvSj3yi8QMDAAAAOgSBHoBsWwqHC2vkh4ZM0J6ba/59lwv2c3PmxMKhav0vX5P+zwvm8r/6DekD39H8AQIAAABtin3ogR4Xj5vu826YX142l08izEsmtMdi5j5nZ83XEgkzJtsuubK77/x3zxPmAQAA0PMI9EAPu3RJWlw0l4eGTAO8WKw1YwkGTZC/ft003stkpOlp8zVJ0q/Epd/7LXOZfecBAAAAptwDvWpx0VTnJVMZj8cbsD98g9i26aDvTsG/fl2KfOGMdM+WPvyD0gufau0AAQAAgDZAhR7oQd4wv7BgquDtEuYl00k/k5FCIfP5q7H/y4R5ieo8AAAA8BiBHugx8bi0u2suLywUgn27CQbN1nmhkPTCt5m95h+O/i3pW59p8cgAAACA9sCUe6CHWJZZly61d5j3enQrof5PhCVJP/ybv6Sfsr6vrWYTAAAAAK1ChR5dw7IKndrrOeZQJ/Uu5ThmazrJVL3X1lo7Hr/6f9VU53fun9XPpL4v38QPAAAA6HUEenQsx5FWVqRTp6S+PlN5Pn3afH7pkvl+OZZltkRzj3Evh8Pme91qcdE8JoFAezXAq+kfviz9zf9Ff/Q9Zu18ItEZMwsAAACAZmPKPTpSPG5C+8GBFIkU9kzPZMy2a/fumcC6u2sarLmiUWl93Uw3j0QKX7dtU7G+d+9xR/W2edHIAAAgAElEQVSIuoplmRMWjiNdvWoeh040Nydtb0vDw2aLvY45KQEAAAA0AYEeHccN5RcvmvBeGuocxwS+hw/N927fNp+7x5UGdrfS705BDwalu3e7KyyePm1OdkxOdvYsBO9zu7xsnn8AAACgVzHlHh0lHi+E8rW18qE7GCwEdscxoc+yzHFXrx6uvs/NFa8nd5zuWlcfjxd6C3R6AA4GC7MLVlbq75kAAAAAdBMq9OgYbof2ixdrN3SLx1XUPG142EzPLw2Atm3W0Je6fbt4qn4nc6vzndLVvhZvld7PawEAAADoVlTo0TEiEWloyF+AGx4u/txdW1+qXOO8oaHuCfOJROEkRqeumy/lrdLfuFG5+SEAAADQ7d7Z6gEAfrgN63Z3/V2/dMp8IFC+0d34uNnCLZUqXC+RON5YK7EsU1V2x+ZO7Z+dbV7Ydivyk5Pdc5JCMo/Xyop5DBOJ7mtiCAAAAPhBoEdHWFszwXtqyt/1S6fWVzouGDRB220UNzXVnGZ47nKBcoaGGn9/kgm729vmcrcF3mDQnAjZ3ibQAwAAoHcx5R5tz7JMdb6eKnZphb7aiYBg0DTGm5trXmf78XEzu2B316xl9zu24/DONHC39esmbojf3mbaPQAAAHoTgR5tz3FMdb6eUHrrVvHnzQrNfgWDZgxTU4eryc0amzvrYHKyu7bgc7mPWzOXSQAAAADtjECPtjc3ZyrufkNp6T7rgUB7rR/3jm9o6HADv0ZxT2q0+mRGswSD5mSFty8BAAAA0EsI9Og69Uy3bwVvoG/W2Byn0Eeg3X7+RnJP1BDoAQAA0IsI9Og6pRX6dgu03uUAzRqbN+C20+yERnN/ttIlFgAAAEAvINCj67RzoD+psbnV+UCgO9fPu7zLFWiMBwAAgF5DoEdXsW2zptrVq+vnXe30szeD9+dj2j0AAAB6DYEeXaW023k7Veelk1k/LxUq9N2um2cfAAAAALUQ6NFV2nm6vXQy6+cBAAAA9IZ3tnoAQCMdZ//5eNxskXfUqq/jSDdumKnfd+9KfX3m9hYWzG22+8kGAAAAAJ2FCj26xnH2n7dtaXHx8JR9PxzHHHvqlLS8LB0cmLA+OSldvSqdOWNu/6TXzwMAAADoblTo0TWOUwFfW6v/GPc+w2ET6kMhc0LAG9SjUSkSkaani79OdR4AAADAcVGhR9uLxUyV+9QpaWWl8vVKq+t+q/OOI21vm6nx9VTN43ET1N0wb1mHjw8GzfUODoq7sDc70LvLBlKp5t5Pq7kncYJBZjwAAACg9xDo0daiURPibdsE51is/PZkmczh8Oo30K+tFW7bL8sy0+wlM7XfsiqvvQ8GTZXeq9mB3v3Zu31vdvfncxwCPQAAAHoPgR5ty3Gk9fXyXy9VTxj3sm1zwuDiRf+B0HHMNHvX2lrtRnre75/E+nnv7ZcuRegm7smdUKi14wAAAABagUCPtlWuEl+u0Z1tm+7yCwsmLFc73ssN5qFQfScEotHCSYWhocPV93JOav951/Bw4bGo9Th0Mvdx9TsbAwAAAOgmBHq0rdKqdyBwuBrudph3v+c2t5NMyK8kkzHr3w8Oqk+XL3ec93bn5vwd14r9592Q280VeneZBU0GAQAA0IsI9Ghb4+Nm6zfJVJwtq7gablkmlN+9Wwjl7r7vkgnf7jp3l+OYKfZnztQf5qXiEwZS/dV56eTCp3uywXsyoZskEub5DAYJ9AAAAOhNBHq0tUTCrG/PZEwIn542H+7lQMBMKfdOuY7Hzf7vgYC53NdXOO7UKfO9ixfLd6X3Mx6X333uW7X/vBtyHefwDgDdwP2ZTvIxBQAAANpJ38HBwUGrBwHUksmYAJfJmI/xcRNYq1Vm3SCbyRRC//CwqVzXU5X3juH06cLns7P+gvLUVKFKvrBgTjKclPFxMy39pO/3JJw6ZZ7jq1dNXwMAAACg1xDoAZ/cKf6u5WV/zfT6+gqXr1/3N02/URKJQkf+u3e7p5IdjxeWU3TTzwUAAADUgyn3wBH5Wbdda/18ItHcpnVzc2ZpgHT0rf3a0cqK+XdhgTAPAACA3kWgB5qo1vr5SKT5Xejd6eg3bphlA50uHi/8HCc52wEAAABoNwR6wKej7HXuXbdeWp23LOnhQ/9b3x1VNNo9VXp3lwLJVOfpbg8AAIBeRqAHfAoGC9vo+RGJSPfuFT4vrc4nEqZqf5QTBfUIBgvb7d240dn70q+tFarznX5yAgAAADguAj1QB2+IrNY1PhIx4XloqPz3Hcd8/6SmjEciUihkLi8umvvvNJZlqvPBoGlIyNp5AAAA9DoCPVCHqSmzh71UvtrtdsJPJKTbt4tDv3f9ujsN/iS3W4vHzX1mMoUO8Z3CcQrd+oeGqM4DAAAAEtvWAUeytmZC5cOHJuQHg4X97hcWzPfdve7X1qRLl8zlqSlzvQcPTPhv9nT7Ut7t3i5eLEzFb2eOY06S2LY5IdGKxw0AAABoRwR64Igcx1Ti3cp7MGga3JWbCp7JmOs6jrleJFII/CctGpXW183l69fbv1P84mJhpsPWVvObCAIAAACdgkAP9KCpKenWLXO5nUO9N8xfvXqySxQAAACAdkegB3qQ45hQn0qZz2Mx02iuXXin2UtmGUO1JoQAAABAL6IpHtCDgkGzFt3dhi8WM03n2qH7vW1LZ84Uwvz164R5AAAAoBwCPdCj3FC/sGA+TyRMkG7lPvUrK2YMmYzpZt/OywEAAACAVmPKPQDF42Z9+sOH5vO5ObNm/aT2ercssxOAW5UfGjInGOhmDwAAAFRGhR6AIpHiKfiJhHT6tGlK53bxbwbLMmvlvevlL140lwnzAAAAQHVU6AEUKa3WS6ZiH4lIs7PHv/1MxnTYX1srhHjJnEyIxUyzPgAAAAC1EegBHOI4JnDH49K9e4WvB4MmcE9NmQp6KGS+Vk0mY27Dskzl3w3xgYA5aRAKmRMIrJUHAAAA6kOgB1BVPG6C+PZ2+e8Hg+WnxztOcQXeKxAoVP2pyAMAAABHQ6AH4IvjmGBvWebDW7n3Y3LSBP+pKRPmAQAAABwPgR7AkbgV+EzmcOO84WHztfHxwjR9AAAAAI1FoAcAAAAAoAOxbR0AAAAAAB2IQA8AAAAAQAci0AMAAAAA0IEI9AAAAAAAdCACPQAAAAAAHYhADwAAAABAByLQAwAAAADQgQj0AAAAAAB0IAI9AAAAAAAdiEAPAAAAAEAHItADAAAAANCBCPQAAAAAAHQgAj0AAAAAAB3ona0eAACgO+RyOd25c0eSlEqlJEmjo6MaHBzU6OhoK4cGAADQlfrOnj04qPegsTFpdbUZw0Gzzcwc7bgrV6RQqLFjAdAddnZ29Nprr2lvb0+SNDY2lv9eNptVNpvVwMCAJiYmFA6HCffwJZVKaX9/X6E6/vNJpVIaHBzUzFH/swMAoMP02XYh0KfTUjIpPS6w5E1MmI/BQfP5wIDE+7HO9LhoJkna2zPP96NHxdc5e9Y8v97neHTUPO8A4EqlUlpdXVU2m9Xg4KDm5+c1MTGhgZI/Ful0Wjdv3tTOzo4kaWJiQhcuXNCg+58KUMbm5qY2NzfrPm5sbEyrVB0AAD2i7+CguEKfSkmXLxc+7++XtrZOelg4KZub5sN19mzx8w8ApXK5nFZXV/MV+XA4rAsXLtQ8Lp1O68qVK7pz544GBgZ0/vx5KqnwJZfLKZlM6tq1a0VfP3v2rJ5//nlODgEAelbNpnhU4psrlZKWllo9ioInn2z1CAC0s1wup8uXL+fD/NLSkq8wL5n19KurqxoZGcmfFNhq8zPGyWRS2Wy21cNoG5ubmy15PAYGBnTu3LlDX2emBwCg19HlvsXS6VaPAAD8ccN8+vEfrnA4XHeFfWBgQKurq+rv75ckbWxs6ObNmw0fa6Mkk0ndv3+/1cNoG5ubm231eJQu7wAAoNcQ6FusdP06ALSr1dXVfJgfGRnxXZkvNTAwoFgslv/82rVr+Yp/u9nf32/1ENoGMxUAAGg/BPoWe+21Vo8AAGq7efNmUeg+aph3hUKhom74q6uryuVyx7rNRmu38bRaO1XmAQCAQaBvoWz28I4CANBucrmcXn755fzng4ODdW0lVsn8/HzRfWxsbBz7NhupXWcNtAqPBwAA7YdA30LJZKtHAAC1bW1tFVWrw+FwQ243FAoVNTTb2dlpq2ndSf5IFyHQAwDQfgj0LZJOF28XBwDtKJfLHepE34jqvMs77V5S2zTIS6fTrJ/3oNs/AADt6Z3NuNFUShoYKL/lXTZrPiSp5H2cb7mcmare31/+PlIpqa9PGhkx4ziqdNo0rfM7Tndcg4Pmo5JUSlpZOfq4Ol0uJ+3vF3f4Hx2VJiZaN6Za0mkzZrdIOTpqXhf1vL6qvT7c1+xRfyeAZtnf3y+qzvf392u0gfuZhkIh7ezs5D/f2dk59vr843K31IORTqcP7f8OAADaw7EDfTIpbW0d3n5tbExy3w/lctLLL0s3bxYCixuWJyak+fnq+91vbEh7e4UTAaX3kctJr78uvfSSuc7gYOG6g4PSzIwUDlcPX5V+Dvd75SwtmYBW2jdpft58lNrcNKEwlSr++p070uXL5e/j/Pnqj00nyeWka9fM4zk2JrlFvvv3zWujr888T9Weq2RS8rz3L2tkRCqXBzY2KvcsOHvWvE7K3d/mpnk9TUyY5yKXM7eVzZpj5ufLn8Cp9Lr1vj42N83rbmTEXO/RI/Oc17kTGNA0r5V07mxkmJcOV/tzuZzS6fSh+8nlcrrj+QVOPf5DOjY2VnHGQDqd1qPHW4lks9l8U7f5cn+gPbd77dq1fDf/oyh3v4ODg0Vb/GWzWaXT6fz9DAwMaGxszPfjm81m8xVz9zGTpJmZmYr7sqdSKfX19VUdV6lkMqlr1671bIPAXC6nnZ0dpVKp/HMqmdddtce6ldLptHZ2dopew4ODg5qYmNBEjTPn3tdIOp1WLpc79DuWSqXys1eq/f4BAE7GsQP9wICplI+NmbBaKp2WYjET0rzBOJczX9/bM8dduVI5uA4MFKqapfeRTptQ399vQpz3/6q9PROq3NC0tFS5Clzr56h0jBvE/M5EHBszH/fvF4Kpe7+V7qMbZLPm8R8dNc9H6XugXM58f3PTvE5isfKvh4EB6eDAXC73PNWqcH/pS4e3CixXac/lzCyKVMo8x6VjvnDBnIS4ds28zsq9fqu9biVzzKNH5jUqFUL+6qq5rW45kYPOVjrtvNGBvlwgSqVSRfeTSqV0ucJZz/n5+bKBYnNzU5sV1jWVC/TJZFKbm5tlp5VXuu+xsbFDlfylpaWyU/XdAJjNZrW5ualkMpkP8NlsNh8YBwcH9fzzz+vs2bNl71Oq/niMjY2VfUxrjavUxsaG9vb2jv14dLLNzU1tbW3pu77ruzQxMZF/XNPptLa2trS5uamZmRmdP39eAxX+s670uHvNz8+XfU1WO9FS7phsNqvV1VWlUqlDJxySyaRisZgGBwd14cKFssG+0ljd37FcLqeVlRX94R/+oZ555hndvHkz/xgsLS1V/RkBAM1z7EA/MVEIyXt7Joi5slnzeblwNjBgvn7uXCHcV1pT7q1ouiHKvf3Ll83JgnIFl4kJE9bcSnosZi6X+z+y2s9Rifc658/X7ljvHWMqVQj0g4Plx99N3PBaqZo9MGCC7IULhed1Y+Pwdb3PUypVPLOh0nPrunDB3L97HyMjJrSXO7lw+bI5WTQyYsZV7r3auXMmqO/tlR9vpdet+/mjR4XXUOlrP50m0KM9lAa6SsGlkUqr46Ojo7py5Up+Xbuf5mwzMzMaHR1VOp32tf67tEHfxsZGfkbA+fPny57IKPdYXLhwIV99L73fvb09ra6uKhwO6+bNm0XH53K5fIC8cuWKXnvtNS0tLZW9D/fx2N/fL6qWVnPhwoX8jIBkMllUbS5nZmamKPR5Q3w9j0encl9vGxsbh06QhEKhfIhNJpPa29vTlStXyj4m7ushlUodetzHxsY0MTGhZ555puwYzp8/r2QyWTQzpdIx7msrl8vp/PnzOnfu3KExP/PMM4rFYorFYlpaWjp0wsB9jWSzWd28ebNorLlcTpcvX1Y4HNbMzIzS6XT+hFkymfRV/QcANEdD19CXVkc3NgpV2XIGBgoV8WzWX4jxfj+brRzmvfexsmIC96NHJpwNDhame/v5Ofx45hm2oKvEXX8uFUJ1uedsYMB83V1G8dJLlZciSOY5PHu2cGLEzwxZt2ouVQ7qq6uF27pwofosiQsXTKCvNV7v6zaXM7MQvDt0zcwUQn1/f/XXJ3BSWjXNutxJhFAopFAopHPnzun8+fNFIaecwcHB/DTjsbGxilXl0ut779M1Ojrqe1rx6OioRkdHNTExodHRUcUen7W7c+dOPkyVCz4DAwO6cOGCBgYGtLm5qb29PV2+fFlXrlw5FJS9j0c4HD4U3qqNy71cq5JebSZGPY9HJ0qlUtrZ2VEoFFI6nS4742FgYECrq6uan59XLpdTLBbTxsbGoefK+3qYmJgoeh1euHCh6uN87tw5zczMaH5+Xo8ePSobwt3xuq+zs2fPVnw9TExMaH5+Xpubm1pdXS16TXjHKpnfB+9rZHNzUxMTE/n7Lz3p5i5nAQCcvIZ2uff+P+auLa/1f773/8mj7Ijjp3fS4KCpprpWVg6ve/fqoiJDWyh9rEt7CHh53+fWWisvFVfk/VxfMieC5ufLP8+pVOF1WOvEj3sdd8w7O/6WXuztHZ7mPzhoAv3Skqnkt+GyTPSg46wjr0dpp/ta6q0Etyp89vf35y+7ldNaVcz5+fn84+GnGd3AwIBGRkbqGlc7rvtuJ+4MEDcopyr8pzUwMJAPuNlstuY2h6FQqOi58vP7NTAwoMHBwXxlvJQ7DV4yr7daDSW9W05We215XyP379/X3t5e0RR/7xKEkZGRqssDAADN1bRt63I5f429nnyyWSMo5t02OZcza+pxMkqf42qzMErfp9d6vxMKFcKvW/muJpWq/tr0Tn33O3vQ+/OU9A8ry22mV8pt4Mh7bfSaXtkezk8lXSpe459MJisGSlc3TXVvB6UzRKoFb+/JIj9LQbyvgUo9HkrHcufOnYqvna2trfxMmomJiZqvhYGBgfxJpVQq5Wsrwtdff73oRIB7O26fimvXrvEaBIAWauo+9O0UTNzp/a5awQ+NMzho1tCfPWuWPtTqF+AtNvmZ8et9n1GrSp9MVg7z2Wxx8zq/RT3v68pvQbOLZ6uiizx5UmdcUaR0Pf/LL7/cwtH0Hm+1ub+/v+Iad/f7rlrLQCQTut1j3LX11dy8ebOoGu6Vy+W05alO1LMsxFW6i0U5uVyu4m0z2wMAWq+pgb7dQot3PPV0psfxhUJmffm5c41f0jAzY9adS6YCXylU53Im8FcqkpW+r/K8T/PNz2uK9z/oFK16s97N67P98oZKv5VUNMbExIQ2NjYUi8V07do1378HfnpOeKfpS6o5TT+ZTB6qjrv29/eL7tPvOL2B3u+ymkbvbgEAaJyGNsVrd6X/192/T7hqpI2NQmO7WrJZs5Y8nTaX3TA9OOivKu81MGCmx7vV+Zs3yzen29oy16v0nJe+X97YkL7pm2rff73j5TWHTtLf31/U7TqVSlXdx71e5YJq/1HOpnWZ0gCVSqVYp9xg7vaIlXYSqBRic7lcvhp/lD4T586dy1fWd3Z28s0QSyWTyXwDxHLK7Qbhh/f3y8+Jonp7NAAATlZPB/p0uv1mEXQyP49nKiW9/HIhwJ89az6WlwuV+6Wl8vu2V3PuXCHQv/66Cdml74+SSX9NFF31XNfFDGV0m4mJCe141rI0ulJcLhBRoT98UoMKfeNdvnxZm5ubNdd/Z7NZ7e3taW9vT+l0WrlcLt+48ChrxwcHBzU2NpbvHbG1tVX2JFm16rykQ9P1/fZo8PIzftbHA0B766lAX4r/oxorm6285V8uZ7aDc3sGnT1be0u4eoyOmrX37u4Ke3vFa+Xd+613m1xyBXpdKBQ6FOiz2WzDpuOXhpLBwUGm96Lp3BMk1V7H2WxWq6ur+dfoxMSElpaWinYqSKVSvprhlZqZmckH+mQyeSjQZ7NZpdPp/HZ0ftSavg8A6E5NXUPfbkqrvu0+9TmbLe663s5yucrrx3M5MwXefc+ztGQ+b/QJFW9xovRxq9YMD0Bl5bZZa+R2dqW3Ve8WdsBR3L9/v+rSjs3NTc3PzyuVSmlkZCS/pr7WtoN+zczM5E8muDMAvF566SVfXesBAOipQF+61rndi0D373dOoHdPlpR7TGOxQqO6iYnmBeuJiUIjO++6fHe9fpWZi/njvTzLhoGeNTAwcKh66Kczth/ZbPbQlnXPP/98Q277JCSTyROrinZCX4GNjY2Gnuxppv39/YozQTY2NvJbyo2MjGh1dbUps0YqNcfL5XJ6/fXXa06hL12a4qcpHwCg+/RUoPfO7Bwba2yF+P79xt1WJ3Lf35c+pqlU8cwIP+vSK70f3Nw01f1KBgaKTxa4749u3jRT/Gs936OjxZ3t631fWm2WAtDJwuFwUaDc2dlpSHgoDcNnz55tSmf9ZoVMd/lBM5Se6Ki2dVq7cNeXd4JKJ6VSqVTRVnCXL18+cpU8nU5XfX14A/3e3l7+unt7e/rmb/7mmicRSr/fKSdTAACN1TOBPp0266tdR+gdU/P2e1U2axrSlSsged+T9vf7W+ZwnMq493nd2TFjq2e6vff4epdFbm1JV67UdwzQCQYGBg5VC72h5yhK99Du7+/XBZ+dKOsNWJ0SMr28gXNwcLChJzp6vcFeNpvVnTt3yjZf9L4mx8bGjlWZ39jYqDqDY3BwsGgK/82bN/P/+mlw593TXqo/0Jeb6g8A6DwdH+j9vk/zTl0fG6vdHK2e907ZbPHJAj+83dCrHdsJu8UsL5t/y73v8T4/ft6Dl+4FX6rWbQwOFjfmi8XMMX6b24XDhec+na49Hi/W6aObzc/PF4WPra2tYwXDzc3NoqAdi8V8B/V6Q9ZxK5ePKpxlLG3o1yhu4HQ1cptA6Wjj9nNCoVNOnGxsbFT8nvex8bPbQqXXhl/eKv3Ozo5SqZSy2azvLQq9wf/111+v675feumlhi2fAQC0Ts1A3+7riKv8v5yXShWqrf39JuTV4g2Ftd77bGwUB28/72kGBwvBsdJU7b299l7n7za7q3ZCwvseMJut/dhsbVXvlO/n8fC+D0qnpXreCw8MmNeHW/S4ds3f87mxYY4h0KObLS0t5fekzuVyWl1dPdLtlE5rnp+fr2urunrXkx9lnbv3pEG1EwL1VM79nlh46aWX8pdHRkZqhrt6xpDL5Q5N5/fDz33cqffMdgskk8l8Vbrcz+QN6H5OUNQKxLUet4mJifx13N8pv2FeMsth3ONTqZTvkzXZbFY7Ozt13RcAoD0dCvSl/8/XU6Usnbnl5zjv/4X7+/4r7q5aneDTaWllxVweGTFbp/kpAnn/j6v23ieZNGP2Lm/c2/P3c5Rb7+3K5cyU8Wb+X5vLlX++a0mnTdB9/vni57jc+/GZmeKp+NeuVb5d9zHwzrr1Pi5+T3DMzBROJPT3179V3ehoIdS7r59qz+fmphmn+zorx/u43rnDWnt0poGBAa2uruZDfSqVqjvUp9NprXh+WZaWluquQHvD//0aDUz29vb0pHdKlPwFNe99lAvibkO/ek5EXLlypeZ9J5PJ/DaBg4ODvh5f7xhqhfWtra2iEOc3hHtnZ5Sbpp1KpdTf31/X43HSNjc3ix7PcmHb+3PWeizd10ClnRn8bu/o3Ws+m83WtZ/8wMCAYrFY/iTX6uqqr9f3lStXdPbs2bZ+vgAA/rwjl4vFdnZMeFxdLR9ed3ZM5fRznzOX02npQx8y30smTUjb3JQ+/enDx+3tSbdumc/dMLa0VLi/Bw8K189mpU9+0oyhUph112u7Njakn/5pM7ZTpwpT2bNZM+aPf1z66ldNU7SPfax4qns1Tz5pQuHeXnEH93e9q3D7166ZExIf/7j0W79VuN6jR+bncH/2SqE8FDLN9O7cMccODEhPPSW98YYJh6Oj0g/9kL/x+uU+9ltbZvylwfKNN8xz+vrr5nrej2vXzGP96U9Ln/+8eVxLf57S9wbvepd5rXz+8+a5TqfNxwc/WDixkk5LL75o7ntpyTz27uPiht9k0tzWj/yIv5/z0SPzmE5NSdPT9T9OTz5pxv3GG+Z2LMvcZl+feV1ks+YxWl2Vfud3zPP11FPFt7GxIX3qU+Z3w/0dkMzjtrVV/DiPjkpPPFH/OIGT9q53vUtTU1N644039MYbbyidTiudTuuDH/xgzSnzOzs7+vjHP65cLqf+/n5dvHjxSBXCJ554Ij81+fd///f10Y9+VO9y/zh7pNNpra6u6uMf/7g++clP5r/+4MEDjY6OVh3vU089pddee00PHjzQG2+8oYmJCT3h+SV1ZxhUC19uFdQ1NTWlRCKhiYmJsuPd29vTiy++qK9+9asaGRnRv/yX/7LoPisZHR3Nj9Wdrl3u9t2u/B/72MfyXdy/+tWvamBgQE899VTZY7yPxy/8wi/oa1/7mt58881Dj/m1a9f0zDPPNC0g5nI5ffrTn9bnPve5oq8/+eSTFZdguEsXtra2tL6+fuhExLlz5w49vk899ZQsy9LXvvY1PXjwQP39/frgBz9Y9rZjsZheeOEFDQwM5MflXj+VSimZTOrixYs1f7annnoq//ocGxurK9BL5vfhQx/6kCzL0oMHD/S5z31OH/rQh8q+vnO5nD72sY/l/y33nOdyOX3qU5/Kn8jKZrMaHR3VU6X/yQEA2kLfSy8dHNR70OBgIaSWdjGvZGysEPb8bsVWrmiTSplp3i63gptMmg/vWAYHTXX23Lmj7zmfTpsu6fv7xeF3cNCMb2LCBNPNzcLP5Z1O707hriaZNPfhFkrcqds++0PVpZnb4EtYdd4AAAS1SURBVE1MVK+gJ5PmJEcqVbyUY2zM/Lyl7+s3NwszAEKh+qbOp9Pm8dvcPPpz70qlCmP3jntkxLy2KuWRZNJ/Jd47qwDoFG6FPpvNamBgQDMzM0VTgF17e3va2trKTwc+e/asLly4cKw9tnO5nGKxmPb39zU4OKjnn39eIyMjGhwc1J07d7S3t6dXX301v+VYpRMH8/PzFWcIpNNpXblyRXfu3Mnfx+DgYP62r127VrUCm0qldNnzH1YymdTGxob29vZ07tw5jY6OamRkRPv7+9rb21MymVR/f7/OnTuncDhc1+PjHWsoFMo/D4ODg/nb/9KXvqTV1dX8c3WUx2NpaUmPHj3S6Oho/nrJZFL379/P33ajbG5u5k88NEOlpRjpdFqxWCzfI2JiYkLnzp3TyMiI0um09vf3lUwmtbS0lD+Bcf78+fxsh9HRUWWzWS0tLfnet/7KlSva2dk51l73uVxOGxsb+ZNIMzMzCoVCGhwcVC6X097envb29nT27FnNz88feq6WlpZ8L8e4cuUK1X0AaBN9Bwf1B/pWqhToAS/3BM8Rl/gCqMPe3p5ee+017e3t6dGjRxoYGNDo6KhyuVy+yueuBX/mmWca2rHdve9sNqtcLqdHjx7lu4fPzMzkQ0s4HC6q5LphZGxsrGowyeVy+XXX6XRaAwMDGhsby4f7asoFeskExps3bxZN2R4YGNDExEQ+gB1VMpnMz15wA+ng4KBmZmaKQvz8/Hz+ftznS6rv8djf39fIyIhCoVDZgHhcqVTqSOv9/aq11GNvb0+pVCo/C2VgYECDg4P5Eyben9f7uIyOjurcuXN1PY/JZLJhJzCy2Wz+99H7O+Ge2Ko0oyGZTCqXy9VsOrm/v6+ZmZmmbDEJAKgfgR5daX7efNDvBzhZ7l7k3vXDtaa3d6tKgR4oFYvFimY9AADg1ztbPQCg0VIp08SOMA+cvOPs2w30Inc/+AvNWGcHAOh6BHp0nM1N09Pg7NnyoX1ry6xtBwCg3d28eVNnz55lCjsA4Ehq7kMPtJO9vUKzvNXVw9vsZbPme55dgAAAaAm3G/78/HzZJRe5XI794AEAx0KgR0cp3V639PMrV0x1vgeX6wIA2szNmze1t7enbDar1TJdWre2tvKNBQEAOIqOCvTpdPEe9JKZXl0a6tC9vO95wuHizzc3zWuBnkIAgHbT399f9Hk2m9XW1haN8AAAx9IRa+j///bu2DaBIIgC6BTgnMuXGAqgChwDVVwBdHHkEF8BFEBOAZtz+ZE7OBmMZEvItoQW3pM22nA3+Rppfl3/3HXfNMOJuG4253mNRsN/aJqI8fj6L9p2CPNq6oBHyjnH+XyOiIjdbndzt9lsLh3jnx3xPLfpdHqZwr9/We7S932s1+tYLBam8wD8SRG1dTnfN4WvqiHw8fxyHkJ81w1vnpJFeMDj1XV9V3f6crk0mX0R2+022raN1WoVKaU4Ho+x3+9jPp/fhHwA+I0iAj0AlCDnHH3fR0op3r5Z5tF1XZxOp6iqyoT+heSc43A4RM45JpNJzGYz7w/AvxDoAQAAoEBFLcUDAAAABgI9AAAAFEigBwAAgAIJ9AAAAFAggR4AAAAK9AEKdaB62mZnyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "image/png": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(r\"C:\\Users\\ilsup\\Google Drive\\NoViews\\Courses\\MITx - Machine Learning with Python from Linear Models to Deep Learning\\image-20200320184730545.png\", width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So as I understand this question you are asking which of the following are optimized during training (the others must have been optimized before that, or will remain as they were settled):\n",
    "\n",
    "1. The dimension of the feature representation. As from the example above would be how many fi will I consider for the hidden layer\n",
    "2. The weights that control the feature representation. The $w_{ij}$ that are used for xi to create the z\n",
    "3. The hyper-parameters. Learning rate, number of hidden units/layers, etc.\n",
    "4. The weights for the classifier. Thinking of the output layer as the classifier it would be like the θ for this classifier. Or, the weights that would accompany the fi for the last calculation (?)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Back Propagation\n",
    "\n",
    "\n",
    "Back propagation is the mechanism through which the parameters of the NN are updated. It is simply a series of derivatives (chain rule), one after the other. We will do an example with a NN with a 1-dimensional $x$ made up of $L$ hidden layers, but each layer consists of only one unit, and each unit has activation function $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'C:\\Users\\lucab\\Google Drive\\NoViews\\Courses\\MITx - Machine Learning with Python from Linear Models to Deep Learning\\images_l7_p4.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1292\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1293\u001b[1;33m             \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1294\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1283\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1284\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1293\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m             raise FileNotFoundError(\n\u001b[0m\u001b[0;32m   1296\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[0;32m   1297\u001b[0m         \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: 'C:\\Users\\lucab\\Google Drive\\NoViews\\Courses\\MITx - Machine Learning with Python from Linear Models to Deep Learning\\images_l7_p4.png'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'C:\\Users\\lucab\\Google Drive\\NoViews\\Courses\\MITx - Machine Learning with Python from Linear Models to Deep Learning\\images_l7_p4.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1292\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1293\u001b[1;33m             \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1294\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1313\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1293\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m             raise FileNotFoundError(\n\u001b[0m\u001b[0;32m   1296\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[0;32m   1297\u001b[0m         \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: 'C:\\Users\\lucab\\Google Drive\\NoViews\\Courses\\MITx - Machine Learning with Python from Linear Models to Deep Learning\\images_l7_p4.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(r\"C:\\Users\\lucab\\Google Drive\\NoViews\\Courses\\MITx - Machine Learning with Python from Linear Models to Deep Learning\\images_l7_p4.png\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with final loss defined as $\\displaystyle  \\displaystyle \\mathcal{L}(y, f_ L) = (y - f_ L)^2$. The goal is to tune the parameters of the NN in order to minimize the loss function. For instance, for the first layer, the update rule will be:\n",
    "\n",
    "$$w_1 \\leftarrow w_1 - \\eta \\cdot \\nabla _{w_1} \\mathcal{L}(y, f_ L)$$\n",
    "\n",
    "where \n",
    "\n",
    "$$z_1 = xw_1$$\n",
    "\n",
    "$$\\displaystyle \\text {for } i=2\\ldots L:\\quad z_ i  = \\displaystyle  f_{i-1} w_ i \\quad \\text {where }\\,  f_{i-1} \\, = \\, f(z_{i-1}).$$\n",
    "\n",
    "$$\n",
    "\\displaystyle \\delta _ i = \\frac{\\partial \\mathcal{L}}{\\partial z_ i}\n",
    "$$\n",
    "\n",
    "Where $\\eta$ be the learning rate for the stochastic gradient descent algorithm. The first step to updating any weight  w  is to calculate $\\displaystyle \\frac{\\partial \\mathcal{L}}{\\partial w}$.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_1} = \\frac{\\partial z_1}{\\partial w_1}\\cdot \\frac{\\partial \\mathcal{L}}{\\partial z_1} = x \\delta_1\n",
    "$$\n",
    "\n",
    "Then assume that $f$ is tge hyperbolic tangent:\n",
    "\n",
    "$$f(x) = \\tanh(x) \\hspace{1cm}  f′(x)=(1−\\tanh^2(x))$$\n",
    "\n",
    "Which of the following option is the correct expression for $δ1$ in terms of $δ2$?\n",
    "\n",
    "for the chain rule:\n",
    "\n",
    "$$\n",
    "\\delta _1 = \\frac{\\partial f_1}{\\partial z_1}\\cdot \\frac{\\partial z_2}{\\partial f_1}\\cdot \\frac{\\partial \\mathcal{L}}{\\partial z_2}.$$\n",
    "\n",
    "Since \n",
    "\n",
    "$$\n",
    "\\frac{\\partial f_1}{\\partial z_1} = (1 - f_1^2) \\hspace{1cm} \\text{and} \\hspace{1cm} \\frac{\\partial z_2}{\\partial f_1} = w_2\n",
    "$$\n",
    "\n",
    "Substituting the values of  $\\frac{\\partial f_1}{\\partial z_1}, \\frac{\\partial z_2}{\\partial f_1}$ into the main expression for $\\delta_1$ we get:\n",
    "\n",
    "$$\n",
    "\\delta _1 = (1 - f_1^2)\\cdot w_2\\cdot \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\, =\\,  (1 - f_1^2)\\cdot w_2\\cdot \\delta _2\n",
    "$$\n",
    "\n",
    "itera5ting recursively we get:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_1} = x (1-f_1^2)(1 - f_2^2)\\cdots (1-f_{L}^2)w_2w_3\\cdots w_ L(2(f_ L - y))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "#### Recurrent Neural Network (RNN)\n",
    "\n",
    "In recurrent neural networks (RNNs), we feed in a sequence of inputs, passing in the next entry in the input sequence and an output/structure of the RNN (usually a hidden state) into the RNN. So we partially feed the output of RNN back into itself for the next prediction. It is in this way that the RNN is \"recurrent\".\n",
    "\n",
    "Backpropagation updates the internals of the RNN to maximize the separate components: hidden state, output, etc. (Different architectures have different components. One of the better \"classic\" models is the long short-term memory (LSTM) cell.)\n",
    "\n",
    "RNN's learn the encoding into a feature vector, unlike feed-forward networks.\n",
    "\n",
    "#### Convolutional Neural Networks (CNN)\n",
    "\n",
    "Given an image, a standard feed forward neural network cannot recognize e.g. a mushroom of it is in a different position from the one in the train set. On top, the number of parameters would explode quickly. How can we solve it? \n",
    "\n",
    "Take an $(n \\times n)$ filter going around the image; \n",
    "\n",
    "Multiple layers are passed, so that from the original image we will have $k$ $n \\times n$ outputs, where $k$ is the number of filters applied\n",
    "\n",
    "- Know the differences between feed-forward and Convolutional neural networks (CNNs).\n",
    "\n",
    "- Implement the key parts in the CNNs, including **convolution** , **max pooling** units.\n",
    "\n",
    "- Determine the dimension of each channel in different layers with a given CNNs.\n",
    "\n",
    "- **CONVOLUTION**: A small squares rolls around the image and we apply the same parameters to all the patches (**shared weights**)\n",
    "\n",
    "  > Let's suppose that we wish to classify images of $1000×1000$ dimensions. If we wish to pass the input through a feed-forward neural network with a single hidden layer made up of $1000×1000$ hidden units each of which is fully connected to the full image, we need $10^{12}$ connections / parameters ($1'000'000 × 1'000'000$); if instead we have convolutional layer with $1$ filter of shape $11×11$ instead, we need $121$ parameters.\n",
    "\n",
    "  Remember that convolution is defines as:\n",
    "  $$\n",
    "  (f * g)(t) \\equiv \\int _{-\\infty }^{+\\infty } f(\\tau )g(t-\\tau )d\\tau\n",
    "  $$\n",
    "  Here is a very cool [video](https://www.youtube.com/watch?v=N-zd-T17uiE) that explains it\n",
    "\n",
    "**(MAX) POOLING**: in order to understand if an object *is* in the picture, regardless of *where* it is, we use pooling, i.e. we take the **maximum value** of each patch of the feature map\n",
    "\n",
    "\n",
    "**Convolution** in 1 dimension. Given two 1 dim vectors, $g$ and $f$, keep one still, flip the other one ($g'$) and make it slide one step at a time; then multiply each corresponding element of the vector for every step and sum everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "image/png": {
       "width": 800
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(r\"C:\\Users\\ilsup\\Google Drive\\NoViews\\Courses\\MITx - Machine Learning with Python from Linear Models to Deep Learning\\images_L12_cov_example.png\", width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we put zero where the value in the convolution is not defined is called **zero-padding**; Without zero padding means performing the operations only where both vectors are defined. \n",
    "\n",
    "With Matrixes, applying the convolutional filter $g'$ to $f$ we obtain C, whose sum is 15.\n",
    "\n",
    "$$\n",
    "f = \\begin{bmatrix}  1 &  2 &  1 \\\\ 2 &  1 &  1 \\\\ 1 &  1 &  1 \\end{bmatrix} \\hspace{1cm} g' = \\begin{bmatrix}  1 &  0.5 \\\\ 0.5 &  1 \\end{bmatrix} \\hspace{1cm} C = \\begin{bmatrix}  4 &  4 \\\\ 4 &  3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "*stride: how many pixel the filter moves at each step\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning\n",
    "\n",
    "- Understand the definition of *clustering*\n",
    "- Understand *clustering cost* with different similarity measures\n",
    "- Understand the *K-means* algorithm\n",
    "\n",
    "A *partition* of a set is a grouping of the set's elements into non-empty subsets, in such a way that **every** element is included in one and only one of the subsets. In other words, $C_1,C_2,...,C_K$ is a partition of ${1,2,...,n}$ if and only if\n",
    "$$\n",
    "C_1 \\cup C_2 \\cup ... \\cup C_ K = \\big \\{  1, 2, ..., n \\big \\}\\\\C_ i \\cap C_ j = \\emptyset \\quad \\text {for any $i \\neq j$ in $\\big \\{ 1, ..., k\\big \\} $ }\n",
    "$$\n",
    "\n",
    "The cost of each cluster is defined as the sum of the cost of each cluster \n",
    "\n",
    "- it can be the diameter of the cluster\n",
    "\n",
    "- the average distance between the points \n",
    "\n",
    "- Or the **distance from a *representative* $z$**:\n",
    "$$\n",
    "\\text{Cost}(C, z) = \\sum_{i \\in C} \\text{dist}(x^{(i)}, z)\n",
    "$$\n",
    "and $\\text{dist}$ is a certain form of distance between vectors. In our case we can use **cosine similarity** (i.e. the dot product of two vectors over the product of the two norms; it is not sensitive to the magnitude of the vectors)\n",
    "$$\n",
    "{\\displaystyle {\\text{similarity}}=\\cos(\\theta )={\\mathbf {A} \\cdot \\mathbf {B}  \\over \\|\\mathbf {A} \\|\\|\\mathbf {B} \\|}}\n",
    "$$\n",
    "Another way of measuring vector's similarity could have also been **Euclidean squared distance**:\n",
    "$$\n",
    "\\|\\mathbf{A}-\\mathbf {B} \\|^2\n",
    "$$\n",
    "We will use this last definition and we will define the full cost of the $k$ clusters given the $k$ representatives as:\n",
    "$$\n",
    "\\text{Cost}(C_1, \\dotso, C_k, z^{(1)}, \\dotso, z^{(k)}) = \\sum_{j = 1}^{k} \\sum_{i \\in C} \\|x^{(i)}-z^{(i)}\\|^2\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "#### K-means Clustering\n",
    "\n",
    "How, given the cost definition, we can find the best partition? Here is the algorithm:\n",
    "\n",
    "1. Randomly select $k$ representatives $z^{(1)} \\dots z^{(k)}$\n",
    "\n",
    "2. Iterate\n",
    "\n",
    "    1. Given $z_1,\\dots,z_K$ assign each data point $x^{(i)}$ to the closest $z_j$, so that\n",
    "\n",
    "    $$\n",
    "    \\text {Cost}(z_1, ... z_ K) = \\sum _{i=1}^{n} \\min _{j=1,...,K} \\left\\|  x^{(i)} - z_ j \\right\\| ^2\n",
    "    $$\n",
    "\n",
    "    2. Given $C_1, \\dots , C_K$ find the best representatives $z_1,...,z_K$ i.e. find them such that\n",
    "\n",
    "    $$\n",
    "    \\displaystyle z_ j=\\operatorname {argmin}_{z} \\sum _{i \\in C_ j} \\| x^{(i)} - z \\| ^2.\n",
    "    $$\n",
    "\n",
    "Given some points belonging to a cluster, how do we find the representative that minimize the squared Euclidean distance? First we compute the gradient:\n",
    "\n",
    "$$\n",
    "\\nabla _{z_ j}\\left(\\sum _{i \\in \\mathbb {C}_ j} \\| x^{(i)} - z_ j\\| ^2\\right).\n",
    "$$\n",
    "\n",
    "Obtaining:\n",
    "\n",
    "$$\n",
    "\\displaystyle \\sum _{i \\in \\mathbb {C}_ j} -2(x^{(i)} - z_ j)\n",
    "$$\n",
    "\n",
    "setting it to zero we obtain: \n",
    "\n",
    "$$\n",
    "\\displaystyle z_j = \\frac{\\sum _{i \\in C_ j} x^{(i)}}{|C_ j|}\n",
    "$$\n",
    "\n",
    "where $|C_ j|$ is the size of $C_j$; \n",
    "\n",
    "- Of course, it is not guaranteed (and most of the times not the case) that the $K$ representatives $z_1,...,z_K \\in {x_1,...,x_n}$\n",
    "- The result of clustering **depends** on the initialization of $z_1,...,z_K$\n",
    "- Imagine two normal distributions, different mean and same variance: in this case, the K-means clustering will yield the right clusters; **but when $\\sigma_1 >>\\sigma_2$, the boundary between the 2 optimal clusters is closer to one centroid then the other. Since the 2-means algorithm will always have an equidistant split between the two centroids, this behavior cannot be reproduced and thus k-means clustering will erroneoously assign more points to the cluster with a smaller variance.**\n",
    "\n",
    "#### K-Medoids\n",
    "\n",
    "How, given the cost definition, we can find the best partition? Here is the algorithm:\n",
    "\n",
    "1. Randomly select $k$ representatives $\\big \\{  z_1, ..., z_ K \\big \\}  \\subseteq \\big \\{  x_1, ..., x_ n \\big \\}$\n",
    "\n",
    "2. Iterate\n",
    "\n",
    "   1. Given $z_1,\\dots,z_K$ assign each data point $x^{(i)}$ to the closest $z_j$, so that\n",
    "\n",
    "   $$\n",
    "   \\text {Cost}(z_1, ... z_ K) = \\sum _{i=1}^{n} \\min _{j=1,...,k} \\text {dist}(x^{(i)}, z_ j)\n",
    "   $$\n",
    "\n",
    "   2. Given $C_1, \\dots , C_K$ find the best representatives $z_1,...,z_K$ i.e. find them such that\n",
    "\n",
    "   $$\n",
    "   \\sum _{x^{(i)} \\in C_ j} \\text {dist}(x^{(i)}, z_ j)\n",
    "   $$\n",
    "\n",
    "   is minimal. \n",
    "\n",
    "**K-means**: In step 2.A, we go through each of the $n$ $x_i$, and iterate through each of the $k$ $z_j$'s for each $x_i$ (to find the closest $z_j$). This iteration is $\\mathcal{O}(nK)$. And because each $x_i$ has length $d$, the total iteration is $\\mathcal{O}(ndK)$. Step 2.B is similar, so the order of complexity remains the same.\n",
    "\n",
    "**K-medoids**: Note that step 2.A of the K-Medoids is the same as that of K-Means, so the time complexity is $\\mathcal{O}(ndK)$. Note that step 2.B of K-Medoids has an additional loop of iterating through the $n$ points $z_j \\in {x_1,...,x_n}$ which takes $\\mathcal{O}(n)$. Thus step 2.2 takes $\\mathcal{O}(n^2dK)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Models\n",
    "\n",
    "Generative models model the probability distribution of each class. We will see two kind of models: **Multinomial** and **Gaussian**, and we have to answer to two order of questions: how to **estimate** the models and how to **predict** using these models. \n",
    "\n",
    "##### Multinomial Models\n",
    "\n",
    "Let's take the case of documents production. In the multinomial case we want to find the probability that a certain word is chosen given the parametrization $\\theta$ of the model:\n",
    "\n",
    "$$\n",
    "\\text{Prob}(w\\vert \\theta) = \\theta_w\n",
    "$$\n",
    "\n",
    "Given that $\\theta_w \\geq 0$ and that all the $\\theta_w$s sum to one. For a document where words are independently \n",
    "generated the **likelihood of the document** is:\n",
    "\n",
    "$$\n",
    "\\text{Prob}(\\text{Doc} \\vert \\theta) = \\prod_{i=1}^n \\theta_{w_i} = \\prod_{w \\in W} \\theta_w^{\\text{count w}}\n",
    "$$\n",
    "\n",
    "The probability of a document is the product of the appearance of each word, i.e. the product of each word at the power of the number of the word's appearances in the document. What we want to do is to maximize the probability of the word being generated \"moving\" $\\theta$.\n",
    "\n",
    "$$\n",
    "\\max_{\\theta} \\prod_{w \\in W} \\theta_w^{\\text{count w}}\n",
    "$$\n",
    "\n",
    "Taking the log it yields:\n",
    "\n",
    "$$\n",
    "\\sum_{w \\in W} \\text{count}(w) \\log(\\theta_w)\n",
    "$$\n",
    "\n",
    "Taking the derivative and setting to zero we get:\n",
    "\n",
    "$$\n",
    "\\tilde{\\theta}_w = \\frac{\\text{count}(w)}{\\sum_{w\\prime \\in W} \\text{count}(w \\prime) }\n",
    "$$\n",
    "\n",
    "For a dictionary with more than 2 words we get this result by applying Lagrangian Multipliers ([check here](https://courses.edx.org/courses/course-v1:MITx+6.86x+1T2020/courseware/unit_4/lec15_gm/?activate_block_id=block-v1%3AMITx%2B6.86x%2B1T2020%2Btype%40sequential%2Bblock%40lec15_gm])). \n",
    "\n",
    "Consider using a multinomial generative model $M$ for the task of binary classification consisting of two classes which are denoted by + (positive class) and - (negative class). Let the parameters of $M$ that maximize the likelihood of training data for the positive class be denoted by $\\theta^+$ and for the negative class be denoted by $\\theta^-$.\n",
    "\n",
    "Also, suppose that we classify a new document $D$ to belong to the positive class if and only if\n",
    "\n",
    "$$\n",
    "\\log \\frac{P(D | \\theta ^+)}{P(D | \\theta ^-)} \\ge 0\n",
    "$$\n",
    "\n",
    "Which becomes:\n",
    "\n",
    "$$\n",
    "\\sum_{w \\in W} \\text{count}(w) \\log \\frac{\\theta^+}{\\theta^-} = \\sum_{w \\in W} \\text{count}(w) \\tilde{\\theta}\n",
    "$$\n",
    "\n",
    "And we can see that the formula has the same form of a **linear classifier that goes through the origin**. Now we may want to inject some conditionality on the words flow. \n",
    "\n",
    "$$\n",
    "\\text{Prob}(y=+ \\vert D) = \\frac{\\text{Prob}(D \\vert \\theta^+)\\text{Prob}(y=+)}{\\text{Prob}(D)}\n",
    "$$\n",
    "\n",
    "Probability that I assign $+$ given a document $D$ follows Bayes rule. $\\text{Prob}(y=+)$ is the prior. Hence:\n",
    "\n",
    "$$\n",
    "\\log \\frac{P(y=+|D)}{P(y=-|D)} = \\log \\frac{\\text{Prob}(D \\vert \\theta^+)\\text{Prob}(y=+)}{\\text{Prob}(D \\vert \\theta^-)\\text{Prob}(y=-)}\n",
    "$$\n",
    "\n",
    "Where ${\\text{Prob}(D)}$ cancels out. \n",
    "\n",
    "$$\n",
    "\\log \\frac{\\text{Prob}(D \\vert \\theta^+)}{\\text{Prob}(D \\vert \\theta^-)} \\log \\frac{\\text{Prob}(y=+)}{\\text{Prob}(y=-)}\n",
    "$$\n",
    "\n",
    "If we substitute $\\log \\frac{\\text{Prob}(y=+)}{\\text{Prob}(y=-)}$ with $\\theta_0$ we get\n",
    "\n",
    "$$\n",
    "\\sum_{w \\in W} \\text{count}(w) \\log \\frac{\\theta^+}{\\theta^-}  + \\theta_0= \\sum_{w \\in W} \\text{count}(w) \\tilde{\\theta} + \\theta_0\n",
    "$$\n",
    "\n",
    "And we can see that the formula has the same form of a **linear classifier with an offset parameter**, where the offset parameter is the log of the ratio of our priors. \n",
    "\n",
    "##### Gaussian Generative Models\n",
    "\n",
    "A random vector $\\mathbf{X}=(X^{(1)},\\ldots ,X^{(d)})^ T\\,$ is a **Gaussian vector**, or **multivariate Gaussian or normal variable** , if any linear combination of its components is a (univariate) Gaussian variable or a constant (a “Gaussian\" variable with zero variance), i.e., if $\\alpha^TX$ is (univariate) Gaussian or constant for any constant non-zero vector $\\alpha \\in R^d$. The distribution of $\\mathbf{X}$, is completely specified by the vector mean $\\mu =\\mathbf E[\\mathbf{X}]= (\\mathbf E[X^{(1)}],\\ldots ,\\mathbf E[X^{(d)}])^ T$ and the $d×d$ covariance matrix $\\Sigma$. If it is invertible, then the pdf of $\\mathbf{X}$ is:\n",
    "$$\n",
    "\\displaystyle  \\displaystyle f_{\\mathbf{X}}(\\mathbf x) = \\frac{1}{\\sqrt{\\left(2\\pi \\right)^ d \\text {det}(\\Sigma )}}e^{-\\frac{1}{2}(\\mathbf x-\\mu )^ T \\Sigma ^{-1} (\\mathbf x-\\mu )}, ~ ~ ~ \\mathbf x\\in \\mathbb {R}^ d\n",
    "$$\n",
    "where $\\text {det}(\\Sigma )$ is the determinant of the $\\Sigma$, which is positive when $\\Sigma$ is invertible. If $\\mu=0$ and $\\Sigma $ is the identity matrix, then it is called a **standard normal random vector**.\n",
    "\n",
    "Recall that the **likelihood** of $x$ being generated from a multi-dimensional Gaussian with **all same mean** $\\mu$ and all the components being uncorrelated and having the same standard deviation $\\sigma$ is:\n",
    "$$\n",
    "P(x | \\mu , \\sigma ^2) = \\frac{1}{(2\\pi \\sigma ^2)^{d/2}} \\text {exp}(-\\frac{1}{2\\sigma ^2} \\|  x - \\mu \\| ^2)\n",
    "$$\n",
    "As expected, the result of the MLE for mean and variance is respectively (remember that the random variables have same mean and same variance)\n",
    "$$\n",
    "\\hat{\\mu } = \\frac{\\sum _{t=1}^{n} x^{(t)}}{n}\\\\\\hat{\\sigma }^2 = \\frac{\\sum _{t=1}^ n \\| x^{(t)} - \\mu \\| ^2}{nd}\n",
    "$$\n",
    "\n",
    "##### Gaussian Mixture Models\n",
    "\n",
    "It is a generative model for data $x\\in R_d$ is defined by the following set of parameters:\n",
    "\n",
    "1. $K$: Number of mixture components\n",
    "2. A $d$-dimensional Gaussian $\\mathcal{N}(\\mu ^{(j)}, \\sigma _ j^2)$ for every $j=1,\\dots,K$\n",
    "3. $p_1,…,p_K$ Mixture weights\n",
    "\n",
    "Let all of the parameters of the Gaussian mixture model be collectively represented as:\n",
    "$$\n",
    "\\theta = \\left\\{ p_1, \\dots , p_ K, \\mu ^{(1)}, \\dots , \\mu ^{(K)}, \\sigma _1^2, \\dots , \\sigma _ K^2\\right\\}\n",
    "$$\n",
    "The **likelihood** of a point x in a GMM is given as\n",
    "$$\n",
    "\\displaystyle  p(\\mathbf{x} \\mid \\theta ) = \\sum _{j = 1}^ K p_ j \\mathcal{N}(\\mathbf{x},\\mu ^{(j)}, \\sigma _ j^2).\n",
    "$$\n",
    "Let $x$ be an observation obtained from the Gaussian mixture model in the following way:\n",
    "\n",
    "1. We draw which gaussian we will use according to the probabilities $p_1, \\dots, p_k$\n",
    "2. We draw from the selected Gaussian $X \\sim N(\\mu^{(j)}, \\sigma_j^2)$\n",
    "\n",
    "##### EM (Expectation Maximization) Algorithm\n",
    "\n",
    "While a “hard\" clustering algorithm like k-means or k-medoids can only provide a cluster ID for each data point, the EM algorithm, along with the generative model driving its equations, can provide the posterior probability (“soft\" assignments) that every data point belongs to any cluster.\n",
    "\n",
    "\n",
    "**Process** (two gaussians)\n",
    "- Start with two randomly placed gaussians $\\mathcal{N_1}(\\mu_1, \\sigma _1^2), \\mathcal{N_2}(\\mu_2, \\sigma _ 2^2)$\n",
    "- For each point: does it look like it came from $\\mathcal{N_1}$ or $\\mathcal{N_2}$?\n",
    "- Adjust parameters of $\\mathcal{N_1}(\\mu_1, \\sigma _1^2)$ and $\\mathcal{N_2}(\\mu_2, \\sigma _2^2)$ to fit points assigned to them\n",
    "\n",
    "We observe $n$ data points $x_1,…,x_n$ in $R_d$. We wish to maximize the GMM likelihood with respect to the parameter set $\\theta = \\left\\{ p_1, \\dots , p_ K, \\mu ^{(1)}, \\dots , \\mu ^{(K)}, \\sigma _1^2, \\dots , \\sigma _ K^2\\right\\}$.\n",
    "\n",
    "Maximizing the log-likelihood $\\log (\\prod _{i=1}^ n p(\\mathbf x^{(i)} | \\theta ))$ is not tractable in the setting of GMMs. There is no closed-form solution to finding the parameter set $\\theta$ that maximizes the likelihood. The *EM algorithm* is an iterative algorithm that finds a locally optimal solution $\\tilde{\\theta}$ to the GMM likelihood maximization problem.\n",
    "\n",
    "**Initialization**: as for the initialization before the first time E step is carried out, we can either do a random initialization of the parameter set $\\theta$ (or we can employ k-means to find the initial cluster centers of the K clusters and use the global variance of the dataset as the initial variance of all the K clusters. In the latter case, the mixture weights can be initialized to the proportion of data points in the clusters as found by the k-means algorithm).\n",
    "\n",
    "**E Step**: it involves finding the posterior probability that point $x^{(i)}$ was generated by cluster $j$, for every $i=1,…,n$ and $j=1,…,K$. This step assumes the knowledge of the parameter set $\\theta $. We find the posterior using the following equation:\n",
    "$$\n",
    "\\displaystyle  p(\\text {point }\\mathbf x^{(i)}\\text { was generated by cluster }j | \\mathbf x^{(i)}, \\theta ) \\triangleq p(j \\mid i) = \\frac{p_ j \\mathcal{N}\\left(\\mathbf x^{(i)}; \\mu ^{(j)},\\sigma _ j^2 I\\right)}{p(\\mathbf x^{(i)} \\mid \\theta )}.\n",
    "$$\n",
    "\n",
    "**M Step**: The step maximizes a proxy function $\\hat{ℓ}(x(1),…,x(n)∣\\theta)$ of the log-likelihood over $\\theta$, where\n",
    "$$\n",
    "\\displaystyle  \\hat{\\ell }(\\mathbf x^{(1)},\\dots ,\\mathbf x^{(n)} \\mid \\theta ) \\triangleq \\sum _{i=1}^{n} \\sum _{j = 1}^ K p(j \\mid i) \\log \\left( \\frac{p\\left( \\mathbf x^{(i)} \\text { and } \\mathbf x^{(i)} \\text { generated by cluster }j \\mid \\theta \\right)}{p(j \\mid i)} \\right).\n",
    "$$\n",
    "This is done instead of maximizing over $\\theta$ the actual log-likelihood\n",
    "$$\n",
    "\\displaystyle  \\ell (\\mathbf x^{(1)},\\dots ,\\mathbf x^{(n)} \\mid \\theta ) = \\sum _{i=1}^{n} \\log \\left[\\sum _{j = 1}^ K p\\left( \\mathbf x^{(i)} \\text { generated by cluster }j \\mid \\theta \\right)\\right].\n",
    "$$\n",
    "Maximizing the proxy function over the parameter set $\\theta$, one can verify by taking derivatives and setting them equal to zero that\n",
    "\n",
    "\n",
    "$$\n",
    "\\displaystyle \\displaystyle  \\widehat{\\mu ^{(j)}}= \\frac{\\sum _{i = 1}^ n p (j \\mid i) \\mathbf x^{(i)}}{\\sum _{i=1}^ n p(j \\mid i)}\\\\\\displaystyle \\displaystyle  \\widehat{p _j}= \\frac{1}{n}\\sum _{i = 1}^ n p(j \\mid i),\\\\\\displaystyle \\displaystyle \\widehat{\\sigma _ j^2}= \\frac{\\sum _{i = 1}^ n p(j \\mid i) \\|  \\mathbf x^{(i)} - \\widehat{\\mu ^{(j)}} \\| ^2}{d \\sum _{i = 1}^ n p(j \\mid i)}.\n",
    "$$\n",
    "The E and M steps are repeated iteratively until there is no noticeable change in the actual likelihood computed after M step using the newly estimated parameters or if the parameters do not vary by much.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A **Markov decision process (MDP)** is defined by\n",
    "\n",
    "- a set of states $s\\in S$;\n",
    "- a set of actions $a \\in A$;\n",
    "- Action dependent transition probabilities $T(s,a,s')=P(s'|s, a)$, so that for each state $s$ and action $a$, $\\displaystyle \\sum _{s'\\in S} T(s,a,s')=1$.\n",
    "- Reward functions $R(s,a,s′)$, representing the reward for starting in state $s$, taking action $a$ and ending up in state $s′$ after one step. (The reward function may also depend only on $s$, or only $s$ and $a$.)\n",
    "\n",
    "MDPs depends on all the fourth quantities. MDPs also satisfy the **Markov property** in that the transition probabilities and rewards depend only on the current state and action, and remain unchanged regardless of the history (i.e. past states and actions) that leads to the current state.\n",
    "\n",
    "#### Utility Functions\n",
    "\n",
    "- **Final horizon** utility: $\\text{U}(s_o, \\dots, s_{n+k}) = \\text{U}(s_o, \\dots, s_{n})$, i.e. utility is calculated up to step $n$, then is stays the same till the last step $k$. This definition of utility though invalidates the dependency of decisions only on the current states; decision will also depend on \"timing\", i.e. if I have only one step to I will be pushed to behave in a riskier way. \n",
    "\n",
    "- **Discounted reward** utility: $U[s_0,s_1,\\ldots ]= \\sum _{k=0}^{\\infty } \\gamma ^ k R(s_ k).$ This means that we discount rewards by a factor $\\gamma$. This kind of utility is bounded to:\n",
    "  $$\n",
    "  U[s_0,s_1,\\ldots ]= \\sum _{k=0}^{\\infty } \\gamma ^ k R(s_ k) \\leq  \\sum _{k=0}^{\\infty } \\gamma ^ k R_{\\text{max}} \\leq R_{\\text{max}} \\frac{1}{1 - \\gamma} \\text {where }0\\leq \\gamma <1.\n",
    "  $$\n",
    "\n",
    "#### Policy\n",
    "\n",
    "Given an MDP, and a utility function $\\text{U}[s_0,s_1,…,s_n]$ our goal is to find an optimal policy function that maximizes the expectation of the utility. Here, a **policy** is a function $\\pi :S \\rightarrow A$ that assigns an action $\\pi(s)$ to any state $s$. We denote the optimal policy by $\\pi^*$.\n",
    "\n",
    "#### Bellman Equations\n",
    "\n",
    "- We then have the optimal policy $\\pi^*$ defined above\n",
    "\n",
    "- We define the **value function** $V^*(s)$ the expected reward at $s$ acting optimally \n",
    "\n",
    "- Then, we then define the **Q-function** $Q^∗(s,a)$ as the expected reward from starting at state $s$, then acting with action $a$, and acting optimally afterwards.\n",
    "\n",
    "  The **Bellman equations** put these three definitions together:\n",
    "  \n",
    "  $$\n",
    "  V^*(s) = \\displaystyle  \\displaystyle \\max _ a Q^*(s, a) = Q^*(s, \\pi^*(s))\\\\\n",
    "  \\displaystyle Q^*(s, a) = \\displaystyle  \\sum _{s'} T(s, a, s') (R(s, a, s') + \\gamma V^*(s') )\\\\\n",
    "  V^*(s) = \\displaystyle  \\displaystyle \\max _ a \\bigg[ \\sum _{s'} T(s, a, s') (R(s, a, s') + \\gamma V^*(s'))\\bigg]\n",
    "  \\\\\n",
    "  V^*(s) = \\displaystyle  \\displaystyle \\max _ a \\bigg[ \\sum _{s'} T(s, a, s') (R(s, a, s') + \\gamma \\max _ a Q^*(s', a') \\bigg]\n",
    "  $$\n",
    "\n",
    "The first equation means: select the set of actions that gives me the higher $Q$. The second equation means: the optimal $Q$ depends on the next step reward (weighted by its particular states with transition function) plus the optima value function discounted. \n",
    "\n",
    "If we consider the value function as the optimal reward function after $k$ steps, the  last equation becomes:\n",
    "$$\n",
    "V^*_{k+1}(s) = \\displaystyle  \\displaystyle \\max _ a \\bigg[ \\sum _{s'} T(s, a, s') (R(s, a, s') + \\gamma V^*_k(s'))\\bigg]\n",
    "$$\n",
    "And, as $k$ goes to $\\infty$,  $V^*_k(s)$ is supposed to converge to $V^*(s)$\n",
    "\n",
    "1. Initialization of the algorithm with $V^*_0(i)=0$ for every $i$\n",
    "2. Iterate until $V^*_k(s)= V^*_{k+1}(s)$ for every $s$\n",
    "\n",
    "\n",
    "\n",
    "In the real world, usually we know the actions and the states, but not the **transition probabilities** and the **rewards** which are **unknown**.  Then we should try to estimate transition probabilities:\n",
    "$$\n",
    "\\displaystyle \\displaystyle  \\hat{T} =  \\frac{\\text {count}(s, a, s')}{\\displaystyle \\sum _{s'} \\text {count}(s, a, s')}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\displaystyle \\hat{R} = \\frac{\\displaystyle \\sum _{t=1}^{\\text {count}(s, a, s')} R_ t(s, a, s')}{\\text {count}(s, a, s')}\n",
    "$$\n",
    "\n",
    "The issue with this approach (called **model based** approach) is that certain states might not be visited at all while collecting the statistics, or certain states might be visited much less often than others leading to very noisy estimates. We then try to use another approach (**model free** approach) which, instead of estimating the probability of an even occurring, simply adds up the outcomes and divides by the number of trials:\n",
    "$$\n",
    "\\displaystyle \\frac{\\sum _{i=1}^ K f(X_ i)}{K}\n",
    "$$\n",
    "**Sampling Based Approach for Q-learning**\n",
    "\n",
    "We decide to run different trials to estimate our $Q$:\n",
    "$$\n",
    "\\displaystyle \\text{sample}_1 = R(s, a, s'_1) + \\gamma \\max _ a Q^*(s'_1, a)\\\\ \\vdots \\\\\t\n",
    "\\displaystyle \\text{sample}_k = R(s, a, s'_k) + \\gamma \\max _ a Q^*(s'_k, a)\n",
    "$$\n",
    "Instead of taking a normal average of all the $k$ samples, we take an exponential running average. The algorithm becomes:\n",
    "\n",
    "1. Initializing $Q(s, a)$ with zero $\\forall s, a$\n",
    "\n",
    "2. Iterate until convergence:\n",
    "\n",
    "   1. collect sample $s, a, s'$ and $R(s, a, s')$\n",
    "\n",
    "   2. $Q_{i+1}(s) = \\displaystyle \\alpha (R(s, a, s'_i) + \\gamma \\max _ a Q^*(s'_i, a))+ (1-\\alpha)Q_i(s, a)$\n",
    "\n",
    "      $Q_{i+1}(s) = Q_i(s, a) + \\alpha (R(s, a, s'_i) + \\gamma \\max _ a Q^*(s'_i, a)-Q_i(s,a))$\n",
    "\n",
    "The second formula in step 2.2 is similar to the gradient descend one, and convergence can be demonstrated starting from there. \n",
    "\n",
    "**Exploration vs Exploitation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
